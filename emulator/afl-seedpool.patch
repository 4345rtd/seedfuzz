diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-analyze.c afl/afl-analyze.c
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-analyze.c	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-analyze.c	2024-12-05 21:00:44.621572006 +0800
@@ -807,7 +807,8 @@ static void usage(u8* argv0) {
        "  -f file       - input file read by the tested program (stdin)\n"
        "  -t msec       - timeout for each run (%u ms)\n"
        "  -m megs       - memory limit for child process (%u MB)\n"
-       "  -Q            - use binary-only instrumentation (QEMU mode)\n\n"
+       "  -Q            - use binary-only instrumentation (QEMU mode)\n"
+       "  -U            - use unicorn-based instrumentation (Unicorn mode)\n\n"
 
        "Analysis settings:\n\n"
 
@@ -943,14 +944,14 @@ static char** get_qemu_argv(u8* own_loc,
 int main(int argc, char** argv) {
 
   s32 opt;
-  u8  mem_limit_given = 0, timeout_given = 0, qemu_mode = 0;
+  u8  mem_limit_given = 0, timeout_given = 0, qemu_mode = 0, unicorn_mode = 0;
   char** use_argv;
 
   doc_path = access(DOC_PATH, F_OK) ? "docs" : DOC_PATH;
 
   SAYF(cCYA "afl-analyze " cBRI VERSION cRST " by <lcamtuf@google.com>\n");
 
-  while ((opt = getopt(argc,argv,"+i:f:m:t:eQ")) > 0)
+  while ((opt = getopt(argc,argv,"+i:f:m:t:eQU")) > 0)
 
     switch (opt) {
 
@@ -1029,6 +1030,13 @@ int main(int argc, char** argv) {
 
         qemu_mode = 1;
         break;
+        
+      case 'U':
+        if (unicorn_mode) FATAL("Multiple -U options not supported");
+        if (!mem_limit_given) mem_limit = MEM_LIMIT_UNICORN;
+        
+        unicorn_mode = 1;
+        break;
 
       default:
 
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-cmin afl/afl-cmin
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-cmin	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-cmin	2024-12-05 21:13:15.822471634 +0800
@@ -49,10 +49,10 @@ MEM_LIMIT=100
 TIMEOUT=none
 
 unset IN_DIR OUT_DIR STDIN_FILE EXTRA_PAR MEM_LIMIT_GIVEN \
-  AFL_CMIN_CRASHES_ONLY AFL_CMIN_ALLOW_ANY QEMU_MODE
-
-while getopts "+i:o:f:m:t:eQC" opt; do
+  AFL_CMIN_CRASHES_ONLY AFL_CMIN_ALLOW_ANY QEMU_MODE UNICORN_MODE \
+  CONSISTENCY
 
+while getopts "+i:o:f:m:t:eQUCK" opt; do
   case "$opt" in 
 
     "i")
@@ -83,9 +83,17 @@ while getopts "+i:o:f:m:t:eQC" opt; do
          test "$MEM_LIMIT_GIVEN" = "" && MEM_LIMIT=250
          QEMU_MODE=1
          ;;
+    "U")
+         EXTRA_PAR="$EXTRA_PAR -U"
+         test "$MEM_LIMIT_GIVEN"= "" && MEM_LIMIT=250
+         UNICORN_MODE=1
+         ;;
     "?")
          exit 1
          ;;
+    "K")
+         CONSISTENCY=1
+         ;;
 
    esac
 
@@ -111,6 +119,7 @@ Execution control settings:
   -m megs       - memory limit for child process ($MEM_LIMIT MB)
   -t msec       - run time limit for child process (none)
   -Q            - use binary-only instrumentation (QEMU mode)
+  -U            - use unicorn-based instrumentation (Unicorn mode)
 
 Minimization settings:
 
@@ -196,7 +205,7 @@ if [ ! -f "$TARGET_BIN" -o ! -x "$TARGET
 
 fi
 
-if [ "$AFL_SKIP_BIN_CHECK" = "" -a "$QEMU_MODE" = "" ]; then
+if [ "$AFL_SKIP_BIN_CHECK" = "" -a "$QEMU_MODE" = "" -a "$UNICORN_MODE" = ""]; then
 
   if ! grep -qF "__AFL_SHM_ID" "$TARGET_BIN"; then
     echo "[-] Error: binary '$TARGET_BIN' doesn't appear to be instrumented." 1>&2
@@ -307,32 +316,13 @@ echo "[*] Obtaining traces for input fil
 
 (
 
-  CUR=0
-
   if [ "$STDIN_FILE" = "" ]; then
 
-    while read -r fn; do
-
-      CUR=$((CUR+1))
-      printf "\\r    Processing file $CUR/$IN_COUNT... "
-
-      "$SHOWMAP" -m "$MEM_LIMIT" -t "$TIMEOUT" -o "$TRACE_DIR/$fn" -Z $EXTRA_PAR -- "$@" <"$IN_DIR/$fn"
-
-    done < <(ls "$IN_DIR")
+    "$HOWMAP" -m "$MEM_LIMIT" -t "$TIMEOUT" -o "$TRACE_DIR/$fn" -Z $EXTRA_PAR -- "$@" <"$IN_DIR/$fn"
 
   else
 
-    while read -r fn; do
-
-      CUR=$((CUR+1))
-      printf "\\r    Processing file $CUR/$IN_COUNT... "
-
-      cp "$IN_DIR/$fn" "$STDIN_FILE"
-
-      "$SHOWMAP" -m "$MEM_LIMIT" -t "$TIMEOUT" -o "$TRACE_DIR/$fn" -Z $EXTRA_PAR -A "$STDIN_FILE" -- "$@" </dev/null
-
-    done < <(ls "$IN_DIR")
-
+    "$SHOWMAP" -m "$MEM_LIMIT" -t "$TIMEOUT" -o "$TRACE_DIR" -i "$IN_DIR" -Z $EXTRA_PAR -A "$STDIN_FILE" -- "$@" </dev/null
 
   fi
 
@@ -456,6 +446,8 @@ fi
 echo "[+] Narrowed down to $OUT_COUNT files, saved in '$OUT_DIR'."
 echo
 
-test "$AFL_KEEP_TRACES" = "" && rm -rf "$TRACE_DIR"
+if [ "$CONSISTENCY" != "1" ]; then
+  test "$AFL_KEEP_TRACES" = "" && rm -rf "$TRACE_DIR"
+fi
 
 exit 0
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-fuzz.c afl/afl-fuzz.c
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-fuzz.c	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-fuzz.c	2024-12-05 21:43:19.248833371 +0800
@@ -1,5 +1,5 @@
 /*
-   american fuzzy lop - fuzzer code
+   American Fuzzy Lop - fuzzer code
    --------------------------------
 
    Written and maintained by Michal Zalewski <lcamtuf@google.com>
@@ -45,6 +45,8 @@
 #include <termios.h>
 #include <dlfcn.h>
 #include <sched.h>
+#include <stdbool.h>
+#include <pthread.h>
 
 #include <sys/wait.h>
 #include <sys/time.h>
@@ -56,6 +58,8 @@
 #include <sys/ioctl.h>
 #include <sys/file.h>
 
+#include <assert.h>
+
 #if defined(__APPLE__) || defined(__FreeBSD__) || defined (__OpenBSD__)
 #  include <sys/sysctl.h>
 #endif /* __APPLE__ || __FreeBSD__ || __OpenBSD__ */
@@ -81,9 +85,9 @@
 
 
 EXP_ST u8 *in_dir,                    /* Input directory with test cases  */
+          *out_file_dir,              /* File directory with file to fuzz */
           *out_file,                  /* File to fuzz, if any             */
           *out_dir,                   /* Working & output directory       */
-          *sync_dir,                  /* Synchronization directory        */
           *sync_id,                   /* Fuzzer ID                        */
           *use_banner,                /* Display banner                   */
           *in_bitmap,                 /* Input bitmap                     */
@@ -99,10 +103,7 @@ EXP_ST u64 mem_limit  = MEM_LIMIT;    /*
 static u32 stats_update_freq = 1;     /* Stats update frequency (execs)   */
 
 EXP_ST u8  skip_deterministic,        /* Skip deterministic stages?       */
-           force_deterministic,       /* Force deterministic stages?      */
-           use_splicing,              /* Recombine input files?           */
            dumb_mode,                 /* Run in non-instrumented mode?    */
-           score_changed,             /* Scoring for favorites changed?   */
            kill_signal,               /* Signal that killed the child     */
            resuming_fuzz,             /* Resuming an older fuzzing job?   */
            timeout_given,             /* Specific timeout given?          */
@@ -118,6 +119,7 @@ EXP_ST u8  skip_deterministic,        /*
            shuffle_queue,             /* Shuffle input queue?             */
            bitmap_changed = 1,        /* Time to update bitmap?           */
            qemu_mode,                 /* Running in QEMU mode?            */
+           unicorn_mode,              /* Running in Unicorn mode?         */
            skip_requested,            /* Skip request, via SIGUSR1        */
            run_over10m,               /* Run time over 10 minutes?        */
            persistent_mode,           /* Running in persistent mode?      */
@@ -148,25 +150,7 @@ static volatile u8 stop_soon,         /*
                    clear_screen = 1,  /* Window resized?                  */
                    child_timed_out;   /* Traced process timed out?        */
 
-EXP_ST u32 queued_paths,              /* Total number of queued testcases */
-           queued_variable,           /* Testcases with variable behavior */
-           queued_at_start,           /* Total number of initial inputs   */
-           queued_discovered,         /* Items discovered during this run */
-           queued_imported,           /* Items imported via -S            */
-           queued_favored,            /* Paths deemed favorable           */
-           queued_with_cov,           /* Paths with new coverage bytes    */
-           pending_not_fuzzed,        /* Queued but not done yet          */
-           pending_favored,           /* Pending favored paths            */
-           cur_skipped_paths,         /* Abandoned inputs in cur cycle    */
-           cur_depth,                 /* Current path depth               */
-           max_depth,                 /* Max path depth                   */
-           useless_at_start,          /* Number of useless starting paths */
-           var_byte_count,            /* Bitmap bytes with var behavior   */
-           current_entry,             /* Current queue entry ID           */
-           havoc_div = 1;             /* Cycle count divisor for havoc    */
-
 EXP_ST u64 total_crashes,             /* Total number of crashes          */
-           unique_crashes,            /* Crashes with unique signatures   */
            total_tmouts,              /* Total number of timeouts         */
            unique_tmouts,             /* Timeouts with unique signatures  */
            unique_hangs,              /* Hangs with unique signatures     */
@@ -176,8 +160,6 @@ EXP_ST u64 total_crashes,             /*
            last_crash_time,           /* Time for most recent crash (ms)  */
            last_hang_time,            /* Time for most recent hang (ms)   */
            last_crash_execs,          /* Exec counter at last crash       */
-           queue_cycle,               /* Queue round counter              */
-           cycles_wo_finds,           /* Cycles without any new paths     */
            trim_execs,                /* Execs done to trim input files   */
            bytes_trim_in,             /* Bytes coming into the trimmer    */
            bytes_trim_out,            /* Bytes coming outa the trimmer    */
@@ -186,30 +168,8 @@ EXP_ST u64 total_crashes,             /*
 
 static u32 subseq_tmouts;             /* Number of timeouts in a row      */
 
-static u8 *stage_name = "init",       /* Name of the current fuzz stage   */
-          *stage_short,               /* Short stage name                 */
-          *syncing_party;             /* Currently syncing with...        */
-
-static s32 stage_cur, stage_max;      /* Stage progression                */
-static s32 splicing_with = -1;        /* Splicing with which test case?   */
-
-static u32 master_id, master_max;     /* Master instance job splitting    */
-
-static u32 syncing_case;              /* Syncing with case #...           */
-
-static s32 stage_cur_byte,            /* Byte offset of current stage op  */
-           stage_cur_val;             /* Value used for stage op          */
-
-static u8  stage_val_type;            /* Value type (STAGE_VAL_*)         */
-
-static u64 stage_finds[32],           /* Patterns found per fuzz stage    */
-           stage_cycles[32];          /* Execs per fuzz stage             */
-
 static u32 rand_cnt;                  /* Random number counter            */
 
-static u64 total_cal_us,              /* Total calibration time (us)      */
-           total_cal_cycles;          /* Total calibration cycles         */
-
 static u64 total_bitmap_size,         /* Total bit count for all bitmaps  */
            total_bitmap_entries;      /* Number of bitmaps counted        */
 
@@ -252,14 +212,6 @@ struct queue_entry {
 
 };
 
-static struct queue_entry *queue,     /* Fuzzing queue (linked list)      */
-                          *queue_cur, /* Current offset within the queue  */
-                          *queue_top, /* Top of the list                  */
-                          *q_prev100; /* Previous 100 marker              */
-
-static struct queue_entry*
-  top_rated[MAP_SIZE];                /* Top entries for bitmap bytes     */
-
 struct extra_data {
   u8* data;                           /* Dictionary token data            */
   u32 len;                            /* Dictionary token length          */
@@ -274,6 +226,77 @@ static u32 a_extras_cnt;              /*
 
 static u8* (*post_handler)(u8* buf, u32* len);
 
+struct object {
+      u8   use_splicing,              /* Recombine input files?           */
+           score_changed;             /* Scoring for favorites changed?   */
+
+      u32  queued_paths,              /* Total number of queued testcases */
+           queued_variable,           /* Testcases with variable behavior */
+           queued_discovered,         /* Items discovered during this run */
+           queued_imported,           /* Items imported via -S            */
+           queued_favored,            /* Paths deemed favorable           */
+           queued_with_cov,           /* Paths with new coverage bytes    */
+           pending_not_fuzzed,        /* Queued but not done yet          */
+           pending_favored,           /* Pending favored paths            */
+           cur_skipped_paths,         /* Abandoned inputs in cur cycle    */
+           cur_depth,                 /* Current path depth               */
+           max_depth,                 /* Max path depth                   */
+           var_byte_count,            /* Bitmap bytes with var behavior   */
+           current_entry,             /* Current queue entry ID           */
+           havoc_div;                 /* Cycle count divisor for havoc    */
+
+      u64  unique_crashes,            /* Crashes with unique signatures   */
+           queue_cycle,               /* Queue round counter              */
+           cycles_wo_finds;           /* Cycles without any new paths     */
+
+      u8   *stage_name,               /* Name of the current fuzz stage   */
+           *stage_short;              /* Short stage name                 */
+
+      s32 stage_cur, stage_max,       /* Stage progression                */
+          splicing_with;              /* Splicing with which test case?   */
+
+      s32 stage_cur_byte,             /* Byte offset of current stage op  */
+          stage_cur_val;              /* Value used for stage op          */
+
+      u8  stage_val_type;             /* Value type (STAGE_VAL_*)         */
+
+      u64 stage_finds[32],            /* Patterns found per fuzz stage    */
+          stage_cycles[32];           /* Execs per fuzz stage             */
+
+      u64 total_cal_us,               /* Total calibration time (us)      */
+          total_cal_cycles;           /* Total calibration cycles         */
+
+      struct queue_entry  *queue,     /* Fuzzing queue (linked list)      */
+                          *queue_cur, /* Current offset within the queue  */
+                          *queue_top, /* Top of the list                  */
+                          *q_prev100; /* Previous 100 marker              */
+
+      struct queue_entry*
+        top_rated[MAP_SIZE];                /* Top entries for bitmap bytes     */
+
+}; 
+
+#define MAX_OBJ 50
+
+struct object obj[MAX_OBJ] = {
+  [0 ... MAX_OBJ-1] = {
+    .havoc_div = 1,
+    .stage_name = "init",
+    .splicing_with = -1
+  }
+};
+
+pthread_t tids[MAX_OBJ];
+pthread_mutex_t fuzz_mutex;
+pthread_cond_t fuzz_wait_cv;
+pthread_mutex_t object_mutex[MAX_OBJ];
+pthread_cond_t object_wait_cv[MAX_OBJ];
+bool fuzz_done[MAX_OBJ] = {
+  [0 ... MAX_OBJ-1] = {true}
+};
+
+static u32 obj_num = 0;
+
 /* Interesting values, as per config.h */
 
 static s8  interesting_8[]  = { INTERESTING_8 };
@@ -476,31 +499,61 @@ static void bind_to_free_cpu(void) {
 
   closedir(d);
 
-  for (i = 0; i < cpu_core_count; i++) if (!cpu_used[i]) break;
-
-  if (i == cpu_core_count) {
+  int bound = 0;
+  int tried_bind = 0;
+  int saved_errno = 0;
 
-    SAYF("\n" cLRD "[-] " cRST
-         "Uh-oh, looks like all %u CPU cores on your system are allocated to\n"
-         "    other instances of afl-fuzz (or similar CPU-locked tasks). Starting\n"
-         "    another fuzzer on this machine is probably a bad plan, but if you are\n"
-         "    absolutely sure, you can set AFL_NO_AFFINITY and try again.\n",
-         cpu_core_count);
+  for (i = 0; i < cpu_core_count; i++) {
 
-    FATAL("No more free CPU cores");
+    if (!cpu_used[i]) {
+    
+      OKF("Found a free CPU core, attempting bind to #%u.", i);
+      
+      CPU_ZERO(&c);
+      CPU_SET(i, &c);
+      
+      if (sched_setaffinity(0, sizeof(c), &c)) {
 
+        saved_errno = errno;
+        tried_bind++;
+        WARNF("Binding attempt failed; looking for another core...");
+        
+      } else {
+      
+        cpu_aff = i;
+        bound = 1;
+        break;
+      }
+    }
   }
 
-  OKF("Found a free CPU core, binding to #%u.", i);
+  if (!bound) {
+    
+    if (tried_bind == 0) {
+    
+      SAYF("\n" cLRD "[-] " cRST
+           "Uh-oh, looks like all %u CPU cores on your system are allocated to\n"
+           "    other instances of afl-fuzz (or similar CPU-locked tasks). Starting\n"
+           "    another fuzzer on this machine is probably a bad plan, but if you are\n"
+           "    absolutely sure, you can set AFL_NO_AFFINITY and try again.\n\n",
+           cpu_core_count);
+      FATAL("No more free CPU cores");
 
-  cpu_aff = i;
+    } else {
 
-  CPU_ZERO(&c);
-  CPU_SET(i, &c);
+      SAYF("\n" cLRD "[-] " cRST
+           "Uh-oh, afl-fuzz found %u apparently free CPU cores, but the system\n"
+           "    wouldn't let us bind to any of them. This can happen if we do not\n"
+           "    have CAP_SYS_NICE, or if we are running in a container that is\n" 
+           "    restricted to a certain set of CPUs that already have processes bound\n"
+           "    to them. For a quick workaround, set AFL_NO_AFFINITY and try again.\n",
+           tried_bind);
 
-  if (sched_setaffinity(0, sizeof(c), &c))
-    PFATAL("sched_setaffinity failed");
+      errno = saved_errno;
+      PFATAL("sched_setaffinity failed");
 
+    }
+  }
 }
 
 #endif /* HAVE_AFFINITY */
@@ -695,12 +748,12 @@ static u8* DTD(u64 cur_ms, u64 event_ms)
    .state file to avoid repeating deterministic fuzzing when resuming aborted
    scans. */
 
-static void mark_as_det_done(struct queue_entry* q) {
+static void mark_as_det_done(struct queue_entry* q, u32 oid) {
 
   u8* fn = strrchr(q->fname, '/');
   s32 fd;
 
-  fn = alloc_printf("%s/queue/.state/deterministic_done/%s", out_dir, fn + 1);
+  fn = alloc_printf("%s/queue_%03u/.state/deterministic_done/%s", out_dir, oid, fn + 1);
 
   fd = open(fn, O_WRONLY | O_CREAT | O_EXCL, 0600);
   if (fd < 0) PFATAL("Unable to create '%s'", fn);
@@ -716,12 +769,12 @@ static void mark_as_det_done(struct queu
 /* Mark as variable. Create symlinks if possible to make it easier to examine
    the files. */
 
-static void mark_as_variable(struct queue_entry* q) {
+static void mark_as_variable(struct queue_entry* q, u32 oid) {
 
   u8 *fn = strrchr(q->fname, '/') + 1, *ldest;
 
   ldest = alloc_printf("../../%s", fn);
-  fn = alloc_printf("%s/queue/.state/variable_behavior/%s", out_dir, fn);
+  fn = alloc_printf("%s/queue_%03u/.state/variable_behavior/%s", out_dir, oid, fn);
 
   if (symlink(ldest, fn)) {
 
@@ -742,7 +795,7 @@ static void mark_as_variable(struct queu
 /* Mark / unmark as redundant (edge-only). This is not used for restoring state,
    but may be useful for post-processing datasets. */
 
-static void mark_as_redundant(struct queue_entry* q, u8 state) {
+static void mark_as_redundant(struct queue_entry* q, u8 state, u32 oid) {
 
   u8* fn;
   s32 fd;
@@ -752,7 +805,7 @@ static void mark_as_redundant(struct que
   q->fs_redundant = state;
 
   fn = strrchr(q->fname, '/');
-  fn = alloc_printf("%s/queue/.state/redundant_edges/%s", out_dir, fn + 1);
+  fn = alloc_printf("%s/queue_%03u/.state/redundant_edges/%s", out_dir, oid, fn + 1);
 
   if (state) {
 
@@ -773,33 +826,33 @@ static void mark_as_redundant(struct que
 
 /* Append new test case to the queue. */
 
-static void add_to_queue(u8* fname, u32 len, u8 passed_det) {
+static void add_to_queue(u8* fname, u32 len, u8 passed_det, u32 oid) {
 
   struct queue_entry* q = ck_alloc(sizeof(struct queue_entry));
 
   q->fname        = fname;
   q->len          = len;
-  q->depth        = cur_depth + 1;
+  q->depth        = obj[oid].cur_depth + 1;
   q->passed_det   = passed_det;
 
-  if (q->depth > max_depth) max_depth = q->depth;
+  if (q->depth > obj[oid].max_depth) obj[oid].max_depth = q->depth;
 
-  if (queue_top) {
+  if (obj[oid].queue_top) {
 
-    queue_top->next = q;
-    queue_top = q;
+    obj[oid].queue_top->next = q;
+    obj[oid].queue_top = q;
 
-  } else q_prev100 = queue = queue_top = q;
+  } else obj[oid].q_prev100 = obj[oid].queue = obj[oid].queue_top = q;
 
-  queued_paths++;
-  pending_not_fuzzed++;
+  obj[oid].queued_paths++;
+  obj[oid].pending_not_fuzzed++;
 
-  cycles_wo_finds = 0;
+  obj[oid].cycles_wo_finds = 0;
 
-  if (!(queued_paths % 100)) {
+  if (!(obj[oid].queued_paths % 100)) {
 
-    q_prev100->next_100 = q;
-    q_prev100 = q;
+    obj[oid].q_prev100->next_100 = q;
+    obj[oid].q_prev100 = q;
 
   }
 
@@ -812,16 +865,18 @@ static void add_to_queue(u8* fname, u32
 
 EXP_ST void destroy_queue(void) {
 
-  struct queue_entry *q = queue, *n;
+  for (u32 oid = 0; oid < obj_num; oid++) {
+    struct queue_entry *q = obj[oid].queue, *n;
 
-  while (q) {
+    while (q) {
 
-    n = q->next;
-    ck_free(q->fname);
-    ck_free(q->trace_mini);
-    ck_free(q);
-    q = n;
+      n = q->next;
+      ck_free(q->fname);
+      ck_free(q->trace_mini);
+      ck_free(q);
+      q = n;
 
+    }
   }
 
 }
@@ -1233,7 +1288,7 @@ static void minimize_bits(u8* dst, u8* s
    for every byte in the bitmap. We win that slot if there is no previous
    contender, or if the contender has a more favorable speed x size factor. */
 
-static void update_bitmap_score(struct queue_entry* q) {
+static void update_bitmap_score(struct queue_entry* q, u32 oid) {
 
   u32 i;
   u64 fav_factor = q->exec_us * q->len;
@@ -1245,25 +1300,25 @@ static void update_bitmap_score(struct q
 
     if (trace_bits[i]) {
 
-       if (top_rated[i]) {
+       if (obj[oid].top_rated[i]) {
 
          /* Faster-executing or smaller test cases are favored. */
 
-         if (fav_factor > top_rated[i]->exec_us * top_rated[i]->len) continue;
+         if (fav_factor > obj[oid].top_rated[i]->exec_us * obj[oid].top_rated[i]->len) continue;
 
          /* Looks like we're going to win. Decrease ref count for the
             previous winner, discard its trace_bits[] if necessary. */
 
-         if (!--top_rated[i]->tc_ref) {
-           ck_free(top_rated[i]->trace_mini);
-           top_rated[i]->trace_mini = 0;
+         if (!--obj[oid].top_rated[i]->tc_ref) {
+           ck_free(obj[oid].top_rated[i]->trace_mini);
+           obj[oid].top_rated[i]->trace_mini = 0;
          }
 
        }
 
        /* Insert ourselves as the new winner. */
 
-       top_rated[i] = q;
+       obj[oid].top_rated[i] = q;
        q->tc_ref++;
 
        if (!q->trace_mini) {
@@ -1271,7 +1326,7 @@ static void update_bitmap_score(struct q
          minimize_bits(q->trace_mini, trace_bits);
        }
 
-       score_changed = 1;
+       obj[oid].score_changed = 1;
 
      }
 
@@ -1284,22 +1339,22 @@ static void update_bitmap_score(struct q
    until the next run. The favored entries are given more air time during
    all fuzzing steps. */
 
-static void cull_queue(void) {
+static void cull_queue(u32 oid) {
 
   struct queue_entry* q;
   static u8 temp_v[MAP_SIZE >> 3];
   u32 i;
 
-  if (dumb_mode || !score_changed) return;
+  if (dumb_mode || !obj[oid].score_changed) return;
 
-  score_changed = 0;
+  obj[oid].score_changed = 0;
 
   memset(temp_v, 255, MAP_SIZE >> 3);
 
-  queued_favored  = 0;
-  pending_favored = 0;
+  obj[oid].queued_favored  = 0;
+  obj[oid].pending_favored = 0;
 
-  q = queue;
+  q = obj[oid].queue;
 
   while (q) {
     q->favored = 0;
@@ -1310,27 +1365,27 @@ static void cull_queue(void) {
      If yes, and if it has a top_rated[] contender, let's use it. */
 
   for (i = 0; i < MAP_SIZE; i++)
-    if (top_rated[i] && (temp_v[i >> 3] & (1 << (i & 7)))) {
+    if (obj[oid].top_rated[i] && (temp_v[i >> 3] & (1 << (i & 7)))) {
 
       u32 j = MAP_SIZE >> 3;
 
       /* Remove all bits belonging to the current entry from temp_v. */
 
       while (j--) 
-        if (top_rated[i]->trace_mini[j])
-          temp_v[j] &= ~top_rated[i]->trace_mini[j];
+        if (obj[oid].top_rated[i]->trace_mini[j])
+          temp_v[j] &= ~obj[oid].top_rated[i]->trace_mini[j];
 
-      top_rated[i]->favored = 1;
-      queued_favored++;
+      obj[oid].top_rated[i]->favored = 1;
+      obj[oid].queued_favored++;
 
-      if (!top_rated[i]->was_fuzzed) pending_favored++;
+      if (!obj[oid].top_rated[i]->was_fuzzed) obj[oid].pending_favored++;
 
     }
 
-  q = queue;
+  q = obj[oid].queue;
 
   while (q) {
-    mark_as_redundant(q, !q->favored);
+    mark_as_redundant(q, !q->favored, oid);
     q = q->next;
   }
 
@@ -1407,12 +1462,6 @@ static void read_testcases(void) {
   struct dirent **nl;
   s32 nl_cnt;
   u32 i;
-  u8* fn;
-
-  /* Auto-detect non-in-place resumption attempts. */
-
-  fn = alloc_printf("%s/queue", in_dir);
-  if (!access(fn, F_OK)) in_dir = fn; else ck_free(fn);
 
   ACTF("Scanning '%s'...", in_dir);
 
@@ -1448,44 +1497,69 @@ static void read_testcases(void) {
     struct stat st;
 
     u8* fn = alloc_printf("%s/%s", in_dir, nl[i]->d_name);
-    u8* dfn = alloc_printf("%s/.state/deterministic_done/%s", in_dir, nl[i]->d_name);
-
-    u8  passed_det = 0;
 
     free(nl[i]); /* not tracked */
- 
+    // printf("current dir name = %s, isreg = %d, isdir = %d, size = %d\n", nl[i]->d_name, strcmp(nl[i]->d_name, "."), strcmp(nl[i]->d_name, ".."), st.st_size);
     if (lstat(fn, &st) || access(fn, R_OK))
       PFATAL("Unable to access '%s'", fn);
 
     /* This also takes care of . and .. */
-
-    if (!S_ISREG(st.st_mode) || !st.st_size || strstr(fn, "/README.txt")) {
+    if (nl[i]->d_name[0] == '.' || strstr(fn, "/README.txt")) {
 
       ck_free(fn);
-      ck_free(dfn);
       continue;
 
     }
+    
+    if (S_ISDIR(st.st_mode)) {
+      
+      struct dirent **sub_nl;
+      s32 sub_nl_cnt = scandir(fn, &sub_nl, NULL, alphasort);
+
+      if (sub_nl_cnt < 0) {
 
-    if (st.st_size > MAX_FILE) 
-      FATAL("Test case '%s' is too big (%s, limit is %s)", fn,
-            DMS(st.st_size), DMS(MAX_FILE));
-
-    /* Check for metadata that indicates that deterministic fuzzing
-       is complete for this entry. We don't want to repeat deterministic
-       fuzzing when resuming aborted scans, because it would be pointless
-       and probably very time-consuming. */
+        PFATAL("Unable to open '%s'", fn);
 
-    if (!access(dfn, F_OK)) passed_det = 1;
-    ck_free(dfn);
+      }
+
+      for(u32 j = 0; j< sub_nl_cnt; j++) {
+
+        struct stat sub_st;
+        
+        u8* sub_fn = alloc_printf("%s/%s", fn, sub_nl[j]->d_name);
+      
+        free(sub_nl[j]);
 
-    add_to_queue(fn, st.st_size, passed_det);
+        if (lstat(sub_fn, &sub_st) || access(sub_fn, R_OK))
+          PFATAL("Unable to access '%s'", sub_fn);
+
+        
+        if (!S_ISREG(sub_st.st_mode) || !sub_st.st_size || strstr(sub_fn, "/README.txt")) {
+
+          ck_free(sub_fn);
+          continue;
+
+        }
+        // printf("index = %d, name = %s\n", j, sub_fn);
+        if (sub_st.st_size > MAX_FILE) 
+          FATAL("Test case '%s' is too big (%s, limit is %s)", fn,
+            DMS(sub_st.st_size), DMS(MAX_FILE));
+        
+        add_to_queue(sub_fn, sub_st.st_size, 0, obj_num);
+
+      }
+
+      obj_num++;
+
+      free(sub_nl); /* not tracked */
+
+    }
 
   }
 
   free(nl); /* not tracked */
 
-  if (!queued_paths) {
+  if (!obj[0].queued_paths) {
 
     SAYF("\n" cLRD "[-] " cRST
          "Looks like there are no valid test cases in the input directory! The fuzzer\n"
@@ -1498,8 +1572,6 @@ static void read_testcases(void) {
   }
 
   last_path_time = 0;
-  queued_at_start = queued_paths;
-
 }
 
 
@@ -1884,22 +1956,26 @@ static void save_auto(void) {
   if (!auto_changed) return;
   auto_changed = 0;
 
-  for (i = 0; i < MIN(USE_AUTO_EXTRAS, a_extras_cnt); i++) {
+  for (u32 oid = 0; oid < obj_num; oid++) {
 
-    u8* fn = alloc_printf("%s/queue/.state/auto_extras/auto_%06u", out_dir, i);
-    s32 fd;
+    for (i = 0; i < MIN(USE_AUTO_EXTRAS, a_extras_cnt); i++) {
 
-    fd = open(fn, O_WRONLY | O_CREAT | O_TRUNC, 0600);
+      u8* fn = alloc_printf("%s/queue_%03u/.state/auto_extras/auto_%06u", out_dir, oid, i);
+      s32 fd;
 
-    if (fd < 0) PFATAL("Unable to create '%s'", fn);
+      fd = open(fn, O_WRONLY | O_CREAT | O_TRUNC, 0600);
 
-    ck_write(fd, a_extras[i].data, a_extras[i].len, fn);
+      if (fd < 0) PFATAL("Unable to create '%s'", fn);
 
-    close(fd);
-    ck_free(fn);
+      ck_write(fd, a_extras[i].data, a_extras[i].len, fn);
 
-  }
+      close(fd);
+      ck_free(fn);
+
+    }
 
+  }
+  
 }
 
 
@@ -1990,6 +2066,8 @@ EXP_ST void init_forkserver(char** argv)
 
   if (!forksrv_pid) {
 
+    /* CHILD PROCESS */
+    
     struct rlimit r;
 
     /* Umpf. On OpenBSD, the default fd limit for root users is set to
@@ -2035,10 +2113,25 @@ EXP_ST void init_forkserver(char** argv)
 
     setsid();
 
-    dup2(dev_null_fd, 1);
-    dup2(dev_null_fd, 2);
+    if (getenv("AFL_LOG_TARGET_OUTPUT")) {
+      /* Log target output to a file */
+      char *log_path;
+      int log_fd;
+      assert(asprintf(&log_path, "%s/%s", out_dir, "log.txt") > 0);
+      ACTF("Logging is enabled, logging to %s\n", log_path);
+      log_fd = open(log_path, O_RDWR | O_CREAT | O_TRUNC, S_IRWXU);
+      assert(log_fd >= 0);
+      free(log_path);
+      dup2(log_fd, 1);
+      dup2(log_fd, 2);
+      close(log_fd);
+    } else {
+      dup2(dev_null_fd, 1);
+      dup2(dev_null_fd, 2);
+    }
+    
 
-    if (out_file) {
+    if (out_file_dir) {
 
       dup2(dev_null_fd, 0);
 
@@ -2095,6 +2188,8 @@ EXP_ST void init_forkserver(char** argv)
 
   }
 
+  /* PARENT PROCESS */
+  
   /* Close the unneeded endpoints. */
 
   close(ctl_pipe[0]);
@@ -2258,7 +2353,7 @@ EXP_ST void init_forkserver(char** argv)
 /* Execute target application, monitoring for timeouts. Return status
    information. The called program will update trace_bits[]. */
 
-static u8 run_target(char** argv, u32 timeout) {
+static u8 run_target(u32 timeout, u32 oid) {
 
   static struct itimerval it;
   static u32 prev_timed_out = 0;
@@ -2268,6 +2363,16 @@ static u8 run_target(char** argv, u32 ti
 
   child_timed_out = 0;
 
+  /*          wait for request, start of one reply                */
+  pthread_mutex_lock(&object_mutex[oid]);
+
+  while (fuzz_done[oid] == true)
+    pthread_cond_wait(&object_wait_cv[oid], &object_mutex[oid]);
+
+  // printf("thread %d after pthread_cond_wait\n", oid);
+
+  // pthread_mutex_lock(&fuzz_mutex);
+
   /* After this memset, trace_bits[] are effectively volatile, so we
      must prevent any earlier operations from venturing into that
      territory. */
@@ -2280,107 +2385,22 @@ static u8 run_target(char** argv, u32 ti
      execve(). There is a bit of code duplication between here and 
      init_forkserver(), but c'est la vie. */
 
-  if (dumb_mode == 1 || no_forkserver) {
-
-    child_pid = fork();
-
-    if (child_pid < 0) PFATAL("fork() failed");
 
-    if (!child_pid) {
+  s32 res;
 
-      struct rlimit r;
+  /* In non-dumb mode, we have the fork server up and running, so simply
+      tell it to have at it, and then read back PID. */
 
-      if (mem_limit) {
+  if ((res = write(fsrv_ctl_fd, &prev_timed_out, 4)) != 4) {
 
-        r.rlim_max = r.rlim_cur = ((rlim_t)mem_limit) << 20;
+    if (stop_soon) return 0;
+    RPFATAL(res, "Unable to request new process from fork server (OOM?)");
 
-#ifdef RLIMIT_AS
-
-        setrlimit(RLIMIT_AS, &r); /* Ignore errors */
-
-#else
-
-        setrlimit(RLIMIT_DATA, &r); /* Ignore errors */
-
-#endif /* ^RLIMIT_AS */
-
-      }
-
-      r.rlim_max = r.rlim_cur = 0;
-
-      setrlimit(RLIMIT_CORE, &r); /* Ignore errors */
-
-      /* Isolate the process and configure standard descriptors. If out_file is
-         specified, stdin is /dev/null; otherwise, out_fd is cloned instead. */
-
-      setsid();
-
-      dup2(dev_null_fd, 1);
-      dup2(dev_null_fd, 2);
-
-      if (out_file) {
-
-        dup2(dev_null_fd, 0);
-
-      } else {
-
-        dup2(out_fd, 0);
-        close(out_fd);
-
-      }
-
-      /* On Linux, would be faster to use O_CLOEXEC. Maybe TODO. */
-
-      close(dev_null_fd);
-      close(out_dir_fd);
-      close(dev_urandom_fd);
-      close(fileno(plot_file));
-
-      /* Set sane defaults for ASAN if nothing else specified. */
-
-      setenv("ASAN_OPTIONS", "abort_on_error=1:"
-                             "detect_leaks=0:"
-                             "symbolize=0:"
-                             "allocator_may_return_null=1", 0);
-
-      setenv("MSAN_OPTIONS", "exit_code=" STRINGIFY(MSAN_ERROR) ":"
-                             "symbolize=0:"
-                             "msan_track_origins=0", 0);
-
-      execv(target_path, argv);
-
-      /* Use a distinctive bitmap value to tell the parent about execv()
-         falling through. */
-
-      *(u32*)trace_bits = EXEC_FAIL_SIG;
-      exit(0);
-
-    }
-
-  } else {
-
-    s32 res;
-
-    /* In non-dumb mode, we have the fork server up and running, so simply
-       tell it to have at it, and then read back PID. */
-
-    if ((res = write(fsrv_ctl_fd, &prev_timed_out, 4)) != 4) {
-
-      if (stop_soon) return 0;
-      RPFATAL(res, "Unable to request new process from fork server (OOM?)");
-
-    }
-
-    if ((res = read(fsrv_st_fd, &child_pid, 4)) != 4) {
-
-      if (stop_soon) return 0;
-      RPFATAL(res, "Unable to request new process from fork server (OOM?)");
-
-    }
+  }
 
-    if (child_pid <= 0) FATAL("Fork server is misbehaving (OOM?)");
+  child_pid = 1000;
 
-  }
+  // printf("run_target thread = %d, after write\n", oid);
 
   /* Configure timeout, as requested by user, then wait for child to terminate. */
 
@@ -2391,23 +2411,15 @@ static u8 run_target(char** argv, u32 ti
 
   /* The SIGALRM handler simply kills the child_pid and sets child_timed_out. */
 
-  if (dumb_mode == 1 || no_forkserver) {
-
-    if (waitpid(child_pid, &status, 0) <= 0) PFATAL("waitpid() failed");
-
-  } else {
+  if ((res = read(fsrv_st_fd, &status, 4)) != 4) {
 
-    s32 res;
-
-    if ((res = read(fsrv_st_fd, &status, 4)) != 4) {
-
-      if (stop_soon) return 0;
-      RPFATAL(res, "Unable to communicate with fork server (OOM?)");
-
-    }
+    if (stop_soon) return 0;
+    RPFATAL(res, "Unable to communicate with fork server (OOM?)");
 
   }
-
+  // if (status != 0 && status != -1)
+    // printf("thread %d status = %d\n", oid, status);
+    
   if (!WIFSTOPPED(status)) child_pid = 0;
 
   it.it_value.tv_sec = 0;
@@ -2433,6 +2445,20 @@ static u8 run_target(char** argv, u32 ti
 
   prev_timed_out = child_timed_out;
 
+
+  /*            end of one fuzzing process                 */
+  fuzz_done[oid] = true;
+
+  // pthread_mutex_unlock(&fuzz_mutex);
+
+  pthread_mutex_unlock(&object_mutex[oid]);
+
+  // printf("[T] thread = %d, before pthread_cond_signal(&fuzz_wait_cv)\n", oid);
+
+  pthread_cond_signal(&fuzz_wait_cv);
+
+  // printf("[T] thread = %d, after pthread_cond_signal(&fuzz_wait_cv)\n", oid);
+
   /* Report outcome to caller. */
 
   if (WIFSIGNALED(status) && !stop_soon) {
@@ -2465,9 +2491,11 @@ static u8 run_target(char** argv, u32 ti
    is unlinked and a new one is created. Otherwise, out_fd is rewound and
    truncated. */
 
-static void write_to_testcase(void* mem, u32 len) {
+static void write_to_testcase(void* mem, u32 len, u32 oid) {
+
+  s32 fd;
 
-  s32 fd = out_fd;
+  u8* out_file = alloc_printf("%s/seed_%03u", out_file_dir, oid);
 
   if (out_file) {
 
@@ -2493,11 +2521,13 @@ static void write_to_testcase(void* mem,
 
 /* The same, but with an adjustable gap. Used for trimming. */
 
-static void write_with_gap(void* mem, u32 len, u32 skip_at, u32 skip_len) {
+static void write_with_gap(void* mem, u32 len, u32 skip_at, u32 skip_len, u32 oid) {
 
-  s32 fd = out_fd;
+  s32 fd;
   u32 tail_len = len - skip_at - skip_len;
 
+  u8* out_file = alloc_printf("%s/seed_%03u", out_file_dir, oid);
+
   if (out_file) {
 
     unlink(out_file); /* Ignore errors. */
@@ -2528,8 +2558,8 @@ static void show_stats(void);
    to warn about flaky or otherwise problematic test cases early on; and when
    new paths are discovered to detect variable behavior and so on. */
 
-static u8 calibrate_case(char** argv, struct queue_entry* q, u8* use_mem,
-                         u32 handicap, u8 from_queue) {
+static u8 calibrate_case(struct queue_entry* q, u8* use_mem,
+                         u32 handicap, u8 from_queue, u32 oid) {
 
   static u8 first_trace[MAP_SIZE];
 
@@ -2538,9 +2568,9 @@ static u8 calibrate_case(char** argv, st
 
   u64 start_us, stop_us;
 
-  s32 old_sc = stage_cur, old_sm = stage_max;
+  s32 old_sc = obj[oid].stage_cur, old_sm = obj[oid].stage_max;
   u32 use_tmout = exec_tmout;
-  u8* old_sn = stage_name;
+  u8* old_sn = obj[oid].stage_name;
 
   /* Be a bit more generous about timeouts when resuming sessions, or when
      trying to calibrate already-added finds. This helps avoid trouble due
@@ -2552,38 +2582,35 @@ static u8 calibrate_case(char** argv, st
 
   q->cal_failed++;
 
-  stage_name = "calibration";
-  stage_max  = fast_cal ? 3 : CAL_CYCLES;
+  obj[oid].stage_name = "calibration";
+  obj[oid].stage_max  = fast_cal ? 3 : CAL_CYCLES;
 
   /* Make sure the forkserver is up before we do anything, and let's not
      count its spin-up time toward binary calibration. */
 
-  if (dumb_mode != 1 && !no_forkserver && !forksrv_pid)
-    init_forkserver(argv);
-
   if (q->exec_cksum) memcpy(first_trace, trace_bits, MAP_SIZE);
 
   start_us = get_cur_time_us();
 
-  for (stage_cur = 0; stage_cur < stage_max; stage_cur++) {
+  for (obj[oid].stage_cur = 0; obj[oid].stage_cur < obj[oid].stage_max; obj[oid].stage_cur++) {
 
     u32 cksum;
 
-    if (!first_run && !(stage_cur % stats_update_freq)) show_stats();
+    if (!first_run && !(obj[oid].stage_cur % stats_update_freq)) show_stats();
 
-    write_to_testcase(use_mem, q->len);
+    write_to_testcase(use_mem, q->len, oid);
 
-    fault = run_target(argv, use_tmout);
+    fault = run_target(use_tmout, oid);
 
     /* stop_soon is set by the handler for Ctrl+C. When it's pressed,
        we want to bail out quickly. */
 
     if (stop_soon || fault != crash_mode) goto abort_calibration;
 
-    if (!dumb_mode && !stage_cur && !count_bytes(trace_bits)) {
-      fault = FAULT_NOINST;
-      goto abort_calibration;
-    }
+    // if (!dumb_mode && !obj[oid].stage_cur && !count_bytes(trace_bits)) {
+    //   fault = FAULT_NOINST;
+    //   goto abort_calibration;
+    // }
 
     cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
 
@@ -2601,7 +2628,7 @@ static u8 calibrate_case(char** argv, st
           if (!var_bytes[i] && first_trace[i] != trace_bits[i]) {
 
             var_bytes[i] = 1;
-            stage_max    = CAL_CYCLES_LONG;
+            obj[oid].stage_max    = CAL_CYCLES_LONG;
 
           }
 
@@ -2622,13 +2649,13 @@ static u8 calibrate_case(char** argv, st
 
   stop_us = get_cur_time_us();
 
-  total_cal_us     += stop_us - start_us;
-  total_cal_cycles += stage_max;
+  obj[oid].total_cal_us     += stop_us - start_us;
+  obj[oid].total_cal_cycles += obj[oid].stage_max;
 
   /* OK, let's collect some stats about the performance of this test case.
      This is used for fuzzing air time calculations in calculate_score(). */
 
-  q->exec_us     = (stop_us - start_us) / stage_max;
+  q->exec_us     = (stop_us - start_us) / obj[oid].stage_max;
   q->bitmap_size = count_bytes(trace_bits);
   q->handicap    = handicap;
   q->cal_failed  = 0;
@@ -2636,7 +2663,7 @@ static u8 calibrate_case(char** argv, st
   total_bitmap_size += q->bitmap_size;
   total_bitmap_entries++;
 
-  update_bitmap_score(q);
+  update_bitmap_score(q, oid);
 
   /* If this case didn't result in new output from the instrumentation, tell
      parent. This is a non-critical problem, but something to warn the user
@@ -2648,25 +2675,25 @@ abort_calibration:
 
   if (new_bits == 2 && !q->has_new_cov) {
     q->has_new_cov = 1;
-    queued_with_cov++;
+    obj[oid].queued_with_cov++;
   }
 
   /* Mark variable paths. */
 
   if (var_detected) {
 
-    var_byte_count = count_bytes(var_bytes);
+    obj[oid].var_byte_count = count_bytes(var_bytes);
 
     if (!q->var_behavior) {
-      mark_as_variable(q);
-      queued_variable++;
+      mark_as_variable(q, oid);
+      obj[oid].queued_variable++;
     }
 
   }
 
-  stage_name = old_sn;
-  stage_cur  = old_sc;
-  stage_max  = old_sm;
+  obj[oid].stage_name = old_sn;
+  obj[oid].stage_cur  = old_sc;
+  obj[oid].stage_max  = old_sm;
 
   if (!first_run) show_stats();
 
@@ -2674,7 +2701,6 @@ abort_calibration:
 
 }
 
-
 /* Examine map coverage. Called once, for first test case. */
 
 static void check_map_coverage(void) {
@@ -2690,13 +2716,12 @@ static void check_map_coverage(void) {
 
 }
 
-
 /* Perform dry run of all test cases to confirm that the app is working as
    expected. This is done only for the initial inputs, and only once. */
 
-static void perform_dry_run(char** argv) {
+static void perform_dry_run(u32 oid) {
 
-  struct queue_entry* q = queue;
+  struct queue_entry* q = obj[oid].queue;
   u32 cal_failures = 0;
   u8* skip_crashes = getenv("AFL_SKIP_CRASHES");
 
@@ -2708,7 +2733,7 @@ static void perform_dry_run(char** argv)
 
     u8* fn = strrchr(q->fname, '/') + 1;
 
-    ACTF("Attempting dry run with '%s'...", fn);
+    // ACTF("Attempting dry run with '%s'...", fn);
 
     fd = open(q->fname, O_RDONLY);
     if (fd < 0) PFATAL("Unable to open '%s'", q->fname);
@@ -2720,20 +2745,20 @@ static void perform_dry_run(char** argv)
 
     close(fd);
 
-    res = calibrate_case(argv, q, use_mem, 0, 1);
+    res = calibrate_case(q, use_mem, 0, 1, oid);
     ck_free(use_mem);
 
     if (stop_soon) return;
 
-    if (res == crash_mode || res == FAULT_NOBITS)
-      SAYF(cGRA "    len = %u, map size = %u, exec speed = %llu us\n" cRST, 
-           q->len, q->bitmap_size, q->exec_us);
+    // if (res == crash_mode || res == FAULT_NOBITS)
+    //   SAYF(cGRA "    len = %u, map size = %u, exec speed = %llu us\n" cRST, 
+    //        q->len, q->bitmap_size, q->exec_us);
 
     switch (res) {
 
       case FAULT_NONE:
 
-        if (q == queue) check_map_coverage();
+        if (q == obj[oid].queue) check_map_coverage();
 
         if (crash_mode) FATAL("Test case '%s' does *NOT* crash", fn);
 
@@ -2853,20 +2878,18 @@ static void perform_dry_run(char** argv)
 
       case FAULT_ERROR:
 
-        FATAL("Unable to execute target application ('%s')", argv[0]);
-
-      case FAULT_NOINST:
+        FATAL("Unable to execute target application");
 
-        FATAL("No instrumentation detected");
+      // case FAULT_NOINST:
 
-      case FAULT_NOBITS: 
+      //   FATAL("No instrumentation detected");
 
-        useless_at_start++;
+      // case FAULT_NOBITS: 
 
-        if (!in_bitmap && !shuffle_queue)
-          WARNF("No new instrumentation output, test case may be useless.");
+      //   if (!in_bitmap && !shuffle_queue)
+      //     WARNF("No new instrumentation output, test case may be useless.");
 
-        break;
+      //   break;
 
     }
 
@@ -2878,15 +2901,15 @@ static void perform_dry_run(char** argv)
 
   if (cal_failures) {
 
-    if (cal_failures == queued_paths)
+    if (cal_failures == obj[oid].queued_paths)
       FATAL("All test cases time out%s, giving up!",
             skip_crashes ? " or crash" : "");
 
     WARNF("Skipped %u test cases (%0.02f%%) due to timeouts%s.", cal_failures,
-          ((double)cal_failures) * 100 / queued_paths,
+          ((double)cal_failures) * 100 / obj[oid].queued_paths,
           skip_crashes ? " or crashes" : "");
 
-    if (cal_failures * 5 > queued_paths)
+    if (cal_failures * 5 > obj[oid].queued_paths)
       WARNF(cLRD "High percentage of rejected test cases, check settings!");
 
   }
@@ -2895,7 +2918,6 @@ static void perform_dry_run(char** argv)
 
 }
 
-
 /* Helper function: link() if possible, copy otherwise. */
 
 static void link_or_copy(u8* old_path, u8* new_path) {
@@ -2933,21 +2955,23 @@ static void nuke_resume_dir(void);
 
 static void pivot_inputs(void) {
 
-  struct queue_entry* q = queue;
-  u32 id = 0;
+  for (u32 oid = 0; oid < obj_num; oid++) {
 
-  ACTF("Creating hard links for all input files...");
+    struct queue_entry* q = obj[oid].queue;
+    u32 id = 0;
 
-  while (q) {
+    ACTF("Creating hard links for all input files...");
 
-    u8  *nfn, *rsl = strrchr(q->fname, '/');
-    u32 orig_id;
+    while (q) {
 
-    if (!rsl) rsl = q->fname; else rsl++;
+      u8  *nfn, *rsl = strrchr(q->fname, '/');
+      u32 orig_id;
 
-    /* If the original file name conforms to the syntax and the recorded
-       ID matches the one we'd assign, just use the original file name.
-       This is valuable for resuming fuzzing runs. */
+      if (!rsl) rsl = q->fname; else rsl++;
+
+      /* If the original file name conforms to the syntax and the recorded
+        ID matches the one we'd assign, just use the original file name.
+        This is valuable for resuming fuzzing runs. */
 
 #ifndef SIMPLE_FILES
 #  define CASE_PREFIX "id:"
@@ -2955,64 +2979,66 @@ static void pivot_inputs(void) {
 #  define CASE_PREFIX "id_"
 #endif /* ^!SIMPLE_FILES */
 
-    if (!strncmp(rsl, CASE_PREFIX, 3) &&
-        sscanf(rsl + 3, "%06u", &orig_id) == 1 && orig_id == id) {
+      if (!strncmp(rsl, CASE_PREFIX, 3) &&
+          sscanf(rsl + 3, "%06u", &orig_id) == 1 && orig_id == id) {
 
-      u8* src_str;
-      u32 src_id;
+        u8* src_str;
+        u32 src_id;
 
-      resuming_fuzz = 1;
-      nfn = alloc_printf("%s/queue/%s", out_dir, rsl);
+        resuming_fuzz = 1;
+        nfn = alloc_printf("%s/queue_%03u/%s", out_dir, oid, rsl);
 
-      /* Since we're at it, let's also try to find parent and figure out the
-         appropriate depth for this entry. */
+        /* Since we're at it, let's also try to find parent and figure out the
+          appropriate depth for this entry. */
 
-      src_str = strchr(rsl + 3, ':');
+        src_str = strchr(rsl + 3, ':');
 
-      if (src_str && sscanf(src_str + 1, "%06u", &src_id) == 1) {
+        if (src_str && sscanf(src_str + 1, "%06u", &src_id) == 1) {
 
-        struct queue_entry* s = queue;
-        while (src_id-- && s) s = s->next;
-        if (s) q->depth = s->depth + 1;
+          struct queue_entry* s = obj[oid].queue;
+          while (src_id-- && s) s = s->next;
+          if (s) q->depth = s->depth + 1;
 
-        if (max_depth < q->depth) max_depth = q->depth;
+          if (obj[oid].max_depth < q->depth) obj[oid].max_depth = q->depth;
 
-      }
+        }
 
-    } else {
+      } else {
 
-      /* No dice - invent a new name, capturing the original one as a
-         substring. */
+        /* No dice - invent a new name, capturing the original one as a
+          substring. */
 
 #ifndef SIMPLE_FILES
 
-      u8* use_name = strstr(rsl, ",orig:");
+        u8* use_name = strstr(rsl, ",orig:");
 
-      if (use_name) use_name += 6; else use_name = rsl;
-      nfn = alloc_printf("%s/queue/id:%06u,orig:%s", out_dir, id, use_name);
+        if (use_name) use_name += 6; else use_name = rsl;
+        nfn = alloc_printf("%s/queue_%03u/id:%06u,orig:%s", out_dir, oid, id, use_name);
 
 #else
 
-      nfn = alloc_printf("%s/queue/id_%06u", out_dir, id);
+        nfn = alloc_printf("%s/queue_%03u/id_%06u", out_dir, oid, id);
 
 #endif /* ^!SIMPLE_FILES */
 
-    }
+      }
 
-    /* Pivot to the new queue entry. */
+      /* Pivot to the new queue entry. */
 
-    link_or_copy(q->fname, nfn);
-    ck_free(q->fname);
-    q->fname = nfn;
+      link_or_copy(q->fname, nfn);
+      ck_free(q->fname);
+      q->fname = nfn;
 
-    /* Make sure that the passed_det value carries over, too. */
+      /* Make sure that the passed_det value carries over, too. */
 
-    if (q->passed_det) mark_as_det_done(q);
+      if (q->passed_det) mark_as_det_done(q, oid);
 
-    q = q->next;
-    id++;
+      q = q->next;
+      id++;
 
+    }
   }
+  
 
   if (in_place_resume) nuke_resume_dir();
 
@@ -3024,35 +3050,27 @@ static void pivot_inputs(void) {
 /* Construct a file name for a new test case, capturing the operation
    that led to its discovery. Uses a static buffer. */
 
-static u8* describe_op(u8 hnb) {
+static u8* describe_op(u8 hnb, u32 oid) {
 
   static u8 ret[256];
 
-  if (syncing_party) {
-
-    sprintf(ret, "sync:%s,src:%06u", syncing_party, syncing_case);
-
-  } else {
-
-    sprintf(ret, "src:%06u", current_entry);
+  sprintf(ret, "src:%06u", obj[oid].current_entry);
 
-    if (splicing_with >= 0)
-      sprintf(ret + strlen(ret), "+%06u", splicing_with);
+  if (obj[oid].splicing_with >= 0)
+    sprintf(ret + strlen(ret), "+%06u", obj[oid].splicing_with);
 
-    sprintf(ret + strlen(ret), ",op:%s", stage_short);
+  sprintf(ret + strlen(ret), ",op:%s", obj[oid].stage_short);
 
-    if (stage_cur_byte >= 0) {
+  if (obj[oid].stage_cur_byte >= 0) {
 
-      sprintf(ret + strlen(ret), ",pos:%u", stage_cur_byte);
+    sprintf(ret + strlen(ret), ",pos:%u", obj[oid].stage_cur_byte);
 
-      if (stage_val_type != STAGE_VAL_NONE)
-        sprintf(ret + strlen(ret), ",val:%s%+d", 
-                (stage_val_type == STAGE_VAL_BE) ? "be:" : "",
-                stage_cur_val);
+    if (obj[oid].stage_val_type != STAGE_VAL_NONE)
+      sprintf(ret + strlen(ret), ",val:%s%+d", 
+              (obj[oid].stage_val_type == STAGE_VAL_BE) ? "be:" : "",
+              obj[oid].stage_cur_val);
 
-    } else sprintf(ret + strlen(ret), ",rep:%u", stage_cur_val);
-
-  }
+  } else sprintf(ret + strlen(ret), ",rep:%u", obj[oid].stage_cur_val);
 
   if (hnb == 2) strcat(ret, ",+cov");
 
@@ -3114,7 +3132,7 @@ static void write_crash_readme(void) {
    save or queue the input test case for further analysis if so. Returns 1 if
    entry is saved, 0 otherwise. */
 
-static u8 save_if_interesting(char** argv, void* mem, u32 len, u8 fault) {
+static u8 save_if_interesting(void* mem, u32 len, u8 fault, u32 oid) {
 
   u8  *fn = "";
   u8  hnb;
@@ -3133,28 +3151,28 @@ static u8 save_if_interesting(char** arg
 
 #ifndef SIMPLE_FILES
 
-    fn = alloc_printf("%s/queue/id:%06u,%s", out_dir, queued_paths,
-                      describe_op(hnb));
+    fn = alloc_printf("%s/queue_%03u/id:%06u,%s", out_dir, oid, obj[oid].queued_paths,
+                      describe_op(hnb, oid));
 
 #else
 
-    fn = alloc_printf("%s/queue/id_%06u", out_dir, queued_paths);
+    fn = alloc_printf("%s/queue_%03u/id_%06u", out_dir, oid, obj[oid].queued_paths);
 
 #endif /* ^!SIMPLE_FILES */
 
-    add_to_queue(fn, len, 0);
+    add_to_queue(fn, len, 0, oid);
 
     if (hnb == 2) {
-      queue_top->has_new_cov = 1;
-      queued_with_cov++;
+      obj[oid].queue_top->has_new_cov = 1;
+      obj[oid].queued_with_cov++;
     }
 
-    queue_top->exec_cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
+    obj[oid].queue_top->exec_cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
 
     /* Try to calibrate inline; this also calls update_bitmap_score() when
        successful. */
 
-    res = calibrate_case(argv, queue_top, mem, queue_cycle - 1, 0);
+    res = calibrate_case(obj[oid].queue_top, mem, obj[oid].queue_cycle - 1, 0, oid);
 
     if (res == FAULT_ERROR)
       FATAL("Unable to execute target application");
@@ -3202,8 +3220,8 @@ static u8 save_if_interesting(char** arg
       if (exec_tmout < hang_tmout) {
 
         u8 new_fault;
-        write_to_testcase(mem, len);
-        new_fault = run_target(argv, hang_tmout);
+        write_to_testcase(mem, len, oid);
+        new_fault = run_target(hang_tmout, oid);
 
         /* A corner case that one user reported bumping into: increasing the
            timeout actually uncovers a crash. Make sure we don't discard it if
@@ -3218,7 +3236,7 @@ static u8 save_if_interesting(char** arg
 #ifndef SIMPLE_FILES
 
       fn = alloc_printf("%s/hangs/id:%06llu,%s", out_dir,
-                        unique_hangs, describe_op(0));
+                        unique_hangs, describe_op(0, oid));
 
 #else
 
@@ -3243,7 +3261,7 @@ keep_as_crash:
 
       total_crashes++;
 
-      if (unique_crashes >= KEEP_UNIQUE_CRASH) return keeping;
+      if (obj[oid].unique_crashes >= KEEP_UNIQUE_CRASH) return keeping;
 
       if (!dumb_mode) {
 
@@ -3257,21 +3275,21 @@ keep_as_crash:
 
       }
 
-      if (!unique_crashes) write_crash_readme();
+      if (!obj[oid].unique_crashes) write_crash_readme();
 
 #ifndef SIMPLE_FILES
 
       fn = alloc_printf("%s/crashes/id:%06llu,sig:%02u,%s", out_dir,
-                        unique_crashes, kill_signal, describe_op(0));
+                        obj[oid].unique_crashes, kill_signal, describe_op(0, oid));
 
 #else
 
-      fn = alloc_printf("%s/crashes/id_%06llu_%02u", out_dir, unique_crashes,
+      fn = alloc_printf("%s/crashes/id_%06llu_%02u", out_dir, obj[oid].unique_crashes,
                         kill_signal);
 
 #endif /* ^!SIMPLE_FILES */
 
-      unique_crashes++;
+      obj[oid].unique_crashes++;
 
       last_crash_time = get_cur_time();
       last_crash_execs = total_execs;
@@ -3298,41 +3316,6 @@ keep_as_crash:
 
 }
 
-
-/* When resuming, try to find the queue position to start from. This makes sense
-   only when resuming, and when we can find the original fuzzer_stats. */
-
-static u32 find_start_position(void) {
-
-  static u8 tmp[4096]; /* Ought to be enough for anybody. */
-
-  u8  *fn, *off;
-  s32 fd, i;
-  u32 ret;
-
-  if (!resuming_fuzz) return 0;
-
-  if (in_place_resume) fn = alloc_printf("%s/fuzzer_stats", out_dir);
-  else fn = alloc_printf("%s/../fuzzer_stats", in_dir);
-
-  fd = open(fn, O_RDONLY);
-  ck_free(fn);
-
-  if (fd < 0) return 0;
-
-  i = read(fd, tmp, sizeof(tmp) - 1); (void)i; /* Ignore errors */
-  close(fd);
-
-  off = strstr(tmp, "cur_path          : ");
-  if (!off) return 0;
-
-  ret = atoi(off + 20);
-  if (ret >= queued_paths) ret = 0;
-  return ret;
-
-}
-
-
 /* The same, but for timeouts. The idea is that when resuming sessions without
    -t given, we don't want to keep auto-scaling the timeout over and over
    again to prevent it from growing due to random flukes. */
@@ -3429,20 +3412,20 @@ static void write_stats_file(double bitm
              "exec_timeout      : %u\n"
              "afl_banner        : %s\n"
              "afl_version       : " VERSION "\n"
-             "target_mode       : %s%s%s%s%s%s%s\n"
+             "target_mode       : %s%s%s%s%s%s%s%s\n"
              "command_line      : %s\n",
              start_time / 1000, get_cur_time() / 1000, getpid(),
-             queue_cycle ? (queue_cycle - 1) : 0, total_execs, eps,
-             queued_paths, queued_favored, queued_discovered, queued_imported,
-             max_depth, current_entry, pending_favored, pending_not_fuzzed,
-             queued_variable, stability, bitmap_cvg, unique_crashes,
+             obj[0].queue_cycle ? (obj[0].queue_cycle - 1) : 0, total_execs, eps,
+             obj[0].queued_paths, obj[0].queued_favored, obj[0].queued_discovered, obj[0].queued_imported,
+             obj[0].max_depth, obj[0].current_entry, obj[0].pending_favored, obj[0].pending_not_fuzzed,
+             obj[0].queued_variable, stability, bitmap_cvg, obj[0].unique_crashes,
              unique_hangs, last_path_time / 1000, last_crash_time / 1000,
              last_hang_time / 1000, total_execs - last_crash_execs,
              exec_tmout, use_banner,
-             qemu_mode ? "qemu " : "", dumb_mode ? " dumb " : "",
+             unicorn_mode ? "unicorn" : "", qemu_mode ? "qemu " : "", dumb_mode ? " dumb " : "",
              no_forkserver ? "no_forksrv " : "", crash_mode ? "crash " : "",
              persistent_mode ? "persistent " : "", deferred_mode ? "deferred " : "",
-             (qemu_mode || dumb_mode || no_forkserver || crash_mode ||
+             (unicorn_mode || qemu_mode || dumb_mode || no_forkserver || crash_mode ||
               persistent_mode || deferred_mode) ? "" : "default",
              orig_cmdline);
              /* ignore errors */
@@ -3459,19 +3442,19 @@ static void maybe_update_plot_file(doubl
   static u32 prev_qp, prev_pf, prev_pnf, prev_ce, prev_md;
   static u64 prev_qc, prev_uc, prev_uh;
 
-  if (prev_qp == queued_paths && prev_pf == pending_favored && 
-      prev_pnf == pending_not_fuzzed && prev_ce == current_entry &&
-      prev_qc == queue_cycle && prev_uc == unique_crashes &&
-      prev_uh == unique_hangs && prev_md == max_depth) return;
-
-  prev_qp  = queued_paths;
-  prev_pf  = pending_favored;
-  prev_pnf = pending_not_fuzzed;
-  prev_ce  = current_entry;
-  prev_qc  = queue_cycle;
-  prev_uc  = unique_crashes;
+  if (prev_qp == obj[0].queued_paths && prev_pf == obj[0].pending_favored && 
+      prev_pnf == obj[0].pending_not_fuzzed && prev_ce == obj[0].current_entry &&
+      prev_qc == obj[0].queue_cycle && prev_uc == obj[0].unique_crashes &&
+      prev_uh == unique_hangs && prev_md == obj[0].max_depth) return;
+
+  prev_qp  = obj[0].queued_paths;
+  prev_pf  = obj[0].pending_favored;
+  prev_pnf = obj[0].pending_not_fuzzed;
+  prev_ce  = obj[0].current_entry;
+  prev_qc  = obj[0].queue_cycle;
+  prev_uc  = obj[0].unique_crashes;
   prev_uh  = unique_hangs;
-  prev_md  = max_depth;
+  prev_md  = obj[0].max_depth;
 
   /* Fields in the file:
 
@@ -3481,9 +3464,9 @@ static void maybe_update_plot_file(doubl
 
   fprintf(plot_file, 
           "%llu, %llu, %u, %u, %u, %u, %0.02f%%, %llu, %llu, %u, %0.02f\n",
-          get_cur_time() / 1000, queue_cycle - 1, current_entry, queued_paths,
-          pending_not_fuzzed, pending_favored, bitmap_cvg, unique_crashes,
-          unique_hangs, max_depth, eps); /* ignore errors */
+          get_cur_time() / 1000, obj[0].queue_cycle - 1, obj[0].current_entry, obj[0].queued_paths,
+          obj[0].pending_not_fuzzed, obj[0].pending_favored, bitmap_cvg, obj[0].unique_crashes,
+          unique_hangs, obj[0].max_depth, eps); /* ignore errors */
 
   fflush(plot_file);
 
@@ -3717,34 +3700,49 @@ static void maybe_delete_out_dir(void) {
 
   }
 
-  /* Next, we need to clean up <out_dir>/queue/.state/ subdirectories: */
+  DIR* d;
+  struct dirent* d_ent;
 
-  fn = alloc_printf("%s/queue/.state/deterministic_done", out_dir);
-  if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
-  ck_free(fn);
+  d = opendir(out_dir);
 
-  fn = alloc_printf("%s/queue/.state/auto_extras", out_dir);
-  if (delete_files(fn, "auto_")) goto dir_cleanup_failed;
-  ck_free(fn);
+  while ((d_ent = readdir(d))) {
 
-  fn = alloc_printf("%s/queue/.state/redundant_edges", out_dir);
-  if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
-  ck_free(fn);
+    if (strstr(d_ent->d_name, "queue")) {
 
-  fn = alloc_printf("%s/queue/.state/variable_behavior", out_dir);
-  if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
-  ck_free(fn);
+      /* Next, we need to clean up <out_dir>/queue/.state/ subdirectories: */
+
+      fn = alloc_printf("%s/%s/.state/deterministic_done", out_dir, d_ent->d_name);
+      if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
+      ck_free(fn);
 
-  /* Then, get rid of the .state subdirectory itself (should be empty by now)
-     and everything matching <out_dir>/queue/id:*. */
+      fn = alloc_printf("%s/%s/.state/auto_extras", out_dir, d_ent->d_name);
+      if (delete_files(fn, "auto_")) goto dir_cleanup_failed;
+      ck_free(fn);
 
-  fn = alloc_printf("%s/queue/.state", out_dir);
-  if (rmdir(fn) && errno != ENOENT) goto dir_cleanup_failed;
-  ck_free(fn);
+      fn = alloc_printf("%s/%s/.state/redundant_edges", out_dir, d_ent->d_name);
+      if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
+      ck_free(fn);
+
+      fn = alloc_printf("%s/%s/.state/variable_behavior", out_dir, d_ent->d_name);
+      if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
+      ck_free(fn);
+
+      /* Then, get rid of the .state subdirectory itself (should be empty by now)
+        and everything matching <out_dir>/queue/id:*. */
+
+      fn = alloc_printf("%s/%s/.state", out_dir, d_ent->d_name);
+      if (rmdir(fn) && errno != ENOENT) goto dir_cleanup_failed;
+      ck_free(fn);
+
+      fn = alloc_printf("%s/%s", out_dir, d_ent->d_name);
+      if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
+      ck_free(fn);
+
+    }
+
+  }
+  closedir(d);
 
-  fn = alloc_printf("%s/queue", out_dir);
-  if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed;
-  ck_free(fn);
 
   /* All right, let's do <out_dir>/crashes/id:* and <out_dir>/hangs/id:*. */
 
@@ -3881,6 +3879,8 @@ static void show_stats(void) {
 
   cur_ms = get_cur_time();
 
+  if (!obj[0].queue_cur) return;
+
   /* If not enough time has passed since last UI update, bail out. */
 
   if (cur_ms - last_ms < 1000 / UI_TARGET_HZ) return;
@@ -3925,7 +3925,7 @@ static void show_stats(void) {
   t_byte_ratio = ((double)t_bytes * 100) / MAP_SIZE;
 
   if (t_bytes) 
-    stab_ratio = 100 - ((double)var_byte_count) * 100 / t_bytes;
+    stab_ratio = 100 - ((double)obj[0].var_byte_count) * 100 / t_bytes;
   else
     stab_ratio = 100;
 
@@ -3951,7 +3951,7 @@ static void show_stats(void) {
 
   /* Honor AFL_EXIT_WHEN_DONE and AFL_BENCH_UNTIL_CRASH. */
 
-  if (!dumb_mode && cycles_wo_finds > 100 && !pending_not_fuzzed &&
+  if (!dumb_mode && obj[0].cycles_wo_finds > 100 && !obj[0].pending_not_fuzzed &&
       getenv("AFL_EXIT_WHEN_DONE")) stop_soon = 2;
 
   if (total_crashes && getenv("AFL_BENCH_UNTIL_CRASH")) stop_soon = 2;
@@ -4024,13 +4024,13 @@ static void show_stats(void) {
     u64 min_wo_finds = (cur_ms - last_path_time) / 1000 / 60;
 
     /* First queue cycle: don't stop now! */
-    if (queue_cycle == 1 || min_wo_finds < 15) strcpy(tmp, cMGN); else
+    if (obj[0].queue_cycle == 1 || min_wo_finds < 15) strcpy(tmp, cMGN); else
 
     /* Subsequent cycles, but we're still making finds. */
-    if (cycles_wo_finds < 25 || min_wo_finds < 30) strcpy(tmp, cYEL); else
+    if (obj[0].cycles_wo_finds < 25 || min_wo_finds < 30) strcpy(tmp, cYEL); else
 
     /* No finds for a long time and no test cases to try. */
-    if (cycles_wo_finds > 100 && !pending_not_fuzzed && min_wo_finds > 120)
+    if (obj[0].cycles_wo_finds > 100 && !obj[0].pending_not_fuzzed && min_wo_finds > 120)
       strcpy(tmp, cLGN);
 
     /* Default: cautiously OK to stop? */
@@ -4040,12 +4040,12 @@ static void show_stats(void) {
 
   SAYF(bV bSTOP "        run time : " cRST "%-34s " bSTG bV bSTOP
        "  cycles done : %s%-5s  " bSTG bV "\n",
-       DTD(cur_ms, start_time), tmp, DI(queue_cycle - 1));
+       DTD(cur_ms, start_time), tmp, DI(obj[0].queue_cycle - 1));
 
   /* We want to warn people about not seeing new paths after a full cycle,
      except when resuming fuzzing or running in non-instrumented mode. */
 
-  if (!dumb_mode && (last_path_time || resuming_fuzz || queue_cycle == 1 ||
+  if (!dumb_mode && (last_path_time || resuming_fuzz || obj[0].queue_cycle == 1 ||
       in_bitmap || crash_mode)) {
 
     SAYF(bV bSTOP "   last new path : " cRST "%-34s ",
@@ -4066,17 +4066,17 @@ static void show_stats(void) {
   }
 
   SAYF(bSTG bV bSTOP "  total paths : " cRST "%-5s  " bSTG bV "\n",
-       DI(queued_paths));
+       DI(obj[0].queued_paths));
 
   /* Highlight crashes in red if found, denote going over the KEEP_UNIQUE_CRASH
      limit with a '+' appended to the count. */
 
-  sprintf(tmp, "%s%s", DI(unique_crashes),
-          (unique_crashes >= KEEP_UNIQUE_CRASH) ? "+" : "");
+  sprintf(tmp, "%s%s", DI(obj[0].unique_crashes),
+          (obj[0].unique_crashes >= KEEP_UNIQUE_CRASH) ? "+" : "");
 
   SAYF(bV bSTOP " last uniq crash : " cRST "%-34s " bSTG bV bSTOP
        " uniq crashes : %s%-6s " bSTG bV "\n",
-       DTD(cur_ms, last_crash_time), unique_crashes ? cLRD : cRST,
+       DTD(cur_ms, last_crash_time), obj[0].unique_crashes ? cLRD : cRST,
        tmp);
 
   sprintf(tmp, "%s%s", DI(unique_hangs),
@@ -4093,20 +4093,20 @@ static void show_stats(void) {
      together, but then cram them into a fixed-width field - so we need to
      put them in a temporary buffer first. */
 
-  sprintf(tmp, "%s%s (%0.02f%%)", DI(current_entry),
-          queue_cur->favored ? "" : "*",
-          ((double)current_entry * 100) / queued_paths);
+  sprintf(tmp, "%s%s (%0.02f%%)", DI(obj[0].current_entry),
+          obj[0].queue_cur->favored ? "" : "*",
+          ((double)obj[0].current_entry * 100) / obj[0].queued_paths);
 
   SAYF(bV bSTOP "  now processing : " cRST "%-17s " bSTG bV bSTOP, tmp);
 
-  sprintf(tmp, "%0.02f%% / %0.02f%%", ((double)queue_cur->bitmap_size) * 
+  sprintf(tmp, "%0.02f%% / %0.02f%%", ((double)obj[0].queue_cur->bitmap_size) * 
           100 / MAP_SIZE, t_byte_ratio);
 
   SAYF("    map density : %s%-21s " bSTG bV "\n", t_byte_ratio > 70 ? cLRD : 
        ((t_bytes < 200 && !dumb_mode) ? cPIN : cRST), tmp);
 
-  sprintf(tmp, "%s (%0.02f%%)", DI(cur_skipped_paths),
-          ((double)cur_skipped_paths * 100) / queued_paths);
+  sprintf(tmp, "%s (%0.02f%%)", DI(obj[0].cur_skipped_paths),
+          ((double)obj[0].cur_skipped_paths * 100) / obj[0].queued_paths);
 
   SAYF(bV bSTOP " paths timed out : " cRST "%-17s " bSTG bV, tmp);
 
@@ -4118,46 +4118,46 @@ static void show_stats(void) {
   SAYF(bVR bH bSTOP cCYA " stage progress " bSTG bH20 bX bH bSTOP cCYA
        " findings in depth " bSTG bH20 bVL "\n");
 
-  sprintf(tmp, "%s (%0.02f%%)", DI(queued_favored),
-          ((double)queued_favored) * 100 / queued_paths);
+  sprintf(tmp, "%s (%0.02f%%)", DI(obj[0].queued_favored),
+          ((double)obj[0].queued_favored) * 100 / obj[0].queued_paths);
 
   /* Yeah... it's still going on... halp? */
 
   SAYF(bV bSTOP "  now trying : " cRST "%-21s " bSTG bV bSTOP 
-       " favored paths : " cRST "%-22s " bSTG bV "\n", stage_name, tmp);
+       " favored paths : " cRST "%-22s " bSTG bV "\n", obj[0].stage_name, tmp);
 
-  if (!stage_max) {
+  if (!obj[0].stage_max) {
 
-    sprintf(tmp, "%s/-", DI(stage_cur));
+    sprintf(tmp, "%s/-", DI(obj[0].stage_cur));
 
   } else {
 
-    sprintf(tmp, "%s/%s (%0.02f%%)", DI(stage_cur), DI(stage_max),
-            ((double)stage_cur) * 100 / stage_max);
+    sprintf(tmp, "%s/%s (%0.02f%%)", DI(obj[0].stage_cur), DI(obj[0].stage_max),
+            ((double)obj[0].stage_cur) * 100 / obj[0].stage_max);
 
   }
 
   SAYF(bV bSTOP " stage execs : " cRST "%-21s " bSTG bV bSTOP, tmp);
 
-  sprintf(tmp, "%s (%0.02f%%)", DI(queued_with_cov),
-          ((double)queued_with_cov) * 100 / queued_paths);
+  sprintf(tmp, "%s (%0.02f%%)", DI(obj[0].queued_with_cov),
+          ((double)obj[0].queued_with_cov) * 100 / obj[0].queued_paths);
 
   SAYF("  new edges on : " cRST "%-22s " bSTG bV "\n", tmp);
 
-  sprintf(tmp, "%s (%s%s unique)", DI(total_crashes), DI(unique_crashes),
-          (unique_crashes >= KEEP_UNIQUE_CRASH) ? "+" : "");
+  sprintf(tmp, "%s (%s%s unique)", DI(total_crashes), DI(obj[0].unique_crashes),
+          (obj[0].unique_crashes >= KEEP_UNIQUE_CRASH) ? "+" : "");
 
   if (crash_mode) {
 
     SAYF(bV bSTOP " total execs : " cRST "%-21s " bSTG bV bSTOP
          "   new crashes : %s%-22s " bSTG bV "\n", DI(total_execs),
-         unique_crashes ? cLRD : cRST, tmp);
+         obj[0].unique_crashes ? cLRD : cRST, tmp);
 
   } else {
 
     SAYF(bV bSTOP " total execs : " cRST "%-21s " bSTG bV bSTOP
          " total crashes : %s%-22s " bSTG bV "\n", DI(total_execs),
-         unique_crashes ? cLRD : cRST, tmp);
+         obj[0].unique_crashes ? cLRD : cRST, tmp);
 
   }
 
@@ -4194,63 +4194,63 @@ static void show_stats(void) {
   } else {
 
     sprintf(tmp, "%s/%s, %s/%s, %s/%s",
-            DI(stage_finds[STAGE_FLIP1]), DI(stage_cycles[STAGE_FLIP1]),
-            DI(stage_finds[STAGE_FLIP2]), DI(stage_cycles[STAGE_FLIP2]),
-            DI(stage_finds[STAGE_FLIP4]), DI(stage_cycles[STAGE_FLIP4]));
+            DI(obj[0].stage_finds[STAGE_FLIP1]), DI(obj[0].stage_cycles[STAGE_FLIP1]),
+            DI(obj[0].stage_finds[STAGE_FLIP2]), DI(obj[0].stage_cycles[STAGE_FLIP2]),
+            DI(obj[0].stage_finds[STAGE_FLIP4]), DI(obj[0].stage_cycles[STAGE_FLIP4]));
 
   }
 
   SAYF(bV bSTOP "   bit flips : " cRST "%-37s " bSTG bV bSTOP "    levels : "
-       cRST "%-10s " bSTG bV "\n", tmp, DI(max_depth));
+       cRST "%-10s " bSTG bV "\n", tmp, DI(obj[0].max_depth));
 
   if (!skip_deterministic)
     sprintf(tmp, "%s/%s, %s/%s, %s/%s",
-            DI(stage_finds[STAGE_FLIP8]), DI(stage_cycles[STAGE_FLIP8]),
-            DI(stage_finds[STAGE_FLIP16]), DI(stage_cycles[STAGE_FLIP16]),
-            DI(stage_finds[STAGE_FLIP32]), DI(stage_cycles[STAGE_FLIP32]));
+            DI(obj[0].stage_finds[STAGE_FLIP8]), DI(obj[0].stage_cycles[STAGE_FLIP8]),
+            DI(obj[0].stage_finds[STAGE_FLIP16]), DI(obj[0].stage_cycles[STAGE_FLIP16]),
+            DI(obj[0].stage_finds[STAGE_FLIP32]), DI(obj[0].stage_cycles[STAGE_FLIP32]));
 
   SAYF(bV bSTOP "  byte flips : " cRST "%-37s " bSTG bV bSTOP "   pending : "
-       cRST "%-10s " bSTG bV "\n", tmp, DI(pending_not_fuzzed));
+       cRST "%-10s " bSTG bV "\n", tmp, DI(obj[0].pending_not_fuzzed));
 
   if (!skip_deterministic)
     sprintf(tmp, "%s/%s, %s/%s, %s/%s",
-            DI(stage_finds[STAGE_ARITH8]), DI(stage_cycles[STAGE_ARITH8]),
-            DI(stage_finds[STAGE_ARITH16]), DI(stage_cycles[STAGE_ARITH16]),
-            DI(stage_finds[STAGE_ARITH32]), DI(stage_cycles[STAGE_ARITH32]));
+            DI(obj[0].stage_finds[STAGE_ARITH8]), DI(obj[0].stage_cycles[STAGE_ARITH8]),
+            DI(obj[0].stage_finds[STAGE_ARITH16]), DI(obj[0].stage_cycles[STAGE_ARITH16]),
+            DI(obj[0].stage_finds[STAGE_ARITH32]), DI(obj[0].stage_cycles[STAGE_ARITH32]));
 
   SAYF(bV bSTOP " arithmetics : " cRST "%-37s " bSTG bV bSTOP "  pend fav : "
-       cRST "%-10s " bSTG bV "\n", tmp, DI(pending_favored));
+       cRST "%-10s " bSTG bV "\n", tmp, DI(obj[0].pending_favored));
 
   if (!skip_deterministic)
     sprintf(tmp, "%s/%s, %s/%s, %s/%s",
-            DI(stage_finds[STAGE_INTEREST8]), DI(stage_cycles[STAGE_INTEREST8]),
-            DI(stage_finds[STAGE_INTEREST16]), DI(stage_cycles[STAGE_INTEREST16]),
-            DI(stage_finds[STAGE_INTEREST32]), DI(stage_cycles[STAGE_INTEREST32]));
+            DI(obj[0].stage_finds[STAGE_INTEREST8]), DI(obj[0].stage_cycles[STAGE_INTEREST8]),
+            DI(obj[0].stage_finds[STAGE_INTEREST16]), DI(obj[0].stage_cycles[STAGE_INTEREST16]),
+            DI(obj[0].stage_finds[STAGE_INTEREST32]), DI(obj[0].stage_cycles[STAGE_INTEREST32]));
 
   SAYF(bV bSTOP "  known ints : " cRST "%-37s " bSTG bV bSTOP " own finds : "
-       cRST "%-10s " bSTG bV "\n", tmp, DI(queued_discovered));
+       cRST "%-10s " bSTG bV "\n", tmp, DI(obj[0].queued_discovered));
 
   if (!skip_deterministic)
     sprintf(tmp, "%s/%s, %s/%s, %s/%s",
-            DI(stage_finds[STAGE_EXTRAS_UO]), DI(stage_cycles[STAGE_EXTRAS_UO]),
-            DI(stage_finds[STAGE_EXTRAS_UI]), DI(stage_cycles[STAGE_EXTRAS_UI]),
-            DI(stage_finds[STAGE_EXTRAS_AO]), DI(stage_cycles[STAGE_EXTRAS_AO]));
+            DI(obj[0].stage_finds[STAGE_EXTRAS_UO]), DI(obj[0].stage_cycles[STAGE_EXTRAS_UO]),
+            DI(obj[0].stage_finds[STAGE_EXTRAS_UI]), DI(obj[0].stage_cycles[STAGE_EXTRAS_UI]),
+            DI(obj[0].stage_finds[STAGE_EXTRAS_AO]), DI(obj[0].stage_cycles[STAGE_EXTRAS_AO]));
 
   SAYF(bV bSTOP "  dictionary : " cRST "%-37s " bSTG bV bSTOP
        "  imported : " cRST "%-10s " bSTG bV "\n", tmp,
-       sync_id ? DI(queued_imported) : (u8*)"n/a");
+       sync_id ? DI(obj[0].queued_imported) : (u8*)"n/a");
 
   sprintf(tmp, "%s/%s, %s/%s",
-          DI(stage_finds[STAGE_HAVOC]), DI(stage_cycles[STAGE_HAVOC]),
-          DI(stage_finds[STAGE_SPLICE]), DI(stage_cycles[STAGE_SPLICE]));
+          DI(obj[0].stage_finds[STAGE_HAVOC]), DI(obj[0].stage_cycles[STAGE_HAVOC]),
+          DI(obj[0].stage_finds[STAGE_SPLICE]), DI(obj[0].stage_cycles[STAGE_SPLICE]));
 
   SAYF(bV bSTOP "       havoc : " cRST "%-37s " bSTG bV bSTOP, tmp);
 
   if (t_bytes) sprintf(tmp, "%0.02f%%", stab_ratio);
     else strcpy(tmp, "n/a");
 
-  SAYF(" stability : %s%-10s " bSTG bV "\n", (stab_ratio < 85 && var_byte_count > 40) 
-       ? cLRD : ((queued_variable && (!persistent_mode || var_byte_count > 20))
+  SAYF(" stability : %s%-10s " bSTG bV "\n", (stab_ratio < 85 && obj[0].var_byte_count > 40) 
+       ? cLRD : ((obj[0].queued_variable && (!persistent_mode || obj[0].var_byte_count > 20))
        ? cMGN : cRST), tmp);
 
   if (!bytes_trim_out) {
@@ -4342,13 +4342,13 @@ static void show_stats(void) {
 
 static void show_init_stats(void) {
 
-  struct queue_entry* q = queue;
+  struct queue_entry* q = obj[0].queue;
   u32 min_bits = 0, max_bits = 0;
   u64 min_us = 0, max_us = 0;
   u64 avg_us = 0;
   u32 max_len = 0;
 
-  if (total_cal_cycles) avg_us = total_cal_us / total_cal_cycles;
+  if (obj[0].total_cal_cycles) avg_us = obj[0].total_cal_us / obj[0].total_cal_cycles;
 
   while (q) {
 
@@ -4366,15 +4366,15 @@ static void show_init_stats(void) {
 
   SAYF("\n");
 
-  if (avg_us > (qemu_mode ? 50000 : 10000)) 
+  if (avg_us > ((qemu_mode || unicorn_mode) ? 50000 : 10000)) 
     WARNF(cLRD "The target binary is pretty slow! See %s/perf_tips.txt.",
           doc_path);
 
   /* Let's keep things moving with slow binaries. */
 
-  if (avg_us > 50000) havoc_div = 10;     /* 0-19 execs/sec   */
-  else if (avg_us > 20000) havoc_div = 5; /* 20-49 execs/sec  */
-  else if (avg_us > 10000) havoc_div = 2; /* 50-100 execs/sec */
+  if (avg_us > 50000) obj[0].havoc_div = 10;     /* 0-19 execs/sec   */
+  else if (avg_us > 20000) obj[0].havoc_div = 5; /* 20-49 execs/sec  */
+  else if (avg_us > 10000) obj[0].havoc_div = 2; /* 50-100 execs/sec */
 
   if (!resuming_fuzz) {
 
@@ -4385,12 +4385,9 @@ static void show_init_stats(void) {
       WARNF("Some test cases are big (%s) - see %s/perf_tips.txt.",
             DMS(max_len), doc_path);
 
-    if (useless_at_start && !in_bitmap)
-      WARNF(cLRD "Some test cases look useless. Consider using a smaller set.");
-
-    if (queued_paths > 100)
+    if (obj[0].queued_paths > 100)
       WARNF(cLRD "You probably have far too many input files! Consider trimming down.");
-    else if (queued_paths > 20)
+    else if (obj[0].queued_paths > 20)
       WARNF("You have lots of input files; try starting small.");
 
   }
@@ -4400,7 +4397,7 @@ static void show_init_stats(void) {
       cGRA "    Test case count : " cRST "%u favored, %u variable, %u total\n"
       cGRA "       Bitmap range : " cRST "%u to %u bits (average: %0.02f bits)\n"
       cGRA "        Exec timing : " cRST "%s to %s us (average: %s us)\n",
-      queued_favored, queued_variable, queued_paths, min_bits, max_bits, 
+      obj[0].queued_favored, obj[0].queued_variable, obj[0].queued_paths, min_bits, max_bits, 
       ((double)total_bitmap_size) / (total_bitmap_entries ? total_bitmap_entries : 1),
       DI(min_us), DI(max_us), DI(avg_us));
 
@@ -4460,7 +4457,7 @@ static u32 next_p2(u32 val) {
    trimmer uses power-of-two increments somewhere between 1/16 and 1/1024 of
    file size, to keep the stage short and sweet. */
 
-static u8 trim_case(char** argv, struct queue_entry* q, u8* in_buf) {
+static u8 trim_case(struct queue_entry* q, u8* in_buf, u32 oid) {
 
   static u8 tmp[64];
   static u8 clean_trace[MAP_SIZE];
@@ -4476,7 +4473,7 @@ static u8 trim_case(char** argv, struct
 
   if (q->len < 5) return 0;
 
-  stage_name = tmp;
+  obj[oid].stage_name = tmp;
   bytes_trim_in += q->len;
 
   /* Select initial chunk len, starting with large steps. */
@@ -4494,17 +4491,17 @@ static u8 trim_case(char** argv, struct
 
     sprintf(tmp, "trim %s/%s", DI(remove_len), DI(remove_len));
 
-    stage_cur = 0;
-    stage_max = q->len / remove_len;
+    obj[oid].stage_cur = 0;
+    obj[oid].stage_max = q->len / remove_len;
 
     while (remove_pos < q->len) {
 
       u32 trim_avail = MIN(remove_len, q->len - remove_pos);
       u32 cksum;
 
-      write_with_gap(in_buf, q->len, remove_pos, trim_avail);
+      write_with_gap(in_buf, q->len, remove_pos, trim_avail, oid);
 
-      fault = run_target(argv, exec_tmout);
+      fault = run_target(exec_tmout, oid);
       trim_execs++;
 
       if (stop_soon || fault == FAULT_ERROR) goto abort_trimming;
@@ -4543,7 +4540,7 @@ static u8 trim_case(char** argv, struct
       /* Since this can be slow, update the screen every now and then. */
 
       if (!(trim_exec++ % stats_update_freq)) show_stats();
-      stage_cur++;
+      obj[oid].stage_cur++;
 
     }
 
@@ -4568,7 +4565,7 @@ static u8 trim_case(char** argv, struct
     close(fd);
 
     memcpy(trace_bits, clean_trace, MAP_SIZE);
-    update_bitmap_score(q);
+    update_bitmap_score(q, oid);
 
   }
 
@@ -4584,7 +4581,7 @@ abort_trimming:
    error conditions, returning 1 if it's time to bail out. This is
    a helper function for fuzz_one(). */
 
-EXP_ST u8 common_fuzz_stuff(char** argv, u8* out_buf, u32 len) {
+EXP_ST u8 common_fuzz_stuff(u8* out_buf, u32 len, u32 oid) {
 
   u8 fault;
 
@@ -4595,16 +4592,16 @@ EXP_ST u8 common_fuzz_stuff(char** argv,
 
   }
 
-  write_to_testcase(out_buf, len);
+  write_to_testcase(out_buf, len, oid);
 
-  fault = run_target(argv, exec_tmout);
+  fault = run_target(exec_tmout, oid);
 
   if (stop_soon) return 1;
 
   if (fault == FAULT_TMOUT) {
 
     if (subseq_tmouts++ > TMOUT_LIMIT) {
-      cur_skipped_paths++;
+      obj[oid].cur_skipped_paths++;
       return 1;
     }
 
@@ -4616,16 +4613,16 @@ EXP_ST u8 common_fuzz_stuff(char** argv,
   if (skip_requested) {
 
      skip_requested = 0;
-     cur_skipped_paths++;
+     obj[oid].cur_skipped_paths++;
      return 1;
 
   }
 
   /* This handles FAULT_ERROR for us: */
 
-  queued_discovered += save_if_interesting(argv, out_buf, len, fault);
+  obj[oid].queued_discovered += save_if_interesting(out_buf, len, fault, oid);
 
-  if (!(stage_cur % stats_update_freq) || stage_cur + 1 == stage_max)
+  if (!(obj[oid].stage_cur % stats_update_freq) || obj[oid].stage_cur + 1 == obj[oid].stage_max)
     show_stats();
 
   return 0;
@@ -4636,10 +4633,10 @@ EXP_ST u8 common_fuzz_stuff(char** argv,
 /* Helper to choose random block len for block operations in fuzz_one().
    Doesn't return zero, provided that max_len is > 0. */
 
-static u32 choose_block_len(u32 limit) {
+static u32 choose_block_len(u32 limit, u32 oid) {
 
   u32 min_value, max_value;
-  u32 rlim = MIN(queue_cycle, 3);
+  u32 rlim = MIN(obj[oid].queue_cycle, 3);
 
   if (!run_over10m) rlim = 1;
 
@@ -4680,9 +4677,9 @@ static u32 choose_block_len(u32 limit) {
    A helper function for fuzz_one(). Maybe some of these constants should
    go into config.h. */
 
-static u32 calculate_score(struct queue_entry* q) {
+static u32 calculate_score(struct queue_entry* q, u32 oid) {
 
-  u32 avg_exec_us = total_cal_us / total_cal_cycles;
+  u32 avg_exec_us = obj[oid].total_cal_us / obj[oid].total_cal_cycles;
   u32 avg_bitmap_size = total_bitmap_size / total_bitmap_entries;
   u32 perf_score = 100;
 
@@ -4937,7 +4934,7 @@ static u8 could_be_interest(u32 old_val,
    function is a tad too long... returns 0 if fuzzed successfully, 1 if
    skipped or bailed out. */
 
-static u8 fuzz_one(char** argv) {
+static u8 fuzz_one(u32 oid) {
 
   s32 len, fd, temp_len, i, j;
   u8  *in_buf, *out_buf, *orig_in, *ex_tmp, *eff_map = 0;
@@ -4954,26 +4951,26 @@ static u8 fuzz_one(char** argv) {
   /* In IGNORE_FINDS mode, skip any entries that weren't in the
      initial data set. */
 
-  if (queue_cur->depth > 1) return 1;
+  if (obj[oid].queue_cur->depth > 1) return 1;
 
 #else
 
-  if (pending_favored) {
+  if (obj[oid].pending_favored) {
 
     /* If we have any favored, non-fuzzed new arrivals in the queue,
        possibly skip to them at the expense of already-fuzzed or non-favored
        cases. */
 
-    if ((queue_cur->was_fuzzed || !queue_cur->favored) &&
+    if ((obj[oid].queue_cur->was_fuzzed || !obj[oid].queue_cur->favored) &&
         UR(100) < SKIP_TO_NEW_PROB) return 1;
 
-  } else if (!dumb_mode && !queue_cur->favored && queued_paths > 10) {
+  } else if (!dumb_mode && !obj[oid].queue_cur->favored && obj[oid].queued_paths > 10) {
 
     /* Otherwise, still possibly skip non-favored cases, albeit less often.
        The odds of skipping stuff are higher for already-fuzzed inputs and
        lower for never-fuzzed entries. */
 
-    if (queue_cycle > 1 && !queue_cur->was_fuzzed) {
+    if (obj[oid].queue_cycle > 1 && !obj[oid].queue_cur->was_fuzzed) {
 
       if (UR(100) < SKIP_NFAV_NEW_PROB) return 1;
 
@@ -4989,21 +4986,21 @@ static u8 fuzz_one(char** argv) {
 
   if (not_on_tty) {
     ACTF("Fuzzing test case #%u (%u total, %llu uniq crashes found)...",
-         current_entry, queued_paths, unique_crashes);
+         obj[oid].current_entry, obj[oid].queued_paths, obj[oid].unique_crashes);
     fflush(stdout);
   }
 
   /* Map the test case into memory. */
 
-  fd = open(queue_cur->fname, O_RDONLY);
+  fd = open(obj[oid].queue_cur->fname, O_RDONLY);
 
-  if (fd < 0) PFATAL("Unable to open '%s'", queue_cur->fname);
+  if (fd < 0) PFATAL("Unable to open '%s'", obj[oid].queue_cur->fname);
 
-  len = queue_cur->len;
+  len = obj[oid].queue_cur->len;
 
   orig_in = in_buf = mmap(0, len, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0);
 
-  if (orig_in == MAP_FAILED) PFATAL("Unable to mmap '%s'", queue_cur->fname);
+  if (orig_in == MAP_FAILED) PFATAL("Unable to mmap '%s'", obj[oid].queue_cur->fname);
 
   close(fd);
 
@@ -5015,19 +5012,19 @@ static u8 fuzz_one(char** argv) {
 
   subseq_tmouts = 0;
 
-  cur_depth = queue_cur->depth;
+  obj[oid].cur_depth = obj[oid].queue_cur->depth;
 
   /*******************************************
    * CALIBRATION (only if failed earlier on) *
    *******************************************/
 
-  if (queue_cur->cal_failed) {
+  if (obj[oid].queue_cur->cal_failed) {
 
     u8 res = FAULT_TMOUT;
 
-    if (queue_cur->cal_failed < CAL_CHANCES) {
+    if (obj[oid].queue_cur->cal_failed < CAL_CHANCES) {
 
-      res = calibrate_case(argv, queue_cur, in_buf, queue_cycle - 1, 0);
+      res = calibrate_case(obj[oid].queue_cur, in_buf, obj[oid].queue_cycle - 1, 0, oid);
 
       if (res == FAULT_ERROR)
         FATAL("Unable to execute target application");
@@ -5035,7 +5032,7 @@ static u8 fuzz_one(char** argv) {
     }
 
     if (stop_soon || res != crash_mode) {
-      cur_skipped_paths++;
+      obj[oid].cur_skipped_paths++;
       goto abandon_entry;
     }
 
@@ -5045,23 +5042,23 @@ static u8 fuzz_one(char** argv) {
    * TRIMMING *
    ************/
 
-  if (!dumb_mode && !queue_cur->trim_done) {
+  if (!dumb_mode && !obj[oid].queue_cur->trim_done) {
 
-    u8 res = trim_case(argv, queue_cur, in_buf);
+    u8 res = trim_case(obj[oid].queue_cur, in_buf, oid);
 
     if (res == FAULT_ERROR)
       FATAL("Unable to execute target application");
 
     if (stop_soon) {
-      cur_skipped_paths++;
+      obj[oid].cur_skipped_paths++;
       goto abandon_entry;
     }
 
     /* Don't retry trimming, even if it failed. */
 
-    queue_cur->trim_done = 1;
+    obj[oid].queue_cur->trim_done = 1;
 
-    if (len != queue_cur->len) len = queue_cur->len;
+    if (len != obj[oid].queue_cur->len) len = obj[oid].queue_cur->len;
 
   }
 
@@ -5071,19 +5068,13 @@ static u8 fuzz_one(char** argv) {
    * PERFORMANCE SCORE *
    *********************/
 
-  orig_perf = perf_score = calculate_score(queue_cur);
+  orig_perf = perf_score = calculate_score(obj[oid].queue_cur, oid);
 
   /* Skip right away if -d is given, if we have done deterministic fuzzing on
      this entry ourselves (was_fuzzed), or if it has gone through deterministic
      testing in earlier, resumed runs (passed_det). */
 
-  if (skip_deterministic || queue_cur->was_fuzzed || queue_cur->passed_det)
-    goto havoc_stage;
-
-  /* Skip deterministic fuzzing if exec path checksum puts this out of scope
-     for this master instance. */
-
-  if (master_max && (queue_cur->exec_cksum % master_max) != master_id - 1)
+  if (skip_deterministic || obj[oid].queue_cur->was_fuzzed || obj[oid].queue_cur->passed_det)
     goto havoc_stage;
 
   doing_det = 1;
@@ -5100,25 +5091,25 @@ static u8 fuzz_one(char** argv) {
 
   /* Single walking bit. */
 
-  stage_short = "flip1";
-  stage_max   = len << 3;
-  stage_name  = "bitflip 1/1";
+  obj[oid].stage_short = "flip1";
+  obj[oid].stage_max   = len << 3;
+  obj[oid].stage_name  = "bitflip 1/1";
 
-  stage_val_type = STAGE_VAL_NONE;
+  obj[oid].stage_val_type = STAGE_VAL_NONE;
 
-  orig_hit_cnt = queued_paths + unique_crashes;
+  orig_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  prev_cksum = queue_cur->exec_cksum;
+  prev_cksum = obj[oid].queue_cur->exec_cksum;
 
-  for (stage_cur = 0; stage_cur < stage_max; stage_cur++) {
+  for (obj[oid].stage_cur = 0; obj[oid].stage_cur < obj[oid].stage_max; obj[oid].stage_cur++) {
 
-    stage_cur_byte = stage_cur >> 3;
+    obj[oid].stage_cur_byte = obj[oid].stage_cur >> 3;
 
-    FLIP_BIT(out_buf, stage_cur);
+    FLIP_BIT(out_buf, obj[oid].stage_cur);
 
-    if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+    if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
-    FLIP_BIT(out_buf, stage_cur);
+    FLIP_BIT(out_buf, obj[oid].stage_cur);
 
     /* While flipping the least significant bit in every byte, pull of an extra
        trick to detect possible syntax tokens. In essence, the idea is that if
@@ -5147,16 +5138,16 @@ static u8 fuzz_one(char** argv) {
 
       */
 
-    if (!dumb_mode && (stage_cur & 7) == 7) {
+    if (!dumb_mode && (obj[oid].stage_cur & 7) == 7) {
 
       u32 cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
 
-      if (stage_cur == stage_max - 1 && cksum == prev_cksum) {
+      if (obj[oid].stage_cur == obj[oid].stage_max - 1 && cksum == prev_cksum) {
 
         /* If at end of file and we are still collecting a string, grab the
            final character and force output. */
 
-        if (a_len < MAX_AUTO_EXTRA) a_collect[a_len] = out_buf[stage_cur >> 3];
+        if (a_len < MAX_AUTO_EXTRA) a_collect[a_len] = out_buf[obj[oid].stage_cur >> 3];
         a_len++;
 
         if (a_len >= MIN_AUTO_EXTRA && a_len <= MAX_AUTO_EXTRA)
@@ -5178,9 +5169,9 @@ static u8 fuzz_one(char** argv) {
       /* Continue collecting string, but only if the bit flip actually made
          any difference - we don't want no-op tokens. */
 
-      if (cksum != queue_cur->exec_cksum) {
+      if (cksum != obj[oid].queue_cur->exec_cksum) {
 
-        if (a_len < MAX_AUTO_EXTRA) a_collect[a_len] = out_buf[stage_cur >> 3];        
+        if (a_len < MAX_AUTO_EXTRA) a_collect[a_len] = out_buf[obj[oid].stage_cur >> 3];        
         a_len++;
 
       }
@@ -5189,68 +5180,68 @@ static u8 fuzz_one(char** argv) {
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_FLIP1]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_FLIP1] += stage_max;
+  obj[oid].stage_finds[STAGE_FLIP1]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_FLIP1] += obj[oid].stage_max;
 
   /* Two walking bits. */
 
-  stage_name  = "bitflip 2/1";
-  stage_short = "flip2";
-  stage_max   = (len << 3) - 1;
+  obj[oid].stage_name  = "bitflip 2/1";
+  obj[oid].stage_short = "flip2";
+  obj[oid].stage_max   = (len << 3) - 1;
 
   orig_hit_cnt = new_hit_cnt;
 
-  for (stage_cur = 0; stage_cur < stage_max; stage_cur++) {
+  for (obj[oid].stage_cur = 0; obj[oid].stage_cur < obj[oid].stage_max; obj[oid].stage_cur++) {
 
-    stage_cur_byte = stage_cur >> 3;
+    obj[oid].stage_cur_byte = obj[oid].stage_cur >> 3;
 
-    FLIP_BIT(out_buf, stage_cur);
-    FLIP_BIT(out_buf, stage_cur + 1);
+    FLIP_BIT(out_buf, obj[oid].stage_cur);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 1);
 
-    if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+    if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
-    FLIP_BIT(out_buf, stage_cur);
-    FLIP_BIT(out_buf, stage_cur + 1);
+    FLIP_BIT(out_buf, obj[oid].stage_cur);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 1);
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_FLIP2]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_FLIP2] += stage_max;
+  obj[oid].stage_finds[STAGE_FLIP2]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_FLIP2] += obj[oid].stage_max;
 
   /* Four walking bits. */
 
-  stage_name  = "bitflip 4/1";
-  stage_short = "flip4";
-  stage_max   = (len << 3) - 3;
+  obj[oid].stage_name  = "bitflip 4/1";
+  obj[oid].stage_short = "flip4";
+  obj[oid].stage_max   = (len << 3) - 3;
 
   orig_hit_cnt = new_hit_cnt;
 
-  for (stage_cur = 0; stage_cur < stage_max; stage_cur++) {
+  for (obj[oid].stage_cur = 0; obj[oid].stage_cur < obj[oid].stage_max; obj[oid].stage_cur++) {
 
-    stage_cur_byte = stage_cur >> 3;
+    obj[oid].stage_cur_byte = obj[oid].stage_cur >> 3;
 
-    FLIP_BIT(out_buf, stage_cur);
-    FLIP_BIT(out_buf, stage_cur + 1);
-    FLIP_BIT(out_buf, stage_cur + 2);
-    FLIP_BIT(out_buf, stage_cur + 3);
+    FLIP_BIT(out_buf, obj[oid].stage_cur);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 1);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 2);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 3);
 
-    if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+    if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
-    FLIP_BIT(out_buf, stage_cur);
-    FLIP_BIT(out_buf, stage_cur + 1);
-    FLIP_BIT(out_buf, stage_cur + 2);
-    FLIP_BIT(out_buf, stage_cur + 3);
+    FLIP_BIT(out_buf, obj[oid].stage_cur);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 1);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 2);
+    FLIP_BIT(out_buf, obj[oid].stage_cur + 3);
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_FLIP4]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_FLIP4] += stage_max;
+  obj[oid].stage_finds[STAGE_FLIP4]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_FLIP4] += obj[oid].stage_max;
 
   /* Effector map setup. These macros calculate:
 
@@ -5278,26 +5269,26 @@ static u8 fuzz_one(char** argv) {
 
   /* Walking byte. */
 
-  stage_name  = "bitflip 8/8";
-  stage_short = "flip8";
-  stage_max   = len;
+  obj[oid].stage_name  = "bitflip 8/8";
+  obj[oid].stage_short = "flip8";
+  obj[oid].stage_max   = len;
 
   orig_hit_cnt = new_hit_cnt;
 
-  for (stage_cur = 0; stage_cur < stage_max; stage_cur++) {
+  for (obj[oid].stage_cur = 0; obj[oid].stage_cur < obj[oid].stage_max; obj[oid].stage_cur++) {
 
-    stage_cur_byte = stage_cur;
+    obj[oid].stage_cur_byte = obj[oid].stage_cur;
 
-    out_buf[stage_cur] ^= 0xFF;
+    out_buf[obj[oid].stage_cur] ^= 0xFF;
 
-    if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+    if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
     /* We also use this stage to pull off a simple trick: we identify
        bytes that seem to have no effect on the current execution path
        even when fully flipped - and we skip them during more expensive
        deterministic stages, such as arithmetics or known ints. */
 
-    if (!eff_map[EFF_APOS(stage_cur)]) {
+    if (!eff_map[EFF_APOS(obj[oid].stage_cur)]) {
 
       u32 cksum;
 
@@ -5307,16 +5298,16 @@ static u8 fuzz_one(char** argv) {
       if (!dumb_mode && len >= EFF_MIN_LEN)
         cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST);
       else
-        cksum = ~queue_cur->exec_cksum;
+        cksum = ~obj[oid].queue_cur->exec_cksum;
 
-      if (cksum != queue_cur->exec_cksum) {
-        eff_map[EFF_APOS(stage_cur)] = 1;
+      if (cksum != obj[oid].queue_cur->exec_cksum) {
+        eff_map[EFF_APOS(obj[oid].stage_cur)] = 1;
         eff_cnt++;
       }
 
     }
 
-    out_buf[stage_cur] ^= 0xFF;
+    out_buf[obj[oid].stage_cur] ^= 0xFF;
 
   }
 
@@ -5339,19 +5330,19 @@ static u8 fuzz_one(char** argv) {
 
   blocks_eff_total += EFF_ALEN(len);
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_FLIP8]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_FLIP8] += stage_max;
+  obj[oid].stage_finds[STAGE_FLIP8]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_FLIP8] += obj[oid].stage_max;
 
   /* Two walking bytes. */
 
   if (len < 2) goto skip_bitflip;
 
-  stage_name  = "bitflip 16/8";
-  stage_short = "flip16";
-  stage_cur   = 0;
-  stage_max   = len - 1;
+  obj[oid].stage_name  = "bitflip 16/8";
+  obj[oid].stage_short = "flip16";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = len - 1;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5360,35 +5351,35 @@ static u8 fuzz_one(char** argv) {
     /* Let's consult the effector map... */
 
     if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)]) {
-      stage_max--;
+      obj[oid].stage_max--;
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     *(u16*)(out_buf + i) ^= 0xFFFF;
 
-    if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-    stage_cur++;
+    if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+    obj[oid].stage_cur++;
 
     *(u16*)(out_buf + i) ^= 0xFFFF;
 
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_FLIP16]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_FLIP16] += stage_max;
+  obj[oid].stage_finds[STAGE_FLIP16]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_FLIP16] += obj[oid].stage_max;
 
   if (len < 4) goto skip_bitflip;
 
   /* Four walking bytes. */
 
-  stage_name  = "bitflip 32/8";
-  stage_short = "flip32";
-  stage_cur   = 0;
-  stage_max   = len - 3;
+  obj[oid].stage_name  = "bitflip 32/8";
+  obj[oid].stage_short = "flip32";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = len - 3;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5397,25 +5388,25 @@ static u8 fuzz_one(char** argv) {
     /* Let's consult the effector map... */
     if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)] &&
         !eff_map[EFF_APOS(i + 2)] && !eff_map[EFF_APOS(i + 3)]) {
-      stage_max--;
+      obj[oid].stage_max--;
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     *(u32*)(out_buf + i) ^= 0xFFFFFFFF;
 
-    if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-    stage_cur++;
+    if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+    obj[oid].stage_cur++;
 
     *(u32*)(out_buf + i) ^= 0xFFFFFFFF;
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_FLIP32]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_FLIP32] += stage_max;
+  obj[oid].stage_finds[STAGE_FLIP32]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_FLIP32] += obj[oid].stage_max;
 
 skip_bitflip:
 
@@ -5427,12 +5418,12 @@ skip_bitflip:
 
   /* 8-bit arithmetics. */
 
-  stage_name  = "arith 8/8";
-  stage_short = "arith8";
-  stage_cur   = 0;
-  stage_max   = 2 * len * ARITH_MAX;
+  obj[oid].stage_name  = "arith 8/8";
+  obj[oid].stage_short = "arith8";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = 2 * len * ARITH_MAX;
 
-  stage_val_type = STAGE_VAL_LE;
+  obj[oid].stage_val_type = STAGE_VAL_LE;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5443,11 +5434,11 @@ skip_bitflip:
     /* Let's consult the effector map... */
 
     if (!eff_map[EFF_APOS(i)]) {
-      stage_max -= 2 * ARITH_MAX;
+      obj[oid].stage_max -= 2 * ARITH_MAX;
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 1; j <= ARITH_MAX; j++) {
 
@@ -5458,25 +5449,25 @@ skip_bitflip:
 
       if (!could_be_bitflip(r)) {
 
-        stage_cur_val = j;
+        obj[oid].stage_cur_val = j;
         out_buf[i] = orig + j;
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       r =  orig ^ (orig - j);
 
       if (!could_be_bitflip(r)) {
 
-        stage_cur_val = -j;
+        obj[oid].stage_cur_val = -j;
         out_buf[i] = orig - j;
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       out_buf[i] = orig;
 
@@ -5484,19 +5475,19 @@ skip_bitflip:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_ARITH8]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_ARITH8] += stage_max;
+  obj[oid].stage_finds[STAGE_ARITH8]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_ARITH8] += obj[oid].stage_max;
 
   /* 16-bit arithmetics, both endians. */
 
   if (len < 2) goto skip_arith;
 
-  stage_name  = "arith 16/8";
-  stage_short = "arith16";
-  stage_cur   = 0;
-  stage_max   = 4 * (len - 1) * ARITH_MAX;
+  obj[oid].stage_name  = "arith 16/8";
+  obj[oid].stage_short = "arith16";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = 4 * (len - 1) * ARITH_MAX;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5507,11 +5498,11 @@ skip_bitflip:
     /* Let's consult the effector map... */
 
     if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)]) {
-      stage_max -= 4 * ARITH_MAX;
+      obj[oid].stage_max -= 4 * ARITH_MAX;
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 1; j <= ARITH_MAX; j++) {
 
@@ -5525,52 +5516,52 @@ skip_bitflip:
          & 0xff overflow checks) and if it couldn't be a product of
          a bitflip. */
 
-      stage_val_type = STAGE_VAL_LE; 
+      obj[oid].stage_val_type = STAGE_VAL_LE; 
 
       if ((orig & 0xff) + j > 0xff && !could_be_bitflip(r1)) {
 
-        stage_cur_val = j;
+        obj[oid].stage_cur_val = j;
         *(u16*)(out_buf + i) = orig + j;
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
  
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       if ((orig & 0xff) < j && !could_be_bitflip(r2)) {
 
-        stage_cur_val = -j;
+        obj[oid].stage_cur_val = -j;
         *(u16*)(out_buf + i) = orig - j;
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       /* Big endian comes next. Same deal. */
 
-      stage_val_type = STAGE_VAL_BE;
+      obj[oid].stage_val_type = STAGE_VAL_BE;
 
 
       if ((orig >> 8) + j > 0xff && !could_be_bitflip(r3)) {
 
-        stage_cur_val = j;
+        obj[oid].stage_cur_val = j;
         *(u16*)(out_buf + i) = SWAP16(SWAP16(orig) + j);
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       if ((orig >> 8) < j && !could_be_bitflip(r4)) {
 
-        stage_cur_val = -j;
+        obj[oid].stage_cur_val = -j;
         *(u16*)(out_buf + i) = SWAP16(SWAP16(orig) - j);
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       *(u16*)(out_buf + i) = orig;
 
@@ -5578,19 +5569,19 @@ skip_bitflip:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_ARITH16]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_ARITH16] += stage_max;
+  obj[oid].stage_finds[STAGE_ARITH16]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_ARITH16] += obj[oid].stage_max;
 
   /* 32-bit arithmetics, both endians. */
 
   if (len < 4) goto skip_arith;
 
-  stage_name  = "arith 32/8";
-  stage_short = "arith32";
-  stage_cur   = 0;
-  stage_max   = 4 * (len - 3) * ARITH_MAX;
+  obj[oid].stage_name  = "arith 32/8";
+  obj[oid].stage_short = "arith32";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = 4 * (len - 3) * ARITH_MAX;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5602,11 +5593,11 @@ skip_bitflip:
 
     if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)] &&
         !eff_map[EFF_APOS(i + 2)] && !eff_map[EFF_APOS(i + 3)]) {
-      stage_max -= 4 * ARITH_MAX;
+      obj[oid].stage_max -= 4 * ARITH_MAX;
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 1; j <= ARITH_MAX; j++) {
 
@@ -5618,51 +5609,51 @@ skip_bitflip:
       /* Little endian first. Same deal as with 16-bit: we only want to
          try if the operation would have effect on more than two bytes. */
 
-      stage_val_type = STAGE_VAL_LE;
+      obj[oid].stage_val_type = STAGE_VAL_LE;
 
       if ((orig & 0xffff) + j > 0xffff && !could_be_bitflip(r1)) {
 
-        stage_cur_val = j;
+        obj[oid].stage_cur_val = j;
         *(u32*)(out_buf + i) = orig + j;
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       if ((orig & 0xffff) < j && !could_be_bitflip(r2)) {
 
-        stage_cur_val = -j;
+        obj[oid].stage_cur_val = -j;
         *(u32*)(out_buf + i) = orig - j;
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       /* Big endian next. */
 
-      stage_val_type = STAGE_VAL_BE;
+      obj[oid].stage_val_type = STAGE_VAL_BE;
 
       if ((SWAP32(orig) & 0xffff) + j > 0xffff && !could_be_bitflip(r3)) {
 
-        stage_cur_val = j;
+        obj[oid].stage_cur_val = j;
         *(u32*)(out_buf + i) = SWAP32(SWAP32(orig) + j);
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       if ((SWAP32(orig) & 0xffff) < j && !could_be_bitflip(r4)) {
 
-        stage_cur_val = -j;
+        obj[oid].stage_cur_val = -j;
         *(u32*)(out_buf + i) = SWAP32(SWAP32(orig) - j);
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       *(u32*)(out_buf + i) = orig;
 
@@ -5670,10 +5661,10 @@ skip_bitflip:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_ARITH32]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_ARITH32] += stage_max;
+  obj[oid].stage_finds[STAGE_ARITH32]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_ARITH32] += obj[oid].stage_max;
 
 skip_arith:
 
@@ -5681,12 +5672,12 @@ skip_arith:
    * INTERESTING VALUES *
    **********************/
 
-  stage_name  = "interest 8/8";
-  stage_short = "int8";
-  stage_cur   = 0;
-  stage_max   = len * sizeof(interesting_8);
+  obj[oid].stage_name  = "interest 8/8";
+  obj[oid].stage_short = "int8";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = len * sizeof(interesting_8);
 
-  stage_val_type = STAGE_VAL_LE;
+  obj[oid].stage_val_type = STAGE_VAL_LE;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5699,11 +5690,11 @@ skip_arith:
     /* Let's consult the effector map... */
 
     if (!eff_map[EFF_APOS(i)]) {
-      stage_max -= sizeof(interesting_8);
+      obj[oid].stage_max -= sizeof(interesting_8);
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 0; j < sizeof(interesting_8); j++) {
 
@@ -5711,35 +5702,35 @@ skip_arith:
 
       if (could_be_bitflip(orig ^ (u8)interesting_8[j]) ||
           could_be_arith(orig, (u8)interesting_8[j], 1)) {
-        stage_max--;
+        obj[oid].stage_max--;
         continue;
       }
 
-      stage_cur_val = interesting_8[j];
+      obj[oid].stage_cur_val = interesting_8[j];
       out_buf[i] = interesting_8[j];
 
-      if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+      if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
       out_buf[i] = orig;
-      stage_cur++;
+      obj[oid].stage_cur++;
 
     }
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_INTEREST8]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_INTEREST8] += stage_max;
+  obj[oid].stage_finds[STAGE_INTEREST8]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_INTEREST8] += obj[oid].stage_max;
 
   /* Setting 16-bit integers, both endians. */
 
   if (no_arith || len < 2) goto skip_interest;
 
-  stage_name  = "interest 16/8";
-  stage_short = "int16";
-  stage_cur   = 0;
-  stage_max   = 2 * (len - 1) * (sizeof(interesting_16) >> 1);
+  obj[oid].stage_name  = "interest 16/8";
+  obj[oid].stage_short = "int16";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = 2 * (len - 1) * (sizeof(interesting_16) >> 1);
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5750,15 +5741,15 @@ skip_arith:
     /* Let's consult the effector map... */
 
     if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)]) {
-      stage_max -= sizeof(interesting_16);
+      obj[oid].stage_max -= sizeof(interesting_16);
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 0; j < sizeof(interesting_16) / 2; j++) {
 
-      stage_cur_val = interesting_16[j];
+      obj[oid].stage_cur_val = interesting_16[j];
 
       /* Skip if this could be a product of a bitflip, arithmetics,
          or single-byte interesting value insertion. */
@@ -5767,27 +5758,27 @@ skip_arith:
           !could_be_arith(orig, (u16)interesting_16[j], 2) &&
           !could_be_interest(orig, (u16)interesting_16[j], 2, 0)) {
 
-        stage_val_type = STAGE_VAL_LE;
+        obj[oid].stage_val_type = STAGE_VAL_LE;
 
         *(u16*)(out_buf + i) = interesting_16[j];
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       if ((u16)interesting_16[j] != SWAP16(interesting_16[j]) &&
           !could_be_bitflip(orig ^ SWAP16(interesting_16[j])) &&
           !could_be_arith(orig, SWAP16(interesting_16[j]), 2) &&
           !could_be_interest(orig, SWAP16(interesting_16[j]), 2, 1)) {
 
-        stage_val_type = STAGE_VAL_BE;
+        obj[oid].stage_val_type = STAGE_VAL_BE;
 
         *(u16*)(out_buf + i) = SWAP16(interesting_16[j]);
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
     }
 
@@ -5795,19 +5786,19 @@ skip_arith:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_INTEREST16]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_INTEREST16] += stage_max;
+  obj[oid].stage_finds[STAGE_INTEREST16]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_INTEREST16] += obj[oid].stage_max;
 
   if (len < 4) goto skip_interest;
 
   /* Setting 32-bit integers, both endians. */
 
-  stage_name  = "interest 32/8";
-  stage_short = "int32";
-  stage_cur   = 0;
-  stage_max   = 2 * (len - 3) * (sizeof(interesting_32) >> 2);
+  obj[oid].stage_name  = "interest 32/8";
+  obj[oid].stage_short = "int32";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = 2 * (len - 3) * (sizeof(interesting_32) >> 2);
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5819,15 +5810,15 @@ skip_arith:
 
     if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)] &&
         !eff_map[EFF_APOS(i + 2)] && !eff_map[EFF_APOS(i + 3)]) {
-      stage_max -= sizeof(interesting_32) >> 1;
+      obj[oid].stage_max -= sizeof(interesting_32) >> 1;
       continue;
     }
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 0; j < sizeof(interesting_32) / 4; j++) {
 
-      stage_cur_val = interesting_32[j];
+      obj[oid].stage_cur_val = interesting_32[j];
 
       /* Skip if this could be a product of a bitflip, arithmetics,
          or word interesting value insertion. */
@@ -5836,27 +5827,27 @@ skip_arith:
           !could_be_arith(orig, interesting_32[j], 4) &&
           !could_be_interest(orig, interesting_32[j], 4, 0)) {
 
-        stage_val_type = STAGE_VAL_LE;
+        obj[oid].stage_val_type = STAGE_VAL_LE;
 
         *(u32*)(out_buf + i) = interesting_32[j];
 
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
       if ((u32)interesting_32[j] != SWAP32(interesting_32[j]) &&
           !could_be_bitflip(orig ^ SWAP32(interesting_32[j])) &&
           !could_be_arith(orig, SWAP32(interesting_32[j]), 4) &&
           !could_be_interest(orig, SWAP32(interesting_32[j]), 4, 1)) {
 
-        stage_val_type = STAGE_VAL_BE;
+        obj[oid].stage_val_type = STAGE_VAL_BE;
 
         *(u32*)(out_buf + i) = SWAP32(interesting_32[j]);
-        if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
-        stage_cur++;
+        if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
+        obj[oid].stage_cur++;
 
-      } else stage_max--;
+      } else obj[oid].stage_max--;
 
     }
 
@@ -5864,10 +5855,10 @@ skip_arith:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_INTEREST32]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_INTEREST32] += stage_max;
+  obj[oid].stage_finds[STAGE_INTEREST32]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_INTEREST32] += obj[oid].stage_max;
 
 skip_interest:
 
@@ -5879,12 +5870,12 @@ skip_interest:
 
   /* Overwrite with user-supplied extras. */
 
-  stage_name  = "user extras (over)";
-  stage_short = "ext_UO";
-  stage_cur   = 0;
-  stage_max   = extras_cnt * len;
+  obj[oid].stage_name  = "user extras (over)";
+  obj[oid].stage_short = "ext_UO";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = extras_cnt * len;
 
-  stage_val_type = STAGE_VAL_NONE;
+  obj[oid].stage_val_type = STAGE_VAL_NONE;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5892,7 +5883,7 @@ skip_interest:
 
     u32 last_len = 0;
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     /* Extras are sorted by size, from smallest to largest. This means
        that we don't have to worry about restoring the buffer in
@@ -5911,7 +5902,7 @@ skip_interest:
           !memcmp(extras[j].data, out_buf + i, extras[j].len) ||
           !memchr(eff_map + EFF_APOS(i), 1, EFF_SPAN_ALEN(i, extras[j].len))) {
 
-        stage_max--;
+        obj[oid].stage_max--;
         continue;
 
       }
@@ -5919,9 +5910,9 @@ skip_interest:
       last_len = extras[j].len;
       memcpy(out_buf + i, extras[j].data, last_len);
 
-      if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+      if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
-      stage_cur++;
+      obj[oid].stage_cur++;
 
     }
 
@@ -5930,17 +5921,17 @@ skip_interest:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_EXTRAS_UO]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_EXTRAS_UO] += stage_max;
+  obj[oid].stage_finds[STAGE_EXTRAS_UO]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_EXTRAS_UO] += obj[oid].stage_max;
 
   /* Insertion of user-supplied extras. */
 
-  stage_name  = "user extras (insert)";
-  stage_short = "ext_UI";
-  stage_cur   = 0;
-  stage_max   = extras_cnt * len;
+  obj[oid].stage_name  = "user extras (insert)";
+  obj[oid].stage_short = "ext_UI";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = extras_cnt * len;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -5948,12 +5939,12 @@ skip_interest:
 
   for (i = 0; i <= len; i++) {
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 0; j < extras_cnt; j++) {
 
       if (len + extras[j].len > MAX_FILE) {
-        stage_max--; 
+        obj[oid].stage_max--; 
         continue;
       }
 
@@ -5963,12 +5954,12 @@ skip_interest:
       /* Copy tail */
       memcpy(ex_tmp + i + extras[j].len, out_buf + i, len - i);
 
-      if (common_fuzz_stuff(argv, ex_tmp, len + extras[j].len)) {
+      if (common_fuzz_stuff(ex_tmp, len + extras[j].len, oid)) {
         ck_free(ex_tmp);
         goto abandon_entry;
       }
 
-      stage_cur++;
+      obj[oid].stage_cur++;
 
     }
 
@@ -5979,21 +5970,21 @@ skip_interest:
 
   ck_free(ex_tmp);
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_EXTRAS_UI]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_EXTRAS_UI] += stage_max;
+  obj[oid].stage_finds[STAGE_EXTRAS_UI]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_EXTRAS_UI] += obj[oid].stage_max;
 
 skip_user_extras:
 
   if (!a_extras_cnt) goto skip_extras;
 
-  stage_name  = "auto extras (over)";
-  stage_short = "ext_AO";
-  stage_cur   = 0;
-  stage_max   = MIN(a_extras_cnt, USE_AUTO_EXTRAS) * len;
+  obj[oid].stage_name  = "auto extras (over)";
+  obj[oid].stage_short = "ext_AO";
+  obj[oid].stage_cur   = 0;
+  obj[oid].stage_max   = MIN(a_extras_cnt, USE_AUTO_EXTRAS) * len;
 
-  stage_val_type = STAGE_VAL_NONE;
+  obj[oid].stage_val_type = STAGE_VAL_NONE;
 
   orig_hit_cnt = new_hit_cnt;
 
@@ -6001,7 +5992,7 @@ skip_user_extras:
 
     u32 last_len = 0;
 
-    stage_cur_byte = i;
+    obj[oid].stage_cur_byte = i;
 
     for (j = 0; j < MIN(a_extras_cnt, USE_AUTO_EXTRAS); j++) {
 
@@ -6011,7 +6002,7 @@ skip_user_extras:
           !memcmp(a_extras[j].data, out_buf + i, a_extras[j].len) ||
           !memchr(eff_map + EFF_APOS(i), 1, EFF_SPAN_ALEN(i, a_extras[j].len))) {
 
-        stage_max--;
+        obj[oid].stage_max--;
         continue;
 
       }
@@ -6019,9 +6010,9 @@ skip_user_extras:
       last_len = a_extras[j].len;
       memcpy(out_buf + i, a_extras[j].data, last_len);
 
-      if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry;
+      if (common_fuzz_stuff(out_buf, len, oid)) goto abandon_entry;
 
-      stage_cur++;
+      obj[oid].stage_cur++;
 
     }
 
@@ -6030,10 +6021,10 @@ skip_user_extras:
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  stage_finds[STAGE_EXTRAS_AO]  += new_hit_cnt - orig_hit_cnt;
-  stage_cycles[STAGE_EXTRAS_AO] += stage_max;
+  obj[oid].stage_finds[STAGE_EXTRAS_AO]  += new_hit_cnt - orig_hit_cnt;
+  obj[oid].stage_cycles[STAGE_EXTRAS_AO] += obj[oid].stage_max;
 
 skip_extras:
 
@@ -6041,7 +6032,7 @@ skip_extras:
      we're properly done with deterministic steps and can mark it as such
      in the .state/ directory. */
 
-  if (!queue_cur->passed_det) mark_as_det_done(queue_cur);
+  if (!obj[oid].queue_cur->passed_det) mark_as_det_done(obj[oid].queue_cur, oid);
 
   /****************
    * RANDOM HAVOC *
@@ -6049,17 +6040,17 @@ skip_extras:
 
 havoc_stage:
 
-  stage_cur_byte = -1;
+  obj[oid].stage_cur_byte = -1;
 
   /* The havoc stage mutation code is also invoked when splicing files; if the
      splice_cycle variable is set, generate different descriptions and such. */
 
   if (!splice_cycle) {
 
-    stage_name  = "havoc";
-    stage_short = "havoc";
-    stage_max   = (doing_det ? HAVOC_CYCLES_INIT : HAVOC_CYCLES) *
-                  perf_score / havoc_div / 100;
+    obj[oid].stage_name  = "havoc";
+    obj[oid].stage_short = "havoc";
+    obj[oid].stage_max   = (doing_det ? HAVOC_CYCLES_INIT : HAVOC_CYCLES) *
+                  perf_score / obj[oid].havoc_div / 100;
 
   } else {
 
@@ -6068,28 +6059,28 @@ havoc_stage:
     perf_score = orig_perf;
 
     sprintf(tmp, "splice %u", splice_cycle);
-    stage_name  = tmp;
-    stage_short = "splice";
-    stage_max   = SPLICE_HAVOC * perf_score / havoc_div / 100;
+    obj[oid].stage_name  = tmp;
+    obj[oid].stage_short = "splice";
+    obj[oid].stage_max   = SPLICE_HAVOC * perf_score / obj[oid].havoc_div / 100;
 
   }
 
-  if (stage_max < HAVOC_MIN) stage_max = HAVOC_MIN;
+  if (obj[oid].stage_max < HAVOC_MIN) obj[oid].stage_max = HAVOC_MIN;
 
   temp_len = len;
 
-  orig_hit_cnt = queued_paths + unique_crashes;
+  orig_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
-  havoc_queued = queued_paths;
+  havoc_queued = obj[oid].queued_paths;
 
   /* We essentially just do several thousand runs (depending on perf_score)
      where we take the input file and make random stacked tweaks. */
 
-  for (stage_cur = 0; stage_cur < stage_max; stage_cur++) {
+  for (obj[oid].stage_cur = 0; obj[oid].stage_cur < obj[oid].stage_max; obj[oid].stage_cur++) {
 
     u32 use_stacking = 1 << (1 + UR(HAVOC_STACK_POW2));
 
-    stage_cur_val = use_stacking;
+    obj[oid].stage_cur_val = use_stacking;
  
     for (i = 0; i < use_stacking; i++) {
 
@@ -6280,7 +6271,7 @@ havoc_stage:
 
             /* Don't delete too much. */
 
-            del_len = choose_block_len(temp_len - 1);
+            del_len = choose_block_len(temp_len - 1, oid);
 
             del_from = UR(temp_len - del_len + 1);
 
@@ -6305,12 +6296,12 @@ havoc_stage:
 
             if (actually_clone) {
 
-              clone_len  = choose_block_len(temp_len);
+              clone_len  = choose_block_len(temp_len, oid);
               clone_from = UR(temp_len - clone_len + 1);
 
             } else {
 
-              clone_len = choose_block_len(HAVOC_BLK_XL);
+              clone_len = choose_block_len(HAVOC_BLK_XL, oid);
               clone_from = 0;
 
             }
@@ -6352,7 +6343,7 @@ havoc_stage:
 
             if (temp_len < 2) break;
 
-            copy_len  = choose_block_len(temp_len - 1);
+            copy_len  = choose_block_len(temp_len - 1, oid);
 
             copy_from = UR(temp_len - copy_len + 1);
             copy_to   = UR(temp_len - copy_len + 1);
@@ -6465,7 +6456,7 @@ havoc_stage:
 
     }
 
-    if (common_fuzz_stuff(argv, out_buf, temp_len))
+    if (common_fuzz_stuff(out_buf, temp_len, oid))
       goto abandon_entry;
 
     /* out_buf might have been mangled a bit, so let's restore it to its
@@ -6478,27 +6469,27 @@ havoc_stage:
     /* If we're finding new stuff, let's run for a bit longer, limits
        permitting. */
 
-    if (queued_paths != havoc_queued) {
+    if (obj[oid].queued_paths != havoc_queued) {
 
       if (perf_score <= HAVOC_MAX_MULT * 100) {
-        stage_max  *= 2;
+        obj[oid].stage_max  *= 2;
         perf_score *= 2;
       }
 
-      havoc_queued = queued_paths;
+      havoc_queued = obj[oid].queued_paths;
 
     }
 
   }
 
-  new_hit_cnt = queued_paths + unique_crashes;
+  new_hit_cnt = obj[oid].queued_paths + obj[oid].unique_crashes;
 
   if (!splice_cycle) {
-    stage_finds[STAGE_HAVOC]  += new_hit_cnt - orig_hit_cnt;
-    stage_cycles[STAGE_HAVOC] += stage_max;
+    obj[oid].stage_finds[STAGE_HAVOC]  += new_hit_cnt - orig_hit_cnt;
+    obj[oid].stage_cycles[STAGE_HAVOC] += obj[oid].stage_max;
   } else {
-    stage_finds[STAGE_SPLICE]  += new_hit_cnt - orig_hit_cnt;
-    stage_cycles[STAGE_SPLICE] += stage_max;
+    obj[oid].stage_finds[STAGE_SPLICE]  += new_hit_cnt - orig_hit_cnt;
+    obj[oid].stage_cycles[STAGE_SPLICE] += obj[oid].stage_max;
   }
 
 #ifndef IGNORE_FINDS
@@ -6514,8 +6505,8 @@ havoc_stage:
 
 retry_splicing:
 
-  if (use_splicing && splice_cycle++ < SPLICE_CYCLES &&
-      queued_paths > 1 && queue_cur->len > 1) {
+  if (obj[oid].use_splicing && splice_cycle++ < SPLICE_CYCLES &&
+      obj[oid].queued_paths > 1 && obj[oid].queue_cur->len > 1) {
 
     struct queue_entry* target;
     u32 tid, split_at;
@@ -6528,24 +6519,24 @@ retry_splicing:
     if (in_buf != orig_in) {
       ck_free(in_buf);
       in_buf = orig_in;
-      len = queue_cur->len;
+      len = obj[oid].queue_cur->len;
     }
 
     /* Pick a random queue entry and seek to it. Don't splice with yourself. */
 
-    do { tid = UR(queued_paths); } while (tid == current_entry);
+    do { tid = UR(obj[oid].queued_paths); } while (tid == obj[oid].current_entry);
 
-    splicing_with = tid;
-    target = queue;
+    obj[oid].splicing_with = tid;
+    target = obj[oid].queue;
 
     while (tid >= 100) { target = target->next_100; tid -= 100; }
     while (tid--) target = target->next;
 
     /* Make sure that the target has a reasonable length. */
 
-    while (target && (target->len < 2 || target == queue_cur)) {
+    while (target && (target->len < 2 || target == obj[oid].queue_cur)) {
       target = target->next;
-      splicing_with++;
+      obj[oid].splicing_with++;
     }
 
     if (!target) goto retry_splicing;
@@ -6597,18 +6588,18 @@ retry_splicing:
 
 abandon_entry:
 
-  splicing_with = -1;
+  obj[oid].splicing_with = -1;
 
   /* Update pending_not_fuzzed count if we made it through the calibration
      cycle and have not seen this entry before. */
 
-  if (!stop_soon && !queue_cur->cal_failed && !queue_cur->was_fuzzed) {
-    queue_cur->was_fuzzed = 1;
-    pending_not_fuzzed--;
-    if (queue_cur->favored) pending_favored--;
+  if (!stop_soon && !obj[oid].queue_cur->cal_failed && !obj[oid].queue_cur->was_fuzzed) {
+    obj[oid].queue_cur->was_fuzzed = 1;
+    obj[oid].pending_not_fuzzed--;
+    if (obj[oid].queue_cur->favored) obj[oid].pending_favored--;
   }
 
-  munmap(orig_in, queue_cur->len);
+  munmap(orig_in, obj[oid].queue_cur->len);
 
   if (in_buf != orig_in) ck_free(in_buf);
   ck_free(out_buf);
@@ -6620,145 +6611,6 @@ abandon_entry:
 
 }
 
-
-/* Grab interesting test cases from other fuzzers. */
-
-static void sync_fuzzers(char** argv) {
-
-  DIR* sd;
-  struct dirent* sd_ent;
-  u32 sync_cnt = 0;
-
-  sd = opendir(sync_dir);
-  if (!sd) PFATAL("Unable to open '%s'", sync_dir);
-
-  stage_max = stage_cur = 0;
-  cur_depth = 0;
-
-  /* Look at the entries created for every other fuzzer in the sync directory. */
-
-  while ((sd_ent = readdir(sd))) {
-
-    static u8 stage_tmp[128];
-
-    DIR* qd;
-    struct dirent* qd_ent;
-    u8 *qd_path, *qd_synced_path;
-    u32 min_accept = 0, next_min_accept;
-
-    s32 id_fd;
-
-    /* Skip dot files and our own output directory. */
-
-    if (sd_ent->d_name[0] == '.' || !strcmp(sync_id, sd_ent->d_name)) continue;
-
-    /* Skip anything that doesn't have a queue/ subdirectory. */
-
-    qd_path = alloc_printf("%s/%s/queue", sync_dir, sd_ent->d_name);
-
-    if (!(qd = opendir(qd_path))) {
-      ck_free(qd_path);
-      continue;
-    }
-
-    /* Retrieve the ID of the last seen test case. */
-
-    qd_synced_path = alloc_printf("%s/.synced/%s", out_dir, sd_ent->d_name);
-
-    id_fd = open(qd_synced_path, O_RDWR | O_CREAT, 0600);
-
-    if (id_fd < 0) PFATAL("Unable to create '%s'", qd_synced_path);
-
-    if (read(id_fd, &min_accept, sizeof(u32)) > 0) 
-      lseek(id_fd, 0, SEEK_SET);
-
-    next_min_accept = min_accept;
-
-    /* Show stats */    
-
-    sprintf(stage_tmp, "sync %u", ++sync_cnt);
-    stage_name = stage_tmp;
-    stage_cur  = 0;
-    stage_max  = 0;
-
-    /* For every file queued by this fuzzer, parse ID and see if we have looked at
-       it before; exec a test case if not. */
-
-    while ((qd_ent = readdir(qd))) {
-
-      u8* path;
-      s32 fd;
-      struct stat st;
-
-      if (qd_ent->d_name[0] == '.' ||
-          sscanf(qd_ent->d_name, CASE_PREFIX "%06u", &syncing_case) != 1 || 
-          syncing_case < min_accept) continue;
-
-      /* OK, sounds like a new one. Let's give it a try. */
-
-      if (syncing_case >= next_min_accept)
-        next_min_accept = syncing_case + 1;
-
-      path = alloc_printf("%s/%s", qd_path, qd_ent->d_name);
-
-      /* Allow this to fail in case the other fuzzer is resuming or so... */
-
-      fd = open(path, O_RDONLY);
-
-      if (fd < 0) {
-         ck_free(path);
-         continue;
-      }
-
-      if (fstat(fd, &st)) PFATAL("fstat() failed");
-
-      /* Ignore zero-sized or oversized files. */
-
-      if (st.st_size && st.st_size <= MAX_FILE) {
-
-        u8  fault;
-        u8* mem = mmap(0, st.st_size, PROT_READ, MAP_PRIVATE, fd, 0);
-
-        if (mem == MAP_FAILED) PFATAL("Unable to mmap '%s'", path);
-
-        /* See what happens. We rely on save_if_interesting() to catch major
-           errors and save the test case. */
-
-        write_to_testcase(mem, st.st_size);
-
-        fault = run_target(argv, exec_tmout);
-
-        if (stop_soon) return;
-
-        syncing_party = sd_ent->d_name;
-        queued_imported += save_if_interesting(argv, mem, st.st_size, fault);
-        syncing_party = 0;
-
-        munmap(mem, st.st_size);
-
-        if (!(stage_cur++ % stats_update_freq)) show_stats();
-
-      }
-
-      ck_free(path);
-      close(fd);
-
-    }
-
-    ck_write(id_fd, &next_min_accept, sizeof(u32), qd_synced_path);
-
-    close(id_fd);
-    closedir(qd);
-    ck_free(qd_path);
-    ck_free(qd_synced_path);
-    
-  }  
-
-  closedir(sd);
-
-}
-
-
 /* Handle stop signal (Ctrl-C, etc). */
 
 static void handle_stop_sig(int sig) {
@@ -6901,7 +6753,7 @@ EXP_ST void check_binary(u8* fname) {
 
 #endif /* ^!__APPLE__ */
 
-  if (!qemu_mode && !dumb_mode &&
+  if (!qemu_mode && !unicorn_mode && !dumb_mode &&
       !memmem(f_data, f_len, SHM_ENV_VAR, strlen(SHM_ENV_VAR) + 1)) {
 
     SAYF("\n" cLRD "[-] " cRST
@@ -6921,15 +6773,15 @@ EXP_ST void check_binary(u8* fname) {
 
   }
 
-  if (qemu_mode &&
+  if ((qemu_mode || unicorn_mode) &&
       memmem(f_data, f_len, SHM_ENV_VAR, strlen(SHM_ENV_VAR) + 1)) {
 
     SAYF("\n" cLRD "[-] " cRST
          "This program appears to be instrumented with afl-gcc, but is being run in\n"
-         "    QEMU mode (-Q). This is probably not what you want - this setup will be\n"
-         "    slow and offer no practical benefits.\n");
+         "    QEMU or Unicorn mode (-Q or -U). This is probably not what you want -\n"
+         "    this setup will be slow and offer no practical benefits.\n");
 
-    FATAL("Instrumentation found in -Q mode");
+    FATAL("Instrumentation found in -Q or -U mode");
 
   }
 
@@ -7054,18 +6906,17 @@ static void usage(u8* argv0) {
        "  -f file       - location read by the fuzzed program (stdin)\n"
        "  -t msec       - timeout for each run (auto-scaled, 50-%u ms)\n"
        "  -m megs       - memory limit for child process (%u MB)\n"
-       "  -Q            - use binary-only instrumentation (QEMU mode)\n\n"     
+       "  -Q            - use binary-only instrumentation (QEMU mode)\n" 
+       "  -U            - use Unicorn-based instrumentation (Unicorn mode)\n\n"    
  
        "Fuzzing behavior settings:\n\n"
 
-       "  -d            - quick & dirty mode (skips deterministic steps)\n"
        "  -n            - fuzz without instrumentation (dumb mode)\n"
        "  -x dir        - optional fuzzer dictionary (see README)\n\n"
 
        "Other stuff:\n\n"
 
        "  -T text       - text banner to show on the screen\n"
-       "  -M / -S id    - distributed mode (see parallel_fuzzing.txt)\n"
        "  -C            - crash exploration mode (the peruvian rabbit thing)\n\n"
 
        "For additional tips, please consult %s/README.\n\n",
@@ -7076,79 +6927,84 @@ static void usage(u8* argv0) {
 
 }
 
-
-/* Prepare output directories and fds. */
-
-EXP_ST void setup_dirs_fds(void) {
+EXP_ST void setup_queue_dirs(u32 oid) {
 
   u8* tmp;
-  s32 fd;
-
-  ACTF("Setting up output directories...");
-
-  if (sync_id && mkdir(sync_dir, 0700) && errno != EEXIST)
-      PFATAL("Unable to create '%s'", sync_dir);
-
-  if (mkdir(out_dir, 0700)) {
-
-    if (errno != EEXIST) PFATAL("Unable to create '%s'", out_dir);
-
-    maybe_delete_out_dir();
-
-  } else {
-
-    if (in_place_resume)
-      FATAL("Resume attempted but old output directory not found");
-
-    out_dir_fd = open(out_dir, O_RDONLY);
-
-#ifndef __sun
-
-    if (out_dir_fd < 0 || flock(out_dir_fd, LOCK_EX | LOCK_NB))
-      PFATAL("Unable to flock() output directory.");
-
-#endif /* !__sun */
-
-  }
 
   /* Queue directory for any starting & discovered paths. */
 
-  tmp = alloc_printf("%s/queue", out_dir);
+  tmp = alloc_printf("%s/queue_%03u", out_dir, oid);
   if (mkdir(tmp, 0700)) PFATAL("Unable to create '%s'", tmp);
   ck_free(tmp);
 
   /* Top-level directory for queue metadata used for session
      resume and related tasks. */
 
-  tmp = alloc_printf("%s/queue/.state/", out_dir);
+  tmp = alloc_printf("%s/queue_%03u/.state/", out_dir, oid);
   if (mkdir(tmp, 0700)) PFATAL("Unable to create '%s'", tmp);
   ck_free(tmp);
 
   /* Directory for flagging queue entries that went through
      deterministic fuzzing in the past. */
 
-  tmp = alloc_printf("%s/queue/.state/deterministic_done/", out_dir);
+  tmp = alloc_printf("%s/queue_%03u/.state/deterministic_done/", out_dir, oid);
   if (mkdir(tmp, 0700)) PFATAL("Unable to create '%s'", tmp);
   ck_free(tmp);
 
   /* Directory with the auto-selected dictionary entries. */
 
-  tmp = alloc_printf("%s/queue/.state/auto_extras/", out_dir);
+  tmp = alloc_printf("%s/queue_%03u/.state/auto_extras/", out_dir, oid);
   if (mkdir(tmp, 0700)) PFATAL("Unable to create '%s'", tmp);
   ck_free(tmp);
 
   /* The set of paths currently deemed redundant. */
 
-  tmp = alloc_printf("%s/queue/.state/redundant_edges/", out_dir);
+  tmp = alloc_printf("%s/queue_%03u/.state/redundant_edges/", out_dir, oid);
   if (mkdir(tmp, 0700)) PFATAL("Unable to create '%s'", tmp);
   ck_free(tmp);
 
   /* The set of paths showing variable behavior. */
 
-  tmp = alloc_printf("%s/queue/.state/variable_behavior/", out_dir);
+  tmp = alloc_printf("%s/queue_%03u/.state/variable_behavior/", out_dir, oid);
   if (mkdir(tmp, 0700)) PFATAL("Unable to create '%s'", tmp);
   ck_free(tmp);
 
+}
+
+/* Prepare output directories and fds. */
+
+EXP_ST void setup_dirs_fds(void) {
+
+  u8* tmp;
+  s32 fd;
+
+  ACTF("Setting up output directories...");
+
+  if (mkdir(out_dir, 0700)) {
+
+    if (errno != EEXIST) PFATAL("Unable to create '%s'", out_dir);
+
+    maybe_delete_out_dir();
+
+  } else {
+
+    if (in_place_resume)
+      FATAL("Resume attempted but old output directory not found");
+
+    out_dir_fd = open(out_dir, O_RDONLY);
+
+#ifndef __sun
+
+    if (out_dir_fd < 0 || flock(out_dir_fd, LOCK_EX | LOCK_NB))
+      PFATAL("Unable to flock() output directory.");
+
+#endif /* !__sun */
+
+  }
+
+  for (u32 i = 0; i < obj_num; i++)
+    setup_queue_dirs(i);
+
   /* Sync directory for keeping track of cooperating fuzzers. */
 
   if (sync_id) {
@@ -7199,24 +7055,6 @@ EXP_ST void setup_dirs_fds(void) {
 
 }
 
-
-/* Setup the output file for fuzzed data, if not using -f. */
-
-EXP_ST void setup_stdio_file(void) {
-
-  u8* fn = alloc_printf("%s/.cur_input", out_dir);
-
-  unlink(fn); /* Ignore errors */
-
-  out_fd = open(fn, O_RDWR | O_CREAT | O_EXCL, 0600);
-
-  if (out_fd < 0) PFATAL("Unable to create '%s'", fn);
-
-  ck_free(fn);
-
-}
-
-
 /* Make sure that core dumps don't go to a program. */
 
 static void check_crash_handling(void) {
@@ -7425,49 +7263,6 @@ static void get_core_count(void) {
 
 }
 
-
-/* Validate and fix up out_dir and sync_dir when using -S. */
-
-static void fix_up_sync(void) {
-
-  u8* x = sync_id;
-
-  if (dumb_mode)
-    FATAL("-S / -M and -n are mutually exclusive");
-
-  if (skip_deterministic) {
-
-    if (force_deterministic)
-      FATAL("use -S instead of -M -d");
-    else
-      FATAL("-S already implies -d");
-
-  }
-
-  while (*x) {
-
-    if (!isalnum(*x) && *x != '_' && *x != '-')
-      FATAL("Non-alphanumeric fuzzer ID specified via -S or -M");
-
-    x++;
-
-  }
-
-  if (strlen(sync_id) > 32) FATAL("Fuzzer ID too long");
-
-  x = alloc_printf("%s/%s", out_dir, sync_id);
-
-  sync_dir = out_dir;
-  out_dir  = x;
-
-  if (!force_deterministic) {
-    skip_deterministic = 1;
-    use_splicing = 1;
-  }
-
-}
-
-
 /* Handle screen resize (SIGWINCH). */
 
 static void handle_resize(int sig) {
@@ -7598,7 +7393,10 @@ EXP_ST void setup_signal_handlers(void)
 }
 
 
-/* Rewrite argv for QEMU. */
+/* Rewrite argv for QEMU.
+   Specifically, this changes the command call to:
+       $ {AFL_PATH}afl-qemu-trace -- {target_bin} {test_input_path and args} 
+ */
 
 static char** get_qemu_argv(u8* own_loc, char** argv, int argc) {
 
@@ -7670,7 +7468,6 @@ static char** get_qemu_argv(u8* own_loc,
 
 }
 
-
 /* Make a copy of the current command line. */
 
 static void save_cmdline(u32 argc, char** argv) {
@@ -7698,6 +7495,53 @@ static void save_cmdline(u32 argc, char*
 
 }
 
+void* fuzzing_loop(void *argc)
+{
+  u64 oid = (u64)argc;
+  OKF("Seedpool %llu setup OK!", oid);
+
+  u64 prev_queued = 0;
+
+  perform_dry_run(oid);
+
+  cull_queue(oid);
+
+  while(1) {
+
+    cull_queue(oid);
+
+    if (!obj[oid].queue_cur) {
+
+      obj[oid].queue_cycle++;
+      obj[oid].current_entry     = 0;
+      obj[oid].cur_skipped_paths = 0;
+      obj[oid].queue_cur         = obj[oid].queue;
+
+      /* If we had a full queue cycle with no new finds, try
+         recombination strategies next. */
+
+      show_stats();
+
+      if (obj[oid].queued_paths == prev_queued) {
+
+        if (obj[oid].use_splicing) obj[oid].cycles_wo_finds++; else obj[oid].use_splicing = 1;
+
+      } else obj[oid].cycles_wo_finds = 0;
+
+      prev_queued = obj[oid].queued_paths;
+
+    }
+
+    fuzz_one(oid);
+
+    if (stop_soon) break;
+
+    obj[oid].queue_cur = obj[oid].queue_cur->next;
+    obj[oid].current_entry++;
+
+  }
+  return 0;
+}
 
 #ifndef AFL_LIB
 
@@ -7706,11 +7550,8 @@ static void save_cmdline(u32 argc, char*
 int main(int argc, char** argv) {
 
   s32 opt;
-  u64 prev_queued = 0;
-  u32 sync_interval_cnt = 0, seek_to;
   u8  *extras_dir = 0;
   u8  mem_limit_given = 0;
-  u8  exit_1 = !!getenv("AFL_BENCH_JUST_ONE");
   char** use_argv;
 
   struct timeval tv;
@@ -7723,7 +7564,7 @@ int main(int argc, char** argv) {
   gettimeofday(&tv, &tz);
   srandom(tv.tv_sec ^ tv.tv_usec ^ getpid());
 
-  while ((opt = getopt(argc, argv, "+i:o:f:m:t:T:dnCB:S:M:x:Q")) > 0)
+  while ((opt = getopt(argc, argv, "+i:o:f:m:t:T:dnCB:S:M:x:QU")) > 0)
 
     switch (opt) {
 
@@ -7742,39 +7583,10 @@ int main(int argc, char** argv) {
         out_dir = optarg;
         break;
 
-      case 'M': { /* master sync ID */
-
-          u8* c;
-
-          if (sync_id) FATAL("Multiple -S or -M options not supported");
-          sync_id = ck_strdup(optarg);
-
-          if ((c = strchr(sync_id, ':'))) {
-
-            *c = 0;
-
-            if (sscanf(c + 1, "%u/%u", &master_id, &master_max) != 2 ||
-                !master_id || !master_max || master_id > master_max ||
-                master_max > 1000000) FATAL("Bogus master ID passed to -M");
-
-          }
-
-          force_deterministic = 1;
-
-        }
-
-        break;
-
-      case 'S': 
-
-        if (sync_id) FATAL("Multiple -S or -M options not supported");
-        sync_id = ck_strdup(optarg);
-        break;
-
       case 'f': /* target file */
 
-        if (out_file) FATAL("Multiple -f options not supported");
-        out_file = optarg;
+        if (out_file_dir) FATAL("Multiple -f options not supported");
+        out_file_dir = optarg;
         break;
 
       case 'x': /* dictionary */
@@ -7837,13 +7649,6 @@ int main(int argc, char** argv) {
 
         break;
 
-      case 'd': /* skip deterministic */
-
-        if (skip_deterministic) FATAL("Multiple -d options not supported");
-        skip_deterministic = 1;
-        use_splicing = 1;
-        break;
-
       case 'B': /* load bitmap */
 
         /* This is a secret undocumented option! It is useful if you find
@@ -7890,6 +7695,15 @@ int main(int argc, char** argv) {
         if (!mem_limit_given) mem_limit = MEM_LIMIT_QEMU;
 
         break;
+        
+      case 'U': /* Unicorn mode */
+
+        if (unicorn_mode) FATAL("Multiple -U options not supported");
+        unicorn_mode = 1;
+
+        if (!mem_limit_given) mem_limit = MEM_LIMIT_UNICORN;
+
+        break;
 
       default:
 
@@ -7902,15 +7716,14 @@ int main(int argc, char** argv) {
   setup_signal_handlers();
   check_asan_opts();
 
-  if (sync_id) fix_up_sync();
-
   if (!strcmp(in_dir, out_dir))
     FATAL("Input and output directories can't be the same");
 
   if (dumb_mode) {
 
-    if (crash_mode) FATAL("-C and -n are mutually exclusive");
-    if (qemu_mode)  FATAL("-Q and -n are mutually exclusive");
+    if (crash_mode)   FATAL("-C and -n are mutually exclusive");
+    if (qemu_mode)    FATAL("-Q and -n are mutually exclusive");
+    if (unicorn_mode) FATAL("-U and -n are mutually exclusive");
 
   }
 
@@ -7955,8 +7768,8 @@ int main(int argc, char** argv) {
   setup_shm();
   init_count_class16();
 
-  setup_dirs_fds();
   read_testcases();
+  setup_dirs_fds();
   load_auto();
 
   pivot_inputs();
@@ -7967,8 +7780,6 @@ int main(int argc, char** argv) {
 
   detect_file_args(argv + optind + 1);
 
-  if (!out_file) setup_stdio_file();
-
   check_binary(argv[optind]);
 
   start_time = get_cur_time();
@@ -7978,88 +7789,87 @@ int main(int argc, char** argv) {
   else
     use_argv = argv + optind;
 
-  perform_dry_run(use_argv);
-
-  cull_queue();
-
   show_init_stats();
 
-  seek_to = find_start_position();
-
   write_stats_file(0, 0, 0);
   save_auto();
 
+  init_forkserver(use_argv);
+
   if (stop_soon) goto stop_fuzzing;
 
   /* Woop woop woop */
 
+  sleep(8);
+
+  for (u64 oid = 0; oid < obj_num; oid++) {
+    pthread_create(&tids[oid], NULL, fuzzing_loop, (void *)oid);
+    pthread_mutex_init(&object_mutex[oid], NULL);
+    pthread_cond_init(&object_wait_cv[oid], NULL);
+  }
+  pthread_mutex_init(&fuzz_mutex, NULL);
+  pthread_cond_init(&fuzz_wait_cv, NULL);
+
   if (!not_on_tty) {
-    sleep(4);
+    sleep(8);
     start_time += 4000;
     if (stop_soon) goto stop_fuzzing;
   }
 
-  while (1) {
+  int tmp;
+  s32 res;
+  struct timespec outtime;
 
-    u8 skipped_fuzz;
+  while(1) {
 
-    cull_queue();
+    // pthread_mutex_lock(&fuzz_mutex);
 
-    if (!queue_cur) {
+    outtime.tv_sec = time(NULL) + 5;
 
-      queue_cycle++;
-      current_entry     = 0;
-      cur_skipped_paths = 0;
-      queue_cur         = queue;
+    // printf(" main before read()\n");
 
-      while (seek_to) {
-        current_entry++;
-        seek_to--;
-        queue_cur = queue_cur->next;
-      }
+    if ((res = read(fsrv_st_fd, &tmp, 4)) != 4) {
 
-      show_stats();
+      RPFATAL(res, "Unable to communicate with fork server (OOM?)");
 
-      if (not_on_tty) {
-        ACTF("Entering queue cycle %llu.", queue_cycle);
-        fflush(stdout);
-      }
+    }
 
-      /* If we had a full queue cycle with no new finds, try
-         recombination strategies next. */
+    int request_oid = tmp;
 
-      if (queued_paths == prev_queued) {
+    // printf(" while(1) read id = %d\n", request_oid);
 
-        if (use_splicing) cycles_wo_finds++; else use_splicing = 1;
+    pthread_mutex_lock(&object_mutex[request_oid]);
 
-      } else cycles_wo_finds = 0;
+    fuzz_done[request_oid] = false;
 
-      prev_queued = queued_paths;
+    // pthread_mutex_unlock(&fuzz_mutex);
 
-      if (sync_id && queue_cycle == 1 && getenv("AFL_IMPORT_FIRST"))
-        sync_fuzzers(use_argv);
+    pthread_cond_signal(&object_wait_cv[request_oid]);
 
-    }
+    pthread_mutex_unlock(&object_mutex[request_oid]);
 
-    skipped_fuzz = fuzz_one(use_argv);
+    // pthread_cond_wait(&fuzz_wait_cv, &fuzz_mutex);
 
-    if (!stop_soon && sync_id && !skipped_fuzz) {
-      
-      if (!(sync_interval_cnt++ % SYNC_INTERVAL))
-        sync_fuzzers(use_argv);
+    pthread_cond_timedwait(&fuzz_wait_cv, &fuzz_mutex, &outtime);
 
-    }
+    // printf(" main before sleep()\n");
 
-    if (!stop_soon && exit_1) stop_soon = 2;
+    // usleep(100);
 
     if (stop_soon) break;
 
-    queue_cur = queue_cur->next;
-    current_entry++;
+  }
 
+  for(u64 oid = 0; oid < obj_num; oid++) {
+    pthread_join(tids[oid], NULL);
+    pthread_mutex_destroy(&object_mutex[oid]);
+    pthread_cond_destroy(&object_wait_cv[oid]);
   }
+  pthread_mutex_destroy(&fuzz_mutex);
+  pthread_cond_destroy(&fuzz_wait_cv);
+
 
-  if (queue_cur) show_stats();
+  if (obj[0].queue_cur) show_stats();
 
   write_bitmap();
   write_stats_file(0, 0, 0);
@@ -8072,7 +7882,7 @@ stop_fuzzing:
 
   /* Running for more than 30 minutes but still doing first cycle? */
 
-  if (queue_cycle == 1 && get_cur_time() - start_time > 30 * 60 * 1000) {
+  if (obj[0].queue_cycle == 1 && get_cur_time() - start_time > 30 * 60 * 1000) {
 
     SAYF("\n" cYEL "[!] " cRST
            "Stopped during the first cycle, results may be incomplete.\n"
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-gcc.c afl/afl-gcc.c
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-gcc.c	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-gcc.c	2024-12-05 00:01:46.399574000 +0800
@@ -205,6 +205,10 @@ static void edit_params(u32 argc, char**
     cc_params[cc_par_cnt++] = cur;
 
   }
+  
+//  #define DEVICE_DIR "hw/"
+//  if(!strstr(cc_params[cc_par_cnt - 1], DEVICE_DIR))
+//    return;
 
   cc_params[cc_par_cnt++] = "-B";
   cc_params[cc_par_cnt++] = as_path;
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-showmap.c afl/afl-showmap.c
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-showmap.c	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-showmap.c	2024-12-05 22:17:47.556806550 +0800
@@ -46,11 +46,16 @@
 #include <sys/types.h>
 #include <sys/resource.h>
 
-static s32 child_pid;                 /* PID of the tested program         */
+static s32 forksrv_pid,               /* PID of the fork server           */
+           child_pid;                 /* PID of the tested program         */
+
+static s32 fsrv_ctl_fd,               /* Fork server control pipe (write) */
+           fsrv_st_fd;                /* Fork server status pipe (read)   */
 
 static u8* trace_bits;                /* SHM with instrumentation bitmap   */
 
-static u8 *out_file,                  /* Trace output file                 */
+static u8 *out_path,                  /* Trace output file / dir           */
+          *in_path,                   /* Program input file / dir          */
           *doc_path,                  /* Path to docs                      */
           *target_path,               /* Path to target binary             */
           *at_file;                   /* Substitution string for @@        */
@@ -61,12 +66,20 @@ static u64 mem_limit = MEM_LIMIT;     /*
 
 static s32 shm_id;                    /* ID of the SHM region              */
 
+static s32 at_file_fd,                    /* Persistent fd for tmp_input_file        */
+           dev_null_fd = -1;          /* Persistent fd for /dev/null       */
+
 static u8  quiet_mode,                /* Hide non-essential messages?      */
            edges_only,                /* Ignore hit counts?                */
            cmin_mode,                 /* Generate output in afl-cmin mode? */
            binary_mode,               /* Write output as a binary map      */
            keep_cores;                /* Allow coredumps?                  */
 
+static u8  batch_mode,
+           no_output,
+           using_file_arg,
+           allocated_at_file;
+
 static volatile u8
            stop_soon,                 /* Ctrl-C pressed?                   */
            child_timed_out,           /* Child timed out?                  */
@@ -103,6 +116,19 @@ static const u8 count_class_binary[256]
 
 };
 
+struct queue_entry {
+    struct queue_entry *next;
+    u8 *in_path;
+    u32 in_len;
+    u8 *out_path;
+};
+
+/* Append new test case to the queue. */
+struct queue_entry *queue_top = 0;
+struct queue_entry *queue = 0;
+int queued_paths = 0;
+
+
 static void classify_counts(u8* mem, const u8* map) {
 
   u32 i = MAP_SIZE;
@@ -159,31 +185,116 @@ static void setup_shm(void) {
 
 }
 
-/* Write results. */
+static void setup_at_file(void) {
+    u8 *use_dir = ".";
 
-static u32 write_results(void) {
+    if (access(use_dir, R_OK | W_OK | X_OK))
+    {
 
-  s32 fd;
-  u32 i, ret = 0;
+        use_dir = getenv("TMPDIR");
+        if (!use_dir)
+            use_dir = "/tmp";
+    }
 
-  u8  cco = !!getenv("AFL_CMIN_CRASHES_ONLY"),
-      caa = !!getenv("AFL_CMIN_ALLOW_ANY");
+    at_file = alloc_printf("%s/.afl-showmap-temp-%u", use_dir, getpid());
 
-  if (!strncmp(out_file, "/dev/", 5)) {
+    unlink(at_file);
 
-    fd = open(out_file, O_WRONLY, 0600);
-    if (fd < 0) PFATAL("Unable to open '%s'", out_file);
+    at_file_fd = open(at_file, O_RDWR | O_CREAT | O_EXCL, 0600);
 
-  } else if (!strcmp(out_file, "-")) {
+    if (at_file_fd < 0) PFATAL("Unable to create '%s'", at_file);
 
-    fd = dup(1);
-    if (fd < 0) PFATAL("Unable to open stdout");
+    allocated_at_file = 1;
+}
 
-  } else {
+
 
-    unlink(out_file); /* Ignore errors */
-    fd = open(out_file, O_WRONLY | O_CREAT | O_EXCL, 0600);
-    if (fd < 0) PFATAL("Unable to create '%s'", out_file);
+#define CHK_FORMAT(_divisor, _limit_mult, _fmt, _cast) do { \
+    if (val < (_divisor) * (_limit_mult)) { \
+      sprintf(tmp[cur], _fmt, ((_cast)val) / (_divisor)); \
+      return tmp[cur]; \
+    } \
+  } while (0)
+
+
+/* Describe integer as memory size. */
+
+static u8* DMS(u64 val) {
+
+  static u8 tmp[12][16];
+  static u8 cur;
+
+  cur = (cur + 1) % 12;
+
+  /* 0-9999 */
+  CHK_FORMAT(1, 10000, "%llu B", u64);
+
+  /* 10.0k - 99.9k */
+  CHK_FORMAT(1024, 99.95, "%0.01f kB", double);
+
+  /* 100k - 999k */
+  CHK_FORMAT(1024, 1000, "%llu kB", u64);
+
+  /* 1.00M - 9.99M */
+  CHK_FORMAT(1024 * 1024, 9.995, "%0.02f MB", double);
+
+  /* 10.0M - 99.9M */
+  CHK_FORMAT(1024 * 1024, 99.95, "%0.01f MB", double);
+
+  /* 100M - 999M */
+  CHK_FORMAT(1024 * 1024, 1000, "%llu MB", u64);
+
+  /* 1.00G - 9.99G */
+  CHK_FORMAT(1024LL * 1024 * 1024, 9.995, "%0.02f GB", double);
+
+  /* 10.0G - 99.9G */
+  CHK_FORMAT(1024LL * 1024 * 1024, 99.95, "%0.01f GB", double);
+
+  /* 100G - 999G */
+  CHK_FORMAT(1024LL * 1024 * 1024, 1000, "%llu GB", u64);
+
+  /* 1.00T - 9.99G */
+  CHK_FORMAT(1024LL * 1024 * 1024 * 1024, 9.995, "%0.02f TB", double);
+
+  /* 10.0T - 99.9T */
+  CHK_FORMAT(1024LL * 1024 * 1024 * 1024, 99.95, "%0.01f TB", double);
+
+#undef CHK_FORMAT
+
+  /* 100T+ */
+  strcpy(tmp[cur], "infty");
+  return tmp[cur];
+
+}
+
+
+/* Write results. */
+
+static u32 write_results(u8 *out_path) {
+
+  s32 fd;
+  u32 i, ret = 0;
+    if(no_output) {
+        return 0;
+    }
+
+    u8 cco = !!getenv("AFL_CMIN_CRASHES_ONLY"),
+       caa = !!getenv("AFL_CMIN_ALLOW_ANY");
+
+    if (!strncmp(out_path, "/dev/", 5))
+    {
+
+        fd = open(out_path, O_WRONLY, 0600);
+        if (fd < 0)
+            PFATAL("Unable to open '%s'", out_path);
+
+  } else
+  {
+
+      unlink(out_path); /* Ignore errors */
+      fd = open(out_path, O_WRONLY | O_CREAT | O_EXCL, 0600);
+      if (fd < 0)
+          PFATAL("Unable to create '%s'", out_path);
 
   }
 
@@ -193,7 +304,7 @@ static u32 write_results(void) {
     for (i = 0; i < MAP_SIZE; i++)
       if (trace_bits[i]) ret++;
     
-    ck_write(fd, trace_bits, MAP_SIZE, out_file);
+    ck_write(fd, trace_bits, MAP_SIZE, out_path);
     close(fd);
 
   } else {
@@ -222,8 +333,7 @@ static u32 write_results(void) {
 
   }
 
-  return ret;
-
+    return ret;
 }
 
 
@@ -242,64 +352,89 @@ static void handle_timeout(int sig) {
 static void run_target(char** argv) {
 
   static struct itimerval it;
+  static u32 prev_timed_out = 0;
   int status = 0;
 
   if (!quiet_mode)
     SAYF("-- Program output begins --\n" cRST);
 
+  memset(trace_bits, 0, MAP_SIZE);
   MEM_BARRIER();
 
-  child_pid = fork();
+  s32 res;
 
-  if (child_pid < 0) PFATAL("fork() failed");
+  if (in_path) {
+    /* we have the fork server up and running, so simply
+        tell it to have at it, and then read back PID. */
 
-  if (!child_pid) {
+    if ((res = write(fsrv_ctl_fd, &prev_timed_out, 4)) != 4) {
 
-    struct rlimit r;
+        if (stop_soon) return;
+        RPFATAL(res, "Unable to request new process from fork server (OOM?)");
 
-    if (quiet_mode) {
+    }
 
-      s32 fd = open("/dev/null", O_RDWR);
+    if ((res = read(fsrv_st_fd, &child_pid, 4)) != 4) {
 
-      if (fd < 0 || dup2(fd, 1) < 0 || dup2(fd, 2) < 0) {
-        *(u32*)trace_bits = EXEC_FAIL_SIG;
-        PFATAL("Descriptor initialization failed");
-      }
-
-      close(fd);
+        if (stop_soon) return;
+        RPFATAL(res, "Unable to request new process from fork server (OOM?)");
 
     }
 
-    if (mem_limit) {
+    if (child_pid <= 0) FATAL("Fork server is misbehaving (OOM?)");
+  } else {
+      child_pid = fork();
 
-      r.rlim_max = r.rlim_cur = ((rlim_t)mem_limit) << 20;
+        if (child_pid < 0) PFATAL("fork() failed");
 
-#ifdef RLIMIT_AS
+        if (!child_pid) {
 
-      setrlimit(RLIMIT_AS, &r); /* Ignore errors */
+            struct rlimit r;
 
-#else
+            if (quiet_mode) {
 
-      setrlimit(RLIMIT_DATA, &r); /* Ignore errors */
+            s32 fd = open("/dev/null", O_RDWR);
 
-#endif /* ^RLIMIT_AS */
+            if (fd < 0 || dup2(fd, 1) < 0 || dup2(fd, 2) < 0) {
+                *(u32*)trace_bits = EXEC_FAIL_SIG;
+                PFATAL("Descriptor initialization failed");
+            }
 
-    }
+            close(fd);
 
-    if (!keep_cores) r.rlim_max = r.rlim_cur = 0;
-    else r.rlim_max = r.rlim_cur = RLIM_INFINITY;
+            }
 
-    setrlimit(RLIMIT_CORE, &r); /* Ignore errors */
+            if (mem_limit) {
 
-    if (!getenv("LD_BIND_LAZY")) setenv("LD_BIND_NOW", "1", 0);
+            r.rlim_max = r.rlim_cur = ((rlim_t)mem_limit) << 20;
 
-    setsid();
+        #ifdef RLIMIT_AS
 
-    execv(target_path, argv);
+            setrlimit(RLIMIT_AS, &r); /* Ignore errors */
 
-    *(u32*)trace_bits = EXEC_FAIL_SIG;
-    exit(0);
+        #else
+
+            setrlimit(RLIMIT_DATA, &r); /* Ignore errors */
+
+        #endif /* ^RLIMIT_AS */
+
+            }
+
+            if (!keep_cores) r.rlim_max = r.rlim_cur = 0;
+            else r.rlim_max = r.rlim_cur = RLIM_INFINITY;
+
+            setrlimit(RLIMIT_CORE, &r); /* Ignore errors */
+
+            if (!getenv("LD_BIND_LAZY")) setenv("LD_BIND_NOW", "1", 0);
+ 
+            setsid();
 
+            execv(target_path, argv);
+
+            *(u32*)trace_bits = EXEC_FAIL_SIG;
+            exit(0);
+
+        }
   }
 
   /* Configure timeout, wait for child, cancel timeout. */
@@ -314,7 +449,16 @@ static void run_target(char** argv) {
 
   setitimer(ITIMER_REAL, &it, NULL);
 
-  if (waitpid(child_pid, &status, 0) <= 0) FATAL("waitpid() failed");
+    if(in_path) {
+        if ((res = read(fsrv_st_fd, &status, 4)) != 4) {
+
+            if (stop_soon) return;
+            RPFATAL(res, "Unable to communicate with fork server (OOM?)");
+
+        }
+  } else {
+      if (waitpid(child_pid, &status, 0) <= 0) FATAL("waitpid() failed");
+  }
 
   child_pid = 0;
   it.it_value.tv_sec = 0;
@@ -427,24 +571,32 @@ static void detect_file_args(char** argv
     u8* aa_loc = strstr(argv[i], "@@");
 
     if (aa_loc) {
+        using_file_arg = 1;
+
+        u8 *aa_subst, *n_arg;
 
-      u8 *aa_subst, *n_arg;
+        if (!in_path && !at_file)
+            FATAL("@@ syntax is not supported by this tool.");
 
-      if (!at_file) FATAL("@@ syntax is not supported by this tool.");
+        if (!at_file)
+            setup_at_file();
 
-      /* Be sure that we're always using fully-qualified paths. */
+        /* Be sure that we're always using fully-qualified paths. */
 
-      if (at_file[0] == '/') aa_subst = at_file;
-      else aa_subst = alloc_printf("%s/%s", cwd, at_file);
+        if (at_file[0] == '/')
+            aa_subst = at_file;
+        else
+            aa_subst = alloc_printf("%s/%s", cwd, at_file);
 
-      /* Construct a replacement argv value. */
+        /* Construct a replacement argv value. */
 
-      *aa_loc = 0;
-      n_arg = alloc_printf("%s%s%s", argv[i], aa_subst, aa_loc + 2);
-      argv[i] = n_arg;
-      *aa_loc = '@';
+        *aa_loc = 0;
+        n_arg = alloc_printf("%s%s%s", argv[i], aa_subst, aa_loc + 2);
+        argv[i] = n_arg;
+        *aa_loc = '@';
 
-      if (at_file[0] != '/') ck_free(aa_subst);
+        if (at_file[0] != '/')
+            ck_free(aa_subst);
 
     }
 
@@ -475,13 +627,16 @@ static void usage(u8* argv0) {
 
        "Required parameters:\n\n"
 
-       "  -o file       - file to write the trace data to\n\n"
+       "  -i file       - file or dir to get inputs from\n"
+       "  -o file       - file or dir to write the trace data to. Use '-' for no output\n\n"
 
        "Execution control settings:\n\n"
 
        "  -t msec       - timeout for each run (none)\n"
        "  -m megs       - memory limit for child process (%u MB)\n"
-       "  -Q            - use binary-only instrumentation (QEMU mode)\n\n"
+       "  -Q            - use binary-only instrumentation (QEMU mode)\n"
+       "  -U            - use Unicorn-based instrumentation (Unicorn mode)\n"
+       "                  (Not necessary, here for consistency with other afl-* tools)\n\n"
 
        "Other settings:\n\n"
 
@@ -615,25 +770,498 @@ static char** get_qemu_argv(u8* own_loc,
 }
 
 
+/* Spin up fork server (instrumented mode only). The idea is explained here:
+
+   http://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html
+
+   In essence, the instrumentation allows us to skip execve(), and just keep
+   cloning a stopped child. So, we just execute once, and then send commands
+   through a pipe. The other part of this logic is in afl-as.h. */
+
+static void init_forkserver(char** argv) {
+
+  static struct itimerval it;
+  int st_pipe[2], ctl_pipe[2];
+  int status;
+  s32 rlen;
+
+  ACTF("Spinning up the fork server...");
+
+  if (pipe(st_pipe) || pipe(ctl_pipe))
+      PFATAL("pipe() failed");
+
+  forksrv_pid = fork();
+
+  if (forksrv_pid < 0) PFATAL("fork() failed");
+
+  if (!forksrv_pid) {
+
+    struct rlimit r;
+
+    /* Umpf. On OpenBSD, the default fd limit for root users is set to
+       soft 128. Let's try to fix that... */
+
+    if (!getrlimit(RLIMIT_NOFILE, &r) && r.rlim_cur < FORKSRV_FD + 2) {
+
+      r.rlim_cur = FORKSRV_FD + 2;
+      setrlimit(RLIMIT_NOFILE, &r); /* Ignore errors */
+
+    }
+
+    if (mem_limit) {
+
+      r.rlim_max = r.rlim_cur = ((rlim_t)mem_limit) << 20;
+
+#ifdef RLIMIT_AS
+
+      setrlimit(RLIMIT_AS, &r); /* Ignore errors */
+
+#else
+
+      /* This takes care of OpenBSD, which doesn't have RLIMIT_AS, but
+         according to reliable sources, RLIMIT_DATA covers anonymous
+         maps - so we should be getting good protection against OOM bugs. */
+
+      setrlimit(RLIMIT_DATA, &r); /* Ignore errors */
+
+#endif /* ^RLIMIT_AS */
+
+
+    }
+
+    /* Dumping cores is slow and can lead to anomalies if SIGKILL is delivered
+       before the dump is complete. */
+
+    r.rlim_max = r.rlim_cur = 0;
+
+    setrlimit(RLIMIT_CORE, &r); /* Ignore errors */
+
+    /* Isolate the process and configure standard descriptors. If at_path is
+       specified, stdin is /dev/null; otherwise, at_file_fd is cloned instead. /
+
+    setsid();
+
+    dup2(dev_null_fd, 1);
+    dup2(dev_null_fd, 2);
+
+    if (using_file_arg) {
+        dup2(dev_null_fd, 0);
+    } else {
+
+        dup2(at_file_fd, 0);
+        close(at_file_fd);
+
+    }
+
+    /* Set up control and status pipes, close the unneeded original fds. */
+
+    if (dup2(ctl_pipe[0], FORKSRV_FD) < 0) PFATAL("dup2() failed");
+    if (dup2(st_pipe[1], FORKSRV_FD + 1) < 0) PFATAL("dup2() failed");
+
+    close(ctl_pipe[0]);
+    close(ctl_pipe[1]);
+    close(st_pipe[0]);
+    close(st_pipe[1]);
+
+    close(dev_null_fd);
+
+    /* This should improve performance a bit, since it stops the linker from
+       doing extra work post-fork(). */
+
+    if (!getenv("LD_BIND_LAZY")) setenv("LD_BIND_NOW", "1", 0);
+
+    /* Set sane defaults for ASAN if nothing else specified. */
+
+    setenv("ASAN_OPTIONS", "abort_on_error=1:"
+                           "detect_leaks=0:"
+                           "symbolize=0:"
+                           "allocator_may_return_null=1", 0);
+
+    /* MSAN is tricky, because it doesn't support abort_on_error=1 at this
+       point. So, we do this in a very hacky way. */
+
+    setenv("MSAN_OPTIONS", "exit_code=" STRINGIFY(MSAN_ERROR) ":"
+                           "symbolize=0:"
+                           "abort_on_error=1:"
+                           "allocator_may_return_null=1:"
+                           "msan_track_origins=0", 0);
+
+    execv(target_path, argv);
+
+    /* Use a distinctive bitmap signature to tell the parent about execv()
+       falling through. */
+
+    *(u32*)trace_bits = EXEC_FAIL_SIG;
+    exit(0);
+
+  }
+
+  /* Close the unneeded endpoints. */
+
+  close(ctl_pipe[0]);
+  close(st_pipe[1]);
+
+  fsrv_ctl_fd = ctl_pipe[1];
+  fsrv_st_fd  = st_pipe[0];
+
+  /* Wait for the fork server to come up, but don't wait too long. */
+
+  it.it_value.tv_sec = ((exec_tmout * FORK_WAIT_MULT) / 1000);
+  it.it_value.tv_usec = ((exec_tmout * FORK_WAIT_MULT) % 1000) * 1000;
+
+  setitimer(ITIMER_REAL, &it, NULL);
+
+  rlen = read(fsrv_st_fd, &status, 4);
+
+  it.it_value.tv_sec = 0;
+  it.it_value.tv_usec = 0;
+
+  setitimer(ITIMER_REAL, &it, NULL);
+
+  /* If we have a four-byte "hello" message from the server, we're all set.
+     Otherwise, try to figure out what went wrong. */
+
+  if (rlen == 4) {
+      OKF("All right - fork server is up.");
+      return;
+  }
+
+  if (child_timed_out)
+    FATAL("Timeout while initializing fork server (adjusting -t may help)");
+
+  if (waitpid(forksrv_pid, &status, 0) <= 0) {
+      PFATAL("waitpid() failed");
+  }
+
+  if (WIFSIGNALED(status)) {
+
+    /*if (mem_limit && mem_limit < 500 && uses_asan) {
+
+      SAYF("\n" cLRD "[-] " cRST
+           "Whoops, the target binary crashed suddenly, before receiving any input\n"
+           "    from the fuzzer! Since it seems to be built with ASAN and you have a\n"
+           "    restrictive memory limit configured, this is expected; please read\n"
+           "    %s/notes_for_asan.txt for help.\n", doc_path);
+
+    } else */if (!mem_limit) {
+
+      SAYF("\n" cLRD "[-] " cRST
+           "Whoops, the target binary crashed suddenly, before receiving any input\n"
+           "    from the fuzzer! There are several probable explanations:\n\n"
+
+           "    - The binary is just buggy and explodes entirely on its own. If so, you\n"
+           "      need to fix the underlying problem or find a better replacement.\n\n"
+
+#ifdef __APPLE__
+
+           "    - On MacOS X, the semantics of fork() syscalls are non-standard and may\n"
+           "      break afl-fuzz performance optimizations when running platform-specific\n"
+           "      targets. To fix this, set AFL_NO_FORKSRV=1 in the environment.\n\n"
+
+#endif /* __APPLE__ */
+
+           "    - Less likely, there is a horrible bug in the fuzzer. If other options\n"
+           "      fail, poke <lcamtuf@coredump.cx> for troubleshooting tips.\n");
+
+    } else {
+
+      SAYF("\n" cLRD "[-] " cRST
+           "Whoops, the target binary crashed suddenly, before receiving any input\n"
+           "    from the fuzzer! There are several probable explanations:\n\n"
+
+           "    - The current memory limit (%s) is too restrictive, causing the\n"
+           "      target to hit an OOM condition in the dynamic linker. Try bumping up\n"
+           "      the limit with the -m setting in the command line. A simple way confirm\n"
+           "      this diagnosis would be:\n\n"
+
+#ifdef RLIMIT_AS
+           "      ( ulimit -Sv $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#else
+           "      ( ulimit -Sd $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#endif /* ^RLIMIT_AS */
+
+           "      Tip: you can use http://jwilk.net/software/recidivm to quickly\n"
+           "      estimate the required amount of virtual memory for the binary.\n\n"
+
+           "    - The binary is just buggy and explodes entirely on its own. If so, you\n"
+           "      need to fix the underlying problem or find a better replacement.\n\n"
+
+#ifdef __APPLE__
+
+           "    - On MacOS X, the semantics of fork() syscalls are non-standard and may\n"
+           "      break afl-fuzz performance optimizations when running platform-specific\n"
+           "      targets. To fix this, set AFL_NO_FORKSRV=1 in the environment.\n\n"
+
+#endif /* __APPLE__ */
+
+           "    - Less likely, there is a horrible bug in the fuzzer. If other options\n"
+           "      fail, poke <lcamtuf@coredump.cx> for troubleshooting tips.\n",
+           DMS(mem_limit << 20), mem_limit - 1);
+
+    }
+
+    FATAL("Fork server crashed with signal %d", WTERMSIG(status));
+
+  }
+
+  if (*(u32*)trace_bits == EXEC_FAIL_SIG)
+    FATAL("Unable to execute target application ('%s')", argv[0]);
+
+  /*if (mem_limit && mem_limit < 500 && uses_asan) {
+
+    SAYF("\n" cLRD "[-] " cRST
+           "Hmm, looks like the target binary terminated before we could complete a\n"
+           "    handshake with the injected code. Since it seems to be built with ASAN and\n"
+           "    you have a restrictive memory limit configured, this is expected; please\n"
+           "    read %s/notes_for_asan.txt for help.\n", doc_path);
+
+  } else */if (!mem_limit) {
+
+    SAYF("\n" cLRD "[-] " cRST
+         "Hmm, looks like the target binary terminated before we could complete a\n"
+         "    handshake with the injected code. Perhaps there is a horrible bug in the\n"
+         "    fuzzer. Poke <lcamtuf@coredump.cx> for troubleshooting tips.\n");
+
+  } else {
+
+    SAYF("\n" cLRD "[-] " cRST
+         "Hmm, looks like the target binary terminated before we could complete a\n"
+         "    handshake with the injected code. There are %s probable explanations:\n\n"
+
+         "%s"
+         "    - The current memory limit (%s) is too restrictive, causing an OOM\n"
+         "      fault in the dynamic linker. This can be fixed with the -m option. A\n"
+         "      simple way to confirm the diagnosis may be:\n\n"
+
+#ifdef RLIMIT_AS
+         "      ( ulimit -Sv $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#else
+         "      ( ulimit -Sd $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#endif /* ^RLIMIT_AS */
+
+         "      Tip: you can use http://jwilk.net/software/recidivm to quickly\n"
+         "      estimate the required amount of virtual memory for the binary.\n\n"
+
+         "    - Less likely, there is a horrible bug in the fuzzer. If other options\n"
+         "      fail, poke <lcamtuf@coredump.cx> for troubleshooting tips.\n",
+         getenv(DEFER_ENV_VAR) ? "three" : "two",
+         getenv(DEFER_ENV_VAR) ?
+         "    - You are using deferred forkserver, but __AFL_INIT() is never\n"
+         "      reached before the program terminates.\n\n" : "",
+         DMS(mem_limit << 20), mem_limit - 1);
+
+  }
+
+  FATAL("Fork server handshake failed");
+
+}
+
+
+/* Write modified data to file for testing. If using_file_arg is set, the old file
+   is unlinked and a new one is created. Otherwise, at_file_fd is rewound and
+   truncated. */
+
+static void write_to_testcase(u8* mem, u32 len) {
+
+  s32 fd = at_file_fd;
+
+  // SAYF("Writing to testcase: at_path='%s', mem='%s', len=%d\n", at_path, mem, len);
+
+  if (using_file_arg) {
+
+    unlink(at_file); /* Ignore errors. */
+
+    fd = open(at_file, O_WRONLY | O_CREAT | O_EXCL, 0600);
+
+    if (fd < 0) PFATAL("Unable to create '%s'", at_file);
+
+  } else lseek(fd, 0, SEEK_SET);
+
+  ck_write(fd, mem, len, at_file);
+
+  if (!using_file_arg) {
+
+    if (ftruncate(fd, len)) PFATAL("ftruncate() failed");
+    lseek(fd, 0, SEEK_SET);
+
+  } else close(fd);
+
+}
+
+static void do_testcase(char **argv, struct queue_entry *q) {
+    u8* use_mem;
+    s32 fd;
+
+    fd = open(q->in_path, O_RDONLY);
+    if (fd < 0) PFATAL("Unable to open '%s'", q->in_path);
+
+    use_mem = ck_alloc_nozero(q->in_len);
+
+    if (read(fd, use_mem, q->in_len) != q->in_len)
+    FATAL("Short read from '%s'", q->in_path);
+
+    close(fd);
+
+    write_to_testcase(use_mem, q->in_len);
+    ck_free(use_mem);
+    if (stop_soon) return;
+        child_crashed = 0;
+        run_target(argv);
+        if(!child_crashed) {
+            write_results(q->out_path);
+        }
+    }
+
+static void add_to_queue(u8 *in_path, u32 in_len, u8 *out_path)
+{
+  struct queue_entry *q = ck_alloc(sizeof(struct queue_entry));
+
+    q->in_path = in_path;
+  q->in_len = in_len;
+  q->out_path = out_path;
+
+  if (queue_top)
+  {
+     q->next = queue_top;
+     queue_top = q;
+  } else queue = queue_top = q;
+
+  queued_paths++;
+}
+
+/* Read all testcases from the input directory, then queue them for testing.
+   Called at startup. */
+
+static void read_testcases(u8 *in_dir, u8 *out_dir) {
+
+  struct dirent **nl;
+  s32 nl_cnt;
+  u32 i;
+
+  ACTF("Scanning '%s'...", in_dir);
+
+  /* We use scandir() + alphasort() rather than readdir() because otherwise,
+     the ordering  of test cases would vary somewhat randomly and would be
+     difficult to control. */
+
+  nl_cnt = scandir(in_dir, &nl, NULL, alphasort);
+
+  if (nl_cnt < 0) {
+
+    if (errno == ENOENT || errno == ENOTDIR)
+
+    PFATAL("Unable to open '%s'", in_dir);
+
+  }
+
+  for (i = 0; i < nl_cnt; i++) {
+
+    struct stat st;
+
+    u8* ifn = alloc_printf("%s/%s", in_dir, nl[i]->d_name);
+    u8* ofn = alloc_printf("%s/%s", out_dir, nl[i]->d_name);
+
+    free(nl[i]); /* not tracked */
+ 
+    if (lstat(ifn, &st) || access(ifn, R_OK))
+      PFATAL("Unable to access '%s'", ifn);
+
+    /* This also takes care of . and .. */
+
+    if (!S_ISREG(st.st_mode) || !st.st_size || strstr(ifn, "/README.txt")) {
+
+      ck_free(ifn);
+      ck_free(ofn);
+      continue;
+
+    }
+
+    if (st.st_size > MAX_FILE) 
+      FATAL("Test case '%s' is too big (%s, limit is %s)", ifn,
+            DMS(st.st_size), DMS(MAX_FILE));
+
+    add_to_queue(ifn, st.st_size, ofn);
+  }
+
+  free(nl); /* not tracked */
+
+  if (!queued_paths) {
+
+    SAYF("\n" cLRD "[-] " cRST
+         "Looks like there are no valid test cases in the input directory! The fuzzer\n"
+         "    needs one or more test case to start with - ideally, a small file under\n"
+         "    1 kB or so. The cases must be stored as regular files directly in the\n"
+         "    input directory.\n");
+
+    FATAL("No usable test cases in '%s'", in_dir);
+
+  }
+
+}
+
+void build_job_queue(u8 *in_path, u8 *out_path) {
+    struct stat in_path_stat;
+    struct stat out_path_stat;
+
+    if(stat(in_path, &in_path_stat) == -1) {
+        FATAL("Cannot open input path '%s'", in_path);
+    }
+    batch_mode = S_ISDIR(in_path_stat.st_mode);
+
+    if(!batch_mode && (!S_ISREG(in_path_stat.st_mode) || access(in_path, F_OK))) {
+        FATAL("Cannot open input path or no regular file '%s'", in_path);
+    }
+    
+    if(out_path) {
+        if (stat(out_path, &out_path_stat) == 0){
+            if (batch_mode != S_ISDIR(out_path_stat.st_mode)) {
+                FATAL("Output target type and batch mode do not match");
+            }
+        } else if(batch_mode) {
+            mkdir(out_path, 0700);
+        }
+    }
+
+    if(batch_mode) {
+
+        read_testcases(in_path, out_path);
+
+    } else {
+
+        // single entry
+        u8* ifn = alloc_printf("%s", in_path);
+        u8* ofn = alloc_printf("%s", out_path);
+
+        add_to_queue(ifn, in_path_stat.st_size, ofn);
+    }
+}
+
 /* Main entry point */
 
 int main(int argc, char** argv) {
 
   s32 opt;
-  u8  mem_limit_given = 0, timeout_given = 0, qemu_mode = 0;
-  u32 tcnt;
+  u8  mem_limit_given = 0, timeout_given = 0, qemu_mode = 0, unicorn_mode = 0;
   char** use_argv;
 
   doc_path = access(DOC_PATH, F_OK) ? "docs" : DOC_PATH;
 
-  while ((opt = getopt(argc,argv,"+o:m:t:A:eqZQbc")) > 0)
+  while ((opt = getopt(argc,argv,"+o:m:t:A:eqZQUbc")) > 0)
 
     switch (opt) {
 
+      case 'i': /* input dir */
+
+        if (in_path) FATAL("Multiple -i options not supported");
+            in_path = optarg;
+        
+            break;
+
       case 'o':
 
-        if (out_file) FATAL("Multiple -o options not supported");
-        out_file = optarg;
+        if (out_path) FATAL("Multiple -o options not supported");
+        out_path = optarg;
+        
         break;
 
       case 'm': {
@@ -723,6 +1351,14 @@ int main(int argc, char** argv) {
         qemu_mode = 1;
         break;
 
+      case 'U':
+
+        if (unicorn_mode) FATAL("Multiple -U options not supported");
+        if (!mem_limit_given) mem_limit = MEM_LIMIT_UNICORN;
+
+        unicorn_mode = 1;
+        break;
+
       case 'b':
 
         /* Secret undocumented mode. Writes output in raw binary format
@@ -738,23 +1374,22 @@ int main(int argc, char** argv) {
         break;
 
       default:
-
         usage(argv[0]);
-
     }
 
-  if (optind == argc || !out_file) usage(argv[0]);
+  if (optind == argc) usage(argv[0]);
+  
+  if ( !out_path )
+      no_output = 1;
 
   setup_shm();
   setup_signal_handlers();
-
   set_up_environment();
-
   find_binary(argv[optind]);
 
   if (!quiet_mode) {
-    show_banner();
-    ACTF("Executing '%s'...\n", target_path);
+      show_banner();
+      ACTF("Executing '%s'...\n", target_path);
   }
 
   detect_file_args(argv + optind);
@@ -763,16 +1398,44 @@ int main(int argc, char** argv) {
     use_argv = get_qemu_argv(argv[0], argv + optind, argc - optind);
   else
     use_argv = argv + optind;
-
-  run_target(use_argv);
-
-  tcnt = write_results();
-
-  if (!quiet_mode) {
-
-    if (!tcnt) FATAL("No instrumentation detected" cRST);
-    OKF("Captured %u tuples in '%s'." cRST, tcnt, out_file);
-
+  if(in_path) {
+      build_job_queue(in_path, out_path);
+      
+      if(!at_file) {
+        setup_at_file();
+      }
+      
+      init_forkserver(use_argv);
+      
+      struct queue_entry *entry;
+      while (queued_paths-- != 0)
+      {
+        do_testcase(argv, queue_top);
+    
+        ck_free(queue_top->in_path);
+        ck_free(queue_top->out_path);
+        
+        entry = queue_top;
+        queue_top = queue_top->next;
+        ck_free(entry);
+    
+      }      
+      unlink(at_file);
+      if (allocated_at_file)
+      {
+        ck_free(at_file);
+      }
+  } else {
+      
+      // stdin used as input, normal operation
+      run_target(use_argv);
+      
+      u32 tcnt = write_results(out_path);
+      
+      if(!quiet_mode) {
+        if (!tcnt) FATAL("No instrumentation detected" cRST);
+        OKF("Captured %u tuples in '%s'." cRST, tcnt, out_path);
+      }
   }
 
   exit(child_crashed * 2 + child_timed_out);
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-tmin.c afl/afl-tmin.c
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-tmin.c	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-tmin.c	2024-12-05 22:42:45.515486225 +0800
@@ -44,7 +44,11 @@
 #include <sys/types.h>
 #include <sys/resource.h>
 
-static s32 child_pid;                 /* PID of the tested program         */
+static s32 forksrv_pid,               /* PID of the fork server           */
+           child_pid;                 /* PID of the tested program        */
+
+static s32 fsrv_ctl_fd,               /* Fork server control pipe (write) */
+           fsrv_st_fd;                /* Fork server status pipe (read)   */
 
 static u8 *trace_bits,                /* SHM with instrumentation bitmap   */
           *mask_bitmap;               /* Mask for trace bits (-B)          */
@@ -68,7 +72,8 @@ static u32 in_len,                    /*
 static u64 mem_limit = MEM_LIMIT;     /* Memory limit (MB)                 */
 
 static s32 shm_id,                    /* ID of the SHM region              */
-           dev_null_fd = -1;          /* FD to /dev/null                   */
+           dev_null_fd = -1,          /* FD to /dev/null                   */
+           prog_in_fd;                /* Persistent fd for out_file        */
 
 static u8  crash_mode,                /* Crash-centric mode?               */
            exit_crash,                /* Treat non-zero exit as crash?     */
@@ -153,6 +158,159 @@ static inline u8 anything_set(void) {
 }
 
 
+/* Describe integer. Uses 12 cyclic static buffers for return values. The value
+   returned should be five characters or less for all the integers we reasonably
+   expect to see. */
+
+static u8* DI(u64 val) {
+
+  static u8 tmp[12][16];
+  static u8 cur;
+
+  cur = (cur + 1) % 12;
+
+#define CHK_FORMAT(_divisor, _limit_mult, _fmt, _cast) do { \
+    if (val < (_divisor) * (_limit_mult)) { \
+      sprintf(tmp[cur], _fmt, ((_cast)val) / (_divisor)); \
+      return tmp[cur]; \
+    } \
+  } while (0)
+
+  /* 0-9999 */
+  CHK_FORMAT(1, 10000, "%llu", u64);
+
+  /* 10.0k - 99.9k */
+  CHK_FORMAT(1000, 99.95, "%0.01fk", double);
+
+  /* 100k - 999k */
+  CHK_FORMAT(1000, 1000, "%lluk", u64);
+
+  /* 1.00M - 9.99M */
+  CHK_FORMAT(1000 * 1000, 9.995, "%0.02fM", double);
+
+  /* 10.0M - 99.9M */
+  CHK_FORMAT(1000 * 1000, 99.95, "%0.01fM", double);
+
+  /* 100M - 999M */
+  CHK_FORMAT(1000 * 1000, 1000, "%lluM", u64);
+
+  /* 1.00G - 9.99G */
+  CHK_FORMAT(1000LL * 1000 * 1000, 9.995, "%0.02fG", double);
+
+  /* 10.0G - 99.9G */
+  CHK_FORMAT(1000LL * 1000 * 1000, 99.95, "%0.01fG", double);
+
+  /* 100G - 999G */
+  CHK_FORMAT(1000LL * 1000 * 1000, 1000, "%lluG", u64);
+
+  /* 1.00T - 9.99G */
+  CHK_FORMAT(1000LL * 1000 * 1000 * 1000, 9.995, "%0.02fT", double);
+
+  /* 10.0T - 99.9T */
+  CHK_FORMAT(1000LL * 1000 * 1000 * 1000, 99.95, "%0.01fT", double);
+
+  /* 100T+ */
+  strcpy(tmp[cur], "infty");
+  return tmp[cur];
+
+}
+
+
+/* Describe float. Similar to the above, except with a single 
+   static buffer. */
+
+static u8* DF(double val) {
+
+  static u8 tmp[16];
+
+  if (val < 99.995) {
+    sprintf(tmp, "%0.02f", val);
+    return tmp;
+  }
+
+  if (val < 999.95) {
+    sprintf(tmp, "%0.01f", val);
+    return tmp;
+  }
+
+  return DI((u64)val);
+
+}
+
+
+/* Describe integer as memory size. */
+
+static u8* DMS(u64 val) {
+
+  static u8 tmp[12][16];
+  static u8 cur;
+
+  cur = (cur + 1) % 12;
+
+  /* 0-9999 */
+  CHK_FORMAT(1, 10000, "%llu B", u64);
+
+  /* 10.0k - 99.9k */
+  CHK_FORMAT(1024, 99.95, "%0.01f kB", double);
+
+  /* 100k - 999k */
+  CHK_FORMAT(1024, 1000, "%llu kB", u64);
+
+  /* 1.00M - 9.99M */
+  CHK_FORMAT(1024 * 1024, 9.995, "%0.02f MB", double);
+
+  /* 10.0M - 99.9M */
+  CHK_FORMAT(1024 * 1024, 99.95, "%0.01f MB", double);
+
+  /* 100M - 999M */
+  CHK_FORMAT(1024 * 1024, 1000, "%llu MB", u64);
+
+  /* 1.00G - 9.99G */
+  CHK_FORMAT(1024LL * 1024 * 1024, 9.995, "%0.02f GB", double);
+
+  /* 10.0G - 99.9G */
+  CHK_FORMAT(1024LL * 1024 * 1024, 99.95, "%0.01f GB", double);
+
+  /* 100G - 999G */
+  CHK_FORMAT(1024LL * 1024 * 1024, 1000, "%llu GB", u64);
+
+  /* 1.00T - 9.99G */
+  CHK_FORMAT(1024LL * 1024 * 1024 * 1024, 9.995, "%0.02f TB", double);
+
+  /* 10.0T - 99.9T */
+  CHK_FORMAT(1024LL * 1024 * 1024 * 1024, 99.95, "%0.01f TB", double);
+
+#undef CHK_FORMAT
+
+  /* 100T+ */
+  strcpy(tmp[cur], "infty");
+  return tmp[cur];
+
+}
+
+
+/* Describe time delta. Returns one static buffer, 34 chars of less. */
+
+static u8* DTD(u64 cur_ms, u64 event_ms) {
+
+  static u8 tmp[64];
+  u64 delta;
+  s32 t_d, t_h, t_m, t_s;
+
+  if (!event_ms) return "none seen yet";
+
+  delta = cur_ms - event_ms;
+
+  t_d = delta / 1000 / 60 / 60 / 24;
+  t_h = (delta / 1000 / 60 / 60) % 24;
+  t_m = (delta / 1000 / 60) % 60;
+  t_s = (delta / 1000) % 60;
+
+  sprintf(tmp, "%s days, %u hrs, %u min, %u sec", DI(t_d), t_h, t_m, t_s);
+  return tmp;
+
+}
+
 
 /* Get rid of shared memory and temp files (atexit handler). */
 
@@ -237,6 +395,36 @@ static s32 write_to_file(u8* path, u8* m
 }
 
 
+/* Write modified data to file for testing. If use_stdin is not set, the old file
+   is unlinked and a new one is created. Otherwise, prog_in_fd is rewound and
+   truncated. */
+
+static void write_to_testcase(void* mem, u32 len) {
+
+  s32 fd = prog_in_fd;
+
+  if (!use_stdin) {
+
+    unlink(prog_in); /* Ignore errors. */
+
+    fd = open(prog_in, O_WRONLY | O_CREAT | O_EXCL, 0600);
+
+    if (fd < 0) PFATAL("Unable to create '%s'", prog_in);
+
+  } else lseek(fd, 0, SEEK_SET);
+
+  ck_write(fd, mem, len, prog_in);
+
+  if (use_stdin) {
+
+    if (ftruncate(fd, len)) PFATAL("ftruncate() failed");
+    lseek(fd, 0, SEEK_SET);
+
+  } else close(fd);
+
+}
+
+
 /* Handle timeout signal. */
 
 static void handle_timeout(int sig) {
@@ -246,44 +434,42 @@ static void handle_timeout(int sig) {
 
 }
 
+/* Spin up fork server (instrumented mode only). The idea is explained here:
 
-/* Execute target application. Returns 0 if the changes are a dud, or
-   1 if they should be kept. */
+   http://lcamtuf.blogspot.com/2014/10/fuzzing-binaries-without-execve.html
 
-static u8 run_target(char** argv, u8* mem, u32 len, u8 first_run) {
+   In essence, the instrumentation allows us to skip execve(), and just keep
+   cloning a stopped child. So, we just execute once, and then send commands
+   through a pipe. The other part of this logic is in afl-as.h. */
+
+static void init_forkserver(char** argv) {
 
   static struct itimerval it;
-  int status = 0;
+  int st_pipe[2], ctl_pipe[2];
+  int status;
+  s32 rlen;
 
-  s32 prog_in_fd;
-  u32 cksum;
+  ACTF("Spinning up the fork server...");
 
-  memset(trace_bits, 0, MAP_SIZE);
-  MEM_BARRIER();
+  if (pipe(st_pipe) || pipe(ctl_pipe)) PFATAL("pipe() failed");
 
-  prog_in_fd = write_to_file(prog_in, mem, len);
+  forksrv_pid = fork();
 
-  child_pid = fork();
+  if (forksrv_pid < 0) PFATAL("fork() failed");
 
-  if (child_pid < 0) PFATAL("fork() failed");
-
-  if (!child_pid) {
+  if (!forksrv_pid) {
 
     struct rlimit r;
 
-    if (dup2(use_stdin ? prog_in_fd : dev_null_fd, 0) < 0 ||
-        dup2(dev_null_fd, 1) < 0 ||
-        dup2(dev_null_fd, 2) < 0) {
-
-      *(u32*)trace_bits = EXEC_FAIL_SIG;
-      PFATAL("dup2() failed");
+    /* Umpf. On OpenBSD, the default fd limit for root users is set to
+       soft 128. Let's try to fix that... */
 
-    }
+    if (!getrlimit(RLIMIT_NOFILE, &r) && r.rlim_cur < FORKSRV_FD + 2) {
 
-    close(dev_null_fd);
-    close(prog_in_fd);
+      r.rlim_cur = FORKSRV_FD + 2;
+      setrlimit(RLIMIT_NOFILE, &r); /* Ignore errors */
 
-    setsid();
+    }
 
     if (mem_limit) {
 
@@ -295,23 +481,281 @@ static u8 run_target(char** argv, u8* me
 
 #else
 
+      /* This takes care of OpenBSD, which doesn't have RLIMIT_AS, but
+         according to reliable sources, RLIMIT_DATA covers anonymous
+         maps - so we should be getting good protection against OOM bugs. */
+
       setrlimit(RLIMIT_DATA, &r); /* Ignore errors */
 
 #endif /* ^RLIMIT_AS */
 
+
     }
 
+    /* Dumping cores is slow and can lead to anomalies if SIGKILL is delivered
+       before the dump is complete. */
+
     r.rlim_max = r.rlim_cur = 0;
+    
     setrlimit(RLIMIT_CORE, &r); /* Ignore errors */
 
+    /* Isolate the process and configure standard descriptors. If out_file is
+       specified, stdin is /dev/null; otherwise, out_fd is cloned instead. */
+
+    setsid();
+
+    dup2(dev_null_fd, 1);
+    dup2(dev_null_fd, 2);
+
+    if (out_file) {
+        dup2(dev_null_fd, 0);
+    } else {
+
+        dup2(prog_in_fd, 0);
+        close(prog_in_fd);
+
+    }
+
+    /* Set up control and status pipes, close the unneeded original fds. */
+
+    if (dup2(ctl_pipe[0], FORKSRV_FD) < 0) PFATAL("dup2() failed");
+    if (dup2(st_pipe[1], FORKSRV_FD + 1) < 0) PFATAL("dup2() failed");
+
+    close(ctl_pipe[0]);
+    close(ctl_pipe[1]);
+    close(st_pipe[0]);
+    close(st_pipe[1]);
+
+    close(dev_null_fd);
+
+    /* This should improve performance a bit, since it stops the linker from
+       doing extra work post-fork(). */
+
+    if (!getenv("LD_BIND_LAZY")) setenv("LD_BIND_NOW", "1", 0);
+
+    /* Set sane defaults for ASAN if nothing else specified. */
+
+    setenv("ASAN_OPTIONS", "abort_on_error=1:"
+                           "detect_leaks=0:"
+                           "symbolize=0:"
+                           "allocator_may_return_null=1", 0);
+
+    /* MSAN is tricky, because it doesn't support abort_on_error=1 at this
+       point. So, we do this in a very hacky way. */
+
+    setenv("MSAN_OPTIONS", "exit_code=" STRINGIFY(MSAN_ERROR) ":"
+                           "symbolize=0:"
+                           "abort_on_error=1:"
+                           "allocator_may_return_null=1:"
+                           "msan_track_origins=0", 0);
+
     execv(target_path, argv);
 
+    /* Use a distinctive bitmap signature to tell the parent about execv()
+       falling through. */
+
     *(u32*)trace_bits = EXEC_FAIL_SIG;
     exit(0);
 
   }
 
-  close(prog_in_fd);
+  /* Close the unneeded endpoints. */
+
+  close(ctl_pipe[0]);
+  close(st_pipe[1]);
+
+  fsrv_ctl_fd = ctl_pipe[1];
+  fsrv_st_fd  = st_pipe[0];
+
+  /* Wait for the fork server to come up, but don't wait too long. */
+
+  it.it_value.tv_sec = ((exec_tmout * FORK_WAIT_MULT) / 1000);
+  it.it_value.tv_usec = ((exec_tmout * FORK_WAIT_MULT) % 1000) * 1000;
+
+  setitimer(ITIMER_REAL, &it, NULL);
+
+  rlen = read(fsrv_st_fd, &status, 4);
+
+  it.it_value.tv_sec = 0;
+  it.it_value.tv_usec = 0;
+
+  setitimer(ITIMER_REAL, &it, NULL);
+
+  /* If we have a four-byte "hello" message from the server, we're all set.
+     Otherwise, try to figure out what went wrong. */
+
+  if (rlen == 4) {
+    OKF("All right - fork server is up.");
+    return;
+  }
+
+  if (child_timed_out)
+    FATAL("Timeout while initializing fork server (adjusting -t may help)");
+
+  if (waitpid(forksrv_pid, &status, 0) <= 0)
+    PFATAL("waitpid() failed");
+
+  if (WIFSIGNALED(status)) {
+
+    /*if (mem_limit && mem_limit < 500 && uses_asan) {
+
+      SAYF("\n" cLRD "[-] " cRST
+           "Whoops, the target binary crashed suddenly, before receiving any input\n"
+           "    from the fuzzer! Since it seems to be built with ASAN and you have a\n"
+           "    restrictive memory limit configured, this is expected; please read\n"
+           "    %s/notes_for_asan.txt for help.\n", doc_path);
+
+    } else */if (!mem_limit) {
+
+      SAYF("\n" cLRD "[-] " cRST
+           "Whoops, the target binary crashed suddenly, before receiving any input\n"
+           "    from the fuzzer! There are several probable explanations:\n\n"
+
+           "    - The binary is just buggy and explodes entirely on its own. If so, you\n"
+           "      need to fix the underlying problem or find a better replacement.\n\n"
+
+#ifdef __APPLE__
+
+           "    - On MacOS X, the semantics of fork() syscalls are non-standard and may\n"
+           "      break afl-fuzz performance optimizations when running platform-specific\n"
+           "      targets. To fix this, set AFL_NO_FORKSRV=1 in the environment.\n\n"
+
+#endif /* __APPLE__ */
+
+           "    - Less likely, there is a horrible bug in the fuzzer. If other options\n"
+           "      fail, poke <lcamtuf@coredump.cx> for troubleshooting tips.\n");
+
+    } else {
+
+      SAYF("\n" cLRD "[-] " cRST
+           "Whoops, the target binary crashed suddenly, before receiving any input\n"
+           "    from the fuzzer! There are several probable explanations:\n\n"
+
+           "    - The current memory limit (%s) is too restrictive, causing the\n"
+           "      target to hit an OOM condition in the dynamic linker. Try bumping up\n"
+           "      the limit with the -m setting in the command line. A simple way confirm\n"
+           "      this diagnosis would be:\n\n"
+
+#ifdef RLIMIT_AS
+           "      ( ulimit -Sv $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#else
+           "      ( ulimit -Sd $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#endif /* ^RLIMIT_AS */
+
+           "      Tip: you can use http://jwilk.net/software/recidivm to quickly\n"
+           "      estimate the required amount of virtual memory for the binary.\n\n"
+
+           "    - The binary is just buggy and explodes entirely on its own. If so, you\n"
+           "      need to fix the underlying problem or find a better replacement.\n\n"
+
+#ifdef __APPLE__
+
+           "    - On MacOS X, the semantics of fork() syscalls are non-standard and may\n"
+           "      break afl-fuzz performance optimizations when running platform-specific\n"
+           "      targets. To fix this, set AFL_NO_FORKSRV=1 in the environment.\n\n"
+
+#endif /* __APPLE__ */
+
+           "    - Less likely, there is a horrible bug in the fuzzer. If other options\n"
+           "      fail, poke <lcamtuf@coredump.cx> for troubleshooting tips.\n",
+           DMS(mem_limit << 20), mem_limit - 1);
+
+    }
+
+    FATAL("Fork server crashed with signal %d", WTERMSIG(status));
+
+  }
+
+  if (*(u32*)trace_bits == EXEC_FAIL_SIG)
+    FATAL("Unable to execute target application ('%s')", argv[0]);
+
+  /*if (mem_limit && mem_limit < 500 && uses_asan) {
+
+    SAYF("\n" cLRD "[-] " cRST
+           "Hmm, looks like the target binary terminated before we could complete a\n"
+           "    handshake with the injected code. Since it seems to be built with ASAN and\n"
+           "    you have a restrictive memory limit configured, this is expected; please\n"
+           "    read %s/notes_for_asan.txt for help.\n", doc_path);
+
+  } else */if (!mem_limit) {
+
+    SAYF("\n" cLRD "[-] " cRST
+         "Hmm, looks like the target binary terminated before we could complete a\n"
+         "    handshake with the injected code. Perhaps there is a horrible bug in the\n"
+         "    fuzzer. Poke <lcamtuf@coredump.cx> for troubleshooting tips.\n");
+
+  } else {
+
+    SAYF("\n" cLRD "[-] " cRST
+         "Hmm, looks like the target binary terminated before we could complete a\n"
+         "    handshake with the injected code. There are %s probable explanations:\n\n"
+
+         "%s"
+         "    - The current memory limit (%s) is too restrictive, causing an OOM\n"
+         "      fault in the dynamic linker. This can be fixed with the -m option. A\n"
+         "      simple way to confirm the diagnosis may be:\n\n"
+
+#ifdef RLIMIT_AS
+         "      ( ulimit -Sv $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#else
+         "      ( ulimit -Sd $[%llu << 10]; /path/to/fuzzed_app )\n\n"
+#endif /* ^RLIMIT_AS */
+
+         "      Tip: you can use http://jwilk.net/software/recidivm to quickly\n"
+         "      estimate the required amount of virtual memory for the binary.\n\n"
+
+         "    - Less likely, there is a horrible bug in the fuzzer. If other options\n"
+         "      fail, poke <lcamtuf@coredump.cx> for troubleshooting tips.\n",
+         getenv(DEFER_ENV_VAR) ? "three" : "two",
+         getenv(DEFER_ENV_VAR) ?
+         "    - You are using deferred forkserver, but __AFL_INIT() is never\n"
+         "      reached before the program terminates.\n\n" : "",
+         DMS(mem_limit << 20), mem_limit - 1);
+
+  }
+
+  FATAL("Fork server handshake failed");
+
+}
+
+
+/* Execute target application. Returns 0 if the changes are a dud, or
+   1 if they should be kept. */
+
+static u8 run_target(char** argv, u8* mem, u32 len, u8 first_run) {
+
+  static struct itimerval it;
+  static u32 prev_timed_out = 0;
+  int status = 0;
+
+  u32 cksum;
+
+  memset(trace_bits, 0, MAP_SIZE);
+  MEM_BARRIER();
+
+  write_to_testcase(mem, len);
+
+  s32 res;
+
+  /* In non-dumb mode, we have the fork server up and running, so simply
+     tell it to have at it, and then read back PID. */
+
+  if ((res = write(fsrv_ctl_fd, &prev_timed_out, 4)) != 4) {
+
+      if (stop_soon) return 0;
+      RPFATAL(res, "Unable to request new process from fork server (OOM?)");
+
+  }
+
+  if ((res = read(fsrv_st_fd, &child_pid, 4)) != 4) {
+
+      if (stop_soon) return 0;
+      RPFATAL(res, "Unable to request new process from fork server (OOM?)");
+
+  }
+
+  if (child_pid <= 0) FATAL("Fork server is misbehaving (OOM?)");
+
 
   /* Configure timeout, wait for child, cancel timeout. */
 
@@ -321,7 +765,12 @@ static u8 run_target(char** argv, u8* me
 
   setitimer(ITIMER_REAL, &it, NULL);
 
-  if (waitpid(child_pid, &status, 0) <= 0) FATAL("waitpid() failed");
+  if ((res = read(fsrv_st_fd, &status, 4)) != 4) {
+
+      if (stop_soon) return 0;
+      RPFATAL(res, "Unable to communicate with fork server (OOM?)");
+
+  }
 
   child_pid = 0;
   it.it_value.tv_sec = 0;
@@ -376,7 +825,7 @@ static u8 run_target(char** argv, u8* me
 
     }
 
-  } else
+  }
 
   /* Handle non-crashing inputs appropriately. */
 
@@ -409,7 +858,6 @@ static u32 next_p2(u32 val) {
 
 }
 
-
 /* Actually minimize! */
 
 static void minimize(char** argv) {
@@ -420,8 +868,9 @@ static void minimize(char** argv) {
   u32 orig_len = in_len, stage_o_len;
 
   u32 del_len, set_len, del_pos, set_pos, i, alpha_size, cur_pass = 0;
-  u32 syms_removed, alpha_del0 = 0, alpha_del1, alpha_del2, alpha_d_total = 0;
+  u32 syms_removed, alpha_del0 = 0, alpha_del1, alpha_del2, alpha_d_total = 0, bits_zeroed, total_bits_zeroed = 0;
   u8  changed_any, prev_del;
+  s32 j;
 
   /***********************
    * BLOCK NORMALIZATION *
@@ -440,18 +889,18 @@ static void minimize(char** argv) {
     u32 use_len = MIN(set_len, in_len - set_pos);
 
     for (i = 0; i < use_len; i++)
-      if (in_data[set_pos + i] != '0') break;
+      if (in_data[set_pos + i] != '\x00') break;
 
     if (i != use_len) {
 
       memcpy(tmp_buf, in_data, in_len);
-      memset(tmp_buf + set_pos, '0', use_len);
+      memset(tmp_buf + set_pos, '\x00', use_len);
   
       res = run_target(argv, tmp_buf, in_len, 0);
 
       if (res) {
 
-        memset(in_data + set_pos, '0', use_len);
+        memset(in_data + set_pos, '\x00', use_len);
         changed_any = 1;
         alpha_del0 += use_len;
 
@@ -473,6 +922,8 @@ next_pass:
   ACTF(cYEL "--- " cBRI "Pass #%u " cYEL "---", ++cur_pass);
   changed_any = 0;
 
+// Tobi: Could remove block deletion step if it does not work well with flat MMIO accesses
+#if 1
   /******************
    * BLOCK DELETION *
    ******************/
@@ -534,7 +985,7 @@ next_del_blksize:
 
   }
 
-  if (del_len > 1 && in_len >= 1) {
+  if (del_len > 4 && in_len >= 1) {
 
     del_len /= 2;
     goto next_del_blksize;
@@ -546,7 +997,8 @@ next_del_blksize:
   if (!in_len && changed_any)
     WARNF(cLRD "Down to zero bytes - check the command line and mem limit!" cRST);
 
-  if (cur_pass > 1 && !changed_any) goto finalize_all;
+  if (cur_pass > 1 && !changed_any) goto bit_minimization;
+#endif
 
   /*************************
    * ALPHABET MINIMIZATION *
@@ -571,12 +1023,12 @@ next_del_blksize:
     u32 r;
     u8 res;
 
-    if (i == '0' || !alpha_map[i]) continue;
+    if (i == '\x00' || !alpha_map[i]) continue;
 
     memcpy(tmp_buf, in_data, in_len);
 
     for (r = 0; r < in_len; r++)
-      if (tmp_buf[r] == i) tmp_buf[r] = '0'; 
+      if (tmp_buf[r] == i) tmp_buf[r] = '\x00'; 
 
     res = run_target(argv, tmp_buf, in_len, 0);
 
@@ -601,24 +1053,45 @@ next_del_blksize:
    * CHARACTER MINIMIZATION *
    **************************/
 
+  changed_any = 0;
+
   alpha_del2 = 0;
 
   ACTF(cBRI "Stage #3: " cRST "Character minimization...");
 
   memcpy(tmp_buf, in_data, in_len);
 
+  // Tobi: Forward
   for (i = 0; i < in_len; i++) {
+    u8 res, orig = tmp_buf[i];
+
+    if (orig == '\x00') continue;
+    tmp_buf[i] = '\x00';
 
+    res = run_target(argv, tmp_buf, in_len, 0);
+
+    if (res) {
+
+      in_data[i] = '\x00';
+      alpha_del2++;
+      changed_any = 1;
+
+    } else tmp_buf[i] = orig;
+
+  }
+
+  // Tobi: Backwards
+  for (i = in_len-1; i < in_len; i--) {
     u8 res, orig = tmp_buf[i];
 
-    if (orig == '0') continue;
-    tmp_buf[i] = '0';
+    if (orig == '\x00') continue;
+    tmp_buf[i] = '\x00';
 
     res = run_target(argv, tmp_buf, in_len, 0);
 
     if (res) {
 
-      in_data[i] = '0';
+      in_data[i] = '\x00';
       alpha_del2++;
       changed_any = 1;
 
@@ -631,7 +1104,43 @@ next_del_blksize:
   OKF("Character minimization done, %u byte%s replaced.",
       alpha_del2, alpha_del2 == 1 ? "" : "s");
 
-  if (changed_any) goto next_pass;
+  //if (changed_any) goto next_pass;
+
+bit_minimization:
+// Tobi: Adding flipping bits to 0
+  ACTF(cBRI "Stage #4: " cRST "Bit minimization...");
+
+  memcpy(tmp_buf, in_data, in_len);
+
+  changed_any = 0;
+  bits_zeroed = 0;
+  for (i = 0; i < in_len; ++i)
+  {
+      // remove lsb's first so we remove unneccessarily large values first
+      for (j = 7; j >= 0; --j)
+      {
+        u8 res, orig = tmp_buf[i];
+
+        // search for 1 bits, skip values that only contain single bit
+        if (tmp_buf[i] & (1 << j) && tmp_buf[i] != (1 << j))
+        {
+            tmp_buf[i] ^= (1 << j);
+            res = run_target(argv, tmp_buf, in_len, 0);
+            if (res)
+            {
+                // SAYF("replacing %02x by %02x\n", orig, tmp_buf[i]);
+                in_data[i] = tmp_buf[i];
+                bits_zeroed++;
+                changed_any = 1;
+            }
+            else
+                tmp_buf[i] = orig;
+        }
+      }
+  }
+  total_bits_zeroed += bits_zeroed;
+  OKF("Bit minimization done, %u bit%s replaced.",
+  bits_zeroed, bits_zeroed == 1 ? "" : "s");
 
 finalize_all:
 
@@ -639,11 +1148,12 @@ finalize_all:
        cGRA "     File size reduced by : " cRST "%0.02f%% (to %u byte%s)\n"
        cGRA "    Characters simplified : " cRST "%0.02f%%\n"
        cGRA "     Number of execs done : " cRST "%u\n"
-       cGRA "          Fruitless execs : " cRST "path=%u crash=%u hang=%s%u\n\n",
+       cGRA "          Fruitless execs : " cRST "path=%u crash=%u hang=%s%u\n"
+       cGRA "              Bits zeroed : " cRST "%u\n\n",
        100 - ((double)in_len) * 100 / orig_len, in_len, in_len == 1 ? "" : "s",
        ((double)(alpha_d_total)) * 100 / (in_len ? in_len : 1),
        total_execs, missed_paths, missed_crashes, missed_hangs ? cLRD : "",
-       missed_hangs);
+       missed_hangs, total_bits_zeroed);
 
   if (total_execs > 50 && missed_hangs * 10 > total_execs)
     WARNF(cLRD "Frequent timeouts - results may be skewed." cRST);
@@ -689,6 +1199,12 @@ static void set_up_environment(void) {
 
   /* Set sane defaults... */
 
+  unlink(prog_in);
+
+  prog_in_fd = open(prog_in, O_RDWR | O_CREAT | O_EXCL, 0600);
+
+  if (prog_in_fd < 0) PFATAL("Unable to create '%s'", prog_in);
+
   x = getenv("ASAN_OPTIONS");
 
   if (x) {
@@ -818,7 +1334,9 @@ static void usage(u8* argv0) {
        "  -f file       - input file read by the tested program (stdin)\n"
        "  -t msec       - timeout for each run (%u ms)\n"
        "  -m megs       - memory limit for child process (%u MB)\n"
-       "  -Q            - use binary-only instrumentation (QEMU mode)\n\n"
+       "  -Q            - use binary-only instrumentation (QEMU mode)\n"
+       "  -U            - use Unicorn-based instrumentation (Unicorn mode)\n\n"
+       "                  (Not necessary, here for consistency with other afl-* tools)\n\n"
 
        "Minimization settings:\n\n"
 
@@ -949,7 +1467,6 @@ static char** get_qemu_argv(u8* own_loc,
 
 }
 
-
 /* Read mask bitmap from file. This is for the -B option. */
 
 static void read_bitmap(u8* fname) {
@@ -964,21 +1481,19 @@ static void read_bitmap(u8* fname) {
 
 }
 
-
-
 /* Main entry point */
 
 int main(int argc, char** argv) {
 
   s32 opt;
-  u8  mem_limit_given = 0, timeout_given = 0, qemu_mode = 0;
+  u8  mem_limit_given = 0, timeout_given = 0, qemu_mode = 0, unicorn_mode = 0;
   char** use_argv;
 
   doc_path = access(DOC_PATH, F_OK) ? "docs" : DOC_PATH;
 
   SAYF(cCYA "afl-tmin " cBRI VERSION cRST " by <lcamtuf@google.com>\n");
 
-  while ((opt = getopt(argc,argv,"+i:o:f:m:t:B:xeQ")) > 0)
+  while ((opt = getopt(argc,argv,"+i:o:f:m:t:B:xeQU")) > 0)
 
     switch (opt) {
 
@@ -1070,6 +1585,14 @@ int main(int argc, char** argv) {
         qemu_mode = 1;
         break;
 
+      case 'U':
+
+        if (unicorn_mode) FATAL("Multiple -Q options not supported");
+        if (!mem_limit_given) mem_limit = MEM_LIMIT_UNICORN;
+
+        unicorn_mode = 1;
+        break;
+
       case 'B': /* load bitmap */
 
         /* This is a secret undocumented option! It is speculated to be useful
@@ -1117,6 +1640,8 @@ int main(int argc, char** argv) {
 
   read_initial_file();
 
+  init_forkserver(use_argv);
+
   ACTF("Performing dry run (mem limit = %llu MB, timeout = %u ms%s)...",
        mem_limit, exec_tmout, edges_only ? ", edges only" : "");
 
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-whatsdown afl/afl-whatsdown
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-whatsdown	1970-01-01 08:00:00.000000000 +0800
+++ afl/afl-whatsdown	2024-12-05 22:46:35.609533858 +0800
@@ -0,0 +1,164 @@
+#!/bin/sh
+#
+# american fuzzy lop - status check tool
+# --------------------------------------
+#
+# Written and maintained by Michal Zalewski <lcamtuf@google.com>
+#
+# Copyright 2015 Google Inc. All rights reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at:
+#
+#   http://www.apache.org/licenses/LICENSE-2.0
+#
+# This tool summarizes the status of any locally-running synchronized
+# instances of afl-fuzz.
+#
+
+echo "status check tool for afl-fuzz by <lcamtuf@google.com>"
+echo
+
+if [ "$1" = "-s" ]; then
+
+  SUMMARY_ONLY=1
+  DIR="$2"
+
+else
+
+  unset SUMMARY_ONLY
+  DIR="$1"
+
+fi
+
+if [ "$DIR" = "" ]; then
+
+  echo "Usage: $0 [ -s ] afl_sync_dir" 1>&2
+  echo 1>&2
+  echo "The -s option causes the tool to skip all the per-fuzzer trivia and show" 1>&2
+  echo "just the summary results. See docs/parallel_fuzzing.txt for additional tips." 1>&2
+  echo 1>&2
+  exit 1
+
+fi
+
+cd "$DIR" || exit 1
+
+if [ -d queue ]; then
+
+  echo "[-] Error: parameter is an individual output directory, not a sync dir." 1>&2
+  exit 1
+
+fi
+
+CUR_TIME=`date +%s`
+
+TMP=`mktemp -t .afl-whatsup-XXXXXXXX` || exit 1
+
+ALIVE_CNT=0
+DEAD_CNT=0
+
+TOTAL_TIME=0
+TOTAL_EXECS=0
+TOTAL_EPS=0
+TOTAL_CRASHES=0
+TOTAL_PFAV=0
+TOTAL_PENDING=0
+TOTAL_PATHS_FOUND=0
+
+if [ "$SUMMARY_ONLY" = "" ]; then
+
+  echo "Individual fuzzers"
+  echo "=================="
+  echo
+
+fi
+
+for i in `find . -maxdepth 2 -iname fuzzer_stats | sort`; do
+
+  sed 's/^command_line.*$/_skip:1/;s/[ ]*:[ ]*/="/;s/$/"/' "$i" >"$TMP"
+  . "$TMP"
+
+  RUN_UNIX=$((CUR_TIME - start_time))
+  RUN_DAYS=$((RUN_UNIX / 60 / 60 / 24))
+  RUN_HRS=$(((RUN_UNIX / 60 / 60) % 24))
+
+  if [ "$SUMMARY_ONLY" = "" ]; then
+
+    echo ">>> $afl_banner ($RUN_DAYS days, $RUN_HRS hrs) <<<"
+    echo
+
+  fi
+
+  #if ! kill -0 "$fuzzer_pid" 2>/dev/null; then
+
+    #if [ "$SUMMARY_ONLY" = "" ]; then
+
+     # echo "  Instance is dead or running remotely, skipping."
+      #echo
+
+    #fi
+
+    #DEAD_CNT=$((DEAD_CNT + 1))
+    #continue
+
+  #fi
+
+  ALIVE_CNT=$((ALIVE_CNT + 1))
+  TOTAL_PATHS_FOUND=$((TOTAL_PATHS_FOUND + paths_found))
+  EXEC_SEC=$((execs_done / RUN_UNIX))
+  PATH_PERC=$((cur_path * 100 / paths_total))
+
+  TOTAL_TIME=$((TOTAL_TIME + RUN_UNIX))
+  TOTAL_EPS=$((TOTAL_EPS + EXEC_SEC))
+  TOTAL_EXECS=$((TOTAL_EXECS + execs_done))
+  TOTAL_CRASHES=$((TOTAL_CRASHES + unique_crashes))
+  TOTAL_PENDING=$((TOTAL_PENDING + pending_total))
+  TOTAL_PFAV=$((TOTAL_PFAV + pending_favs))
+
+  if [ "$SUMMARY_ONLY" = "" ]; then
+
+    echo "  cycle $((cycles_done + 1)), lifetime speed $EXEC_SEC execs/sec, path $cur_path/$paths_total (${PATH_PERC}%)"
+
+    if [ "$unique_crashes" = "0" ]; then
+      echo "  pending $pending_favs/$pending_total, coverage $bitmap_cvg, no crashes yet"
+    else
+      echo "  pending $pending_favs/$pending_total, coverage $bitmap_cvg, crash count $unique_crashes (!)"
+    fi
+
+    echo
+
+  fi
+
+done
+
+rm -f "$TMP"
+
+TOTAL_DAYS=$((TOTAL_TIME / 60 / 60 / 24))
+TOTAL_HRS=$(((TOTAL_TIME / 60 / 60) % 24))
+
+test "$TOTAL_TIME" = "0" && TOTAL_TIME=1
+
+echo "Summary stats"
+echo "============="
+echo
+echo "       Fuzzers alive : $ALIVE_CNT"
+
+if [ ! "$DEAD_CNT" = "0" ]; then
+  echo "      Dead or remote : $DEAD_CNT (excluded from stats)"
+fi
+
+echo "      Total run time : $TOTAL_DAYS days, $TOTAL_HRS hours"
+echo "         Total execs : $TOTAL_EXECS"
+echo "    Cumulative speed : $TOTAL_EPS execs/sec"
+echo "       Pending paths : $TOTAL_PFAV faves, $TOTAL_PENDING total"
+echo "    Total Paths : $TOTAL_PATHS_FOUND"
+if [ "$ALIVE_CNT" -gt "1" ]; then
+  echo "  Pending per fuzzer : $((TOTAL_PFAV/ALIVE_CNT)) faves, $((TOTAL_PENDING/ALIVE_CNT)) total (on average)"
+fi
+
+echo "       Crashes found : $TOTAL_CRASHES locally unique"
+echo
+
+exit 0
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-whatsup afl/afl-whatsup
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/afl-whatsup	2020-01-08 03:20:26.000000000 +0800
+++ afl/afl-whatsup	2024-12-05 22:47:23.812384374 +0800
@@ -149,7 +149,7 @@ if [ ! "$DEAD_CNT" = "0" ]; then
 fi
 
 echo "      Total run time : $TOTAL_DAYS days, $TOTAL_HRS hours"
-echo "         Total execs : $((TOTAL_EXECS / 1000 / 1000)) million"
+echo "         Total execs : $TOTAL_EXECS"
 echo "    Cumulative speed : $TOTAL_EPS execs/sec"
 echo "       Pending paths : $TOTAL_PFAV faves, $TOTAL_PENDING total"
 
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/config.h afl/config.h
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/config.h	2020-01-08 03:20:26.000000000 +0800
+++ afl/config.h	2024-12-05 22:48:07.793264412 +0800
@@ -59,6 +59,10 @@
 
 #define MEM_LIMIT_QEMU      200
 
+/* Default memory limit when running in Unicorn mode (MB): */
+
+#define MEM_LIMIT_UNICORN   200
+
 /* Number of calibration cycles per every new test case (and for test
    cases that show variable behavior): */
 

diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/experimental/clang_asm_normalize/as afl/experimental/clang_asm_normalize/as
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/experimental/clang_asm_normalize/as	2020-01-08 03:20:26.000000000 +0800
+++ afl/experimental/clang_asm_normalize/as	2024-12-05 22:49:06.620126179 +0800
@@ -1,75 +0,0 @@
-#!/bin/sh
-#
-# american fuzzy lop - clang assembly normalizer
-# ----------------------------------------------
-#
-# Written and maintained by Michal Zalewski <lcamtuf@google.com>
-# The idea for this wrapper comes from Ryan Govostes.
-#
-# Copyright 2013, 2014 Google Inc. All rights reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at:
-#
-#   http://www.apache.org/licenses/LICENSE-2.0
-#
-# This 'as' wrapper should allow you to instrument unruly, hand-written
-# assembly with afl-as.
-#
-# Usage:
-#
-# export AFL_REAL_PATH=/path/to/directory/with/afl-as/
-# AFL_PATH=/path/to/this/directory/ make clean all
-
-if [ "$#" -lt "2" ]; then
-  echo "[-] Error: this utility can't be called directly." 1>&2
-  exit 1
-fi
-
-if [ "$AFL_REAL_PATH" = "" ]; then
-  echo "[-] Error: AFL_REAL_PATH not set!" 1>&2
-  exit 1
-fi
-
-if [ ! -x "$AFL_REAL_PATH/afl-as" ]; then
-  echo "[-] Error: AFL_REAL_PATH does not contain the 'afl-as' binary." 1>&2
-  exit 1
-fi
-
-unset __AFL_AS_CMDLINE __AFL_FNAME
-
-while [ ! "$#" = "0" ]; do
-
-  if [ "$#" = "1" ]; then
-    __AFL_FNAME="$1"
-  else
-    __AFL_AS_CMDLINE="${__AFL_AS_CMDLINE} $1"
-  fi
-
-  shift
-
-done
-
-test "$TMPDIR" = "" && TMPDIR=/tmp
-
-TMPFILE=`mktemp $TMPDIR/.afl-XXXXXXXXXX.s`
-
-test "$TMPFILE" = "" && exit 1
-
-clang -cc1as -filetype asm -output-asm-variant 0 "${__AFL_FNAME}" >"$TMPFILE"
-
-ERR="$?"
-
-if [ ! "$ERR" = "0" ]; then
-  rm -f "$TMPFILE"
-  exit $ERR
-fi
-
-"$AFL_REAL_PATH/afl-as" ${__AFL_AS_CMDLINE} "$TMPFILE"
-
-ERR="$?"
-
-rm -f "$TMPFILE"
-
-exit "$ERR"
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/LICENSE afl/LICENSE
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/LICENSE	1970-01-01 08:00:00.000000000 +0800
+++ afl/LICENSE	2024-12-05 22:52:51.031788661 +0800
@@ -0,0 +1,201 @@
+   Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
\ No newline at end of file
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/Makefile afl/Makefile
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/Makefile	2020-01-08 03:20:26.000000000 +0800
+++ afl/Makefile	2024-12-05 22:56:13.239673694 +0800
@@ -70,7 +70,7 @@ afl-as: afl-as.c afl-as.h $(COMM_HDR) |
 	ln -sf afl-as as
 
 afl-fuzz: afl-fuzz.c $(COMM_HDR) | test_x86
-	$(CC) $(CFLAGS) $@.c -o $@ $(LDFLAGS)
+	$(CC) $(CFLAGS) $@.c -o $@ $(LDFLAGS) -lpthread
 
 afl-showmap: afl-showmap.c $(COMM_HDR) | test_x86
 	$(CC) $(CFLAGS) $@.c -o $@ $(LDFLAGS)
@@ -89,10 +89,29 @@
 test_build: afl-gcc afl-as afl-showmap
 	@echo "[*] Testing the CC wrapper and instrumentation output..."
 	unset AFL_USE_ASAN AFL_USE_MSAN; AFL_QUIET=1 AFL_INST_RATIO=100 AFL_PATH=. ./$(TEST_CC) $(CFLAGS) test-instr.c -o test-instr $(LDFLAGS)
+	unset AFL_USE_ASAN AFL_USE_MSAN; AFL_QUIET=1 AFL_INST_RATIO=100 AFL_PATH=. ./$(TEST_CC) $(CFLAGS) test-instr-argv.c -o test-instr-argv $(LDFLAGS)
 	echo 0 | ./afl-showmap -m none -q -o .test-instr0 ./test-instr
 	echo 1 | ./afl-showmap -m none -q -o .test-instr1 ./test-instr
-	@rm -f test-instr
 	@cmp -s .test-instr0 .test-instr1; DR="$$?"; rm -f .test-instr0 .test-instr1; if [ "$$DR" = "0" ]; then echo; echo "Oops, the instrumentation does not seem to be behaving correctly!"; echo; echo "Please ping <lcamtuf@google.com> to troubleshoot the issue."; echo; exit 1; fi
+	@mkdir -p .tmp_inputs .tmp_outputs
+
+	@echo 0 > .tmp_inputs/input0
+	@echo 1 > .tmp_inputs/input1
+	./afl-showmap -m none -q -i .tmp_inputs/input0 -o .test-instr0 ./test-instr 
+	./afl-showmap -m none -q -i .tmp_inputs/input1 -o .test-instr1 ./test-instr
+	@cmp -s .test-instr0 .test-instr1; DR="$$?"; rm -f .test-instr0 .test-instr1; if [ "$$DR" = "0" ]; then echo; echo "Oops, the instrumentation does not seem to be behaving correctly!"; echo; echo "Please ping <lcamtuf@google.com> to troubleshoot the issue."; echo; exit 1; fi
+
+	./afl-showmap -m none -q -i .tmp_inputs/input0 -o .test-instr0 ./test-instr-argv @@ 
+	./afl-showmap -m none -q -i .tmp_inputs/input1 -o .test-instr1 ./test-instr-argv @@
+	@cmp -s .test-instr0 .test-instr1; DR="$$?"; rm -f .test-instr0 .test-instr1; if [ "$$DR" = "0" ]; then echo; echo "Oops, the instrumentation does not seem to be behaving correctly!"; echo; echo "Please ping <lcamtuf@google.com> to troubleshoot the issue."; echo; exit 1; fi
+
+	./afl-showmap -m none -q -i .tmp_inputs -o .tmp_outputs ./test-instr
+	@cmp -s .tmp_outputs/.test-instr0 .tmp_outputs/.test-instr1; DR="$$?"; rm -f tmp_outputs/.test-instr0 tmp_outputs/.test-instr1; if [ "$$DR" = "0" ]; then echo; echo "Oops, the instrumentation does not seem to be behaving correctly!"; echo; echo "Please ping <lcamtuf@google.com> to troubleshoot the issue."; echo; exit 1; fi
+
+	./afl-showmap -m none -q -i .tmp_inputs -o .tmp_outputs ./test-instr-argv @@
+	@cmp -s .tmp_outputs/.test-instr0 .tmp_outputs/.test-instr1; DR="$$?"; rm -f tmp_outputs/.test-instr0 tmp_outputs/.test-instr1; if [ "$$DR" = "0" ]; then echo; echo "Oops, the instrumentation does not seem to be behaving correctly!"; echo; echo "Please ping <lcamtuf@google.com> to troubleshoot the issue."; echo; exit 1; fi
+
+	@rm -rf .tmp_outputs .tmp_inputs
 	@echo "[+] All right, the instrumentation seems to be working!"
 
 else
@@ -111,8 +130,8 @@
 .NOTPARALLEL: clean
 
 clean:
-	rm -f $(PROGS) afl-as as afl-g++ afl-clang afl-clang++ *.o *~ a.out core core.[1-9][0-9]* *.stackdump test .test test-instr .test-instr0 .test-instr1 qemu_mode/qemu-2.10.0.tar.bz2 afl-qemu-trace
-	rm -rf out_dir qemu_mode/qemu-2.10.0
+	rm -f $(PROGS) afl-as as afl-g++ afl-clang afl-clang++ *.o *~ a.out core core.[1-9][0-9]* *.stackdump test .test test-instr test-instr-argv .test-instr0 .test-instr1 qemu_mode/qemu-2.10.0.tar.bz2 afl-qemu-trace
+	rm -rf out_dir qemu_mode/qemu-2.10.0 .tmp_outputs .tmp_inputs
 	$(MAKE) -C llvm_mode clean
 	$(MAKE) -C libdislocator clean
 	$(MAKE) -C libtokencap clean
@@ -123,6 +142,7 @@
 	install -m 755 $(PROGS) $(SH_PROGS) $${DESTDIR}$(BIN_PATH)
 	rm -f $${DESTDIR}$(BIN_PATH)/afl-as
 	if [ -f afl-qemu-trace ]; then install -m 755 afl-qemu-trace $${DESTDIR}$(BIN_PATH); fi
+	if [ -f libunicorn.so.1 ]; then install -m 755 libunicorn.so.1 $${DESTDIR}$(HELPER_PATH); ln -sf libunicorn.so.1 $${DESTDIR}$(HELPER_PATH)/libunicorn.so; fi
 ifndef AFL_TRACE_PC
 	if [ -f afl-clang-fast -a -f afl-llvm-pass.so -a -f afl-llvm-rt.o ]; then set -e; install -m 755 afl-clang-fast $${DESTDIR}$(BIN_PATH); ln -sf afl-clang-fast $${DESTDIR}$(BIN_PATH)/afl-clang-fast++; install -m 755 afl-llvm-pass.so afl-llvm-rt.o $${DESTDIR}$(HELPER_PATH); fi
 else
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/qemu_mode/build_qemu_support.sh afl/qemu_mode/build_qemu_support.sh
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/qemu_mode/build_qemu_support.sh	2020-01-08 03:20:26.000000000 +0800
+++ afl/qemu_mode/build_qemu_support.sh	2024-12-05 22:56:56.781666062 +0800
@@ -139,7 +139,7 @@ echo "[+] Patching done."
 
 CFLAGS="-O3 -ggdb" ./configure --disable-system \
   --enable-linux-user --disable-gtk --disable-sdl --disable-vnc \
-  --target-list="${CPU_TARGET}-linux-user" --enable-pie --enable-kvm || exit 1
+  --target-list="${CPU_TARGET}-linux-user" --enable-pie --enable-kvm --python=/usr/bin/python2 || exit 1
 
 echo "[+] Configuration complete."
 
diff -uprN "afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/README -aflunicorn.md" "afl/README -aflunicorn.md"
--- "afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/README -aflunicorn.md"	1970-01-01 08:00:00.000000000 +0800
+++ "afl/README -aflunicorn.md"	2024-12-05 22:58:09.442664248 +0800
@@ -0,0 +1,16 @@
+```
+        __ _                 _                      
+  __ _ / _| |    _   _ _ __ (_) ___ ___  _ __ _ __  
+ / _` | |_| |___| | | | '_ \| |/ __/ _ \| '__| '_ \ 
+| (_| |  _| |___| |_| | | | | | (_| (_) | |  | | | |
+ \__,_|_| |_|    \__,_|_| |_|_|\___\___/|_|  |_| |_|
+                                                      
+```
+
+afl-unicorn lets you fuzz any piece of binary that can be emulated by [Unicorn Engine](http://www.unicorn-engine.org/). 
+
+For an in-depth description of what this is, how to install it, and how to use it check out this [blog post](https://medium.com/@njvoss299afl-unicorn-fuzzing-arbitrary-binary-code-563ca28936bf).
+
+For general help with AFL, please refer to both the official [AFL website](http://lcamtuf.coredump.cxafl/) and the documents in the /doc/ directory.
+
+Created by Nathan Voss, originally funded by [Battelle](https://www.battelle.org/cyber).
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/test-instr-argv.c afl/test-instr-argv.c
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/test-instr-argv.c	1970-01-01 08:00:00.000000000 +0800
+++ afl/test-instr-argv.c	2024-12-05 22:59:36.416677827 +0800
@@ -0,0 +1,45 @@
+/*
+   american fuzzy lop - a trivial program to test the build
+   --------------------------------------------------------
+
+   Written and maintained by Michal Zalewski <lcamtuf@google.com>
+
+   Copyright 2014 Google Inc. All rights reserved.
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at:
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <fcntl.h>
+
+int main(int argc, char** argv) {
+
+  char buf[8];
+  int fd = 0;
+
+  if(argc != 2)
+      return -1;
+
+  fd = open(argv[1], O_RDONLY);
+
+  if (read(fd, buf, 8) < 1) {
+    printf("Hum?\n");
+    exit(1);
+  }
+
+  close(fd);
+
+  if (buf[0] == '0')
+    printf("Looks like a zero to me!\n");
+  else
+    printf("A non-zero value? How quaint!\n");
+
+  exit(0);
+}
diff -uprN afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/types.h afl/types.h
--- afl-2.52b-c49750c9e27e29100d055292453551d560e594ce/types.h	2020-01-08 03:20:26.000000000 +0800
+++ afl/types.h	2024-12-05 23:00:30.108693662 +0800
@@ -80,7 +80,9 @@ typedef int64_t  s64;
 #define MEM_BARRIER() \
   asm volatile("" ::: "memory")
 
+#ifndef likely
 #define likely(_x)   __builtin_expect(!!(_x), 1)
 #define unlikely(_x)  __builtin_expect(!!(_x), 0)
+#endif
 
 #endif /* ! _HAVE_TYPES_H */
